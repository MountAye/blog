<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">



<title>.py | PyTorch 数据处理方面的封装 | 阿掖山：一个博客</title>
<link rel="shortcut icon" href="https://mountaye.github.io/blog/favicon.ico" >
<link rel="canonical" href="https://mountaye.github.io/blog/articles/pytorch-dataset-dataloader-sampler" />
<meta name="generator" content="Jekyll v4.3.2" />
<meta name="author" content="MountAye" />
<meta name="description" content="一般监督学习的数据结构和处理过程，以及 PyTorch 对上述结构和处理过程的封装" />
<meta property="og:title" content=".py | PyTorch 数据处理方面的封装" />
<meta property="og:locale" content="zh-CN" />
<meta property="og:description" content="" />
<meta property="og:url" content="https://mountaye.github.io/blog/articles/pytorch-dataset-dataloader-sampler" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-09-01 00:00:00 -0500" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content=".py | PyTorch 数据处理方面的封装" />
<script type="application/ld+json">
    {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"MountAye"},"dateModified":"","datePublished":"2022-09-01","description":"一般监督学习的数据结构和处理过程，以及 PyTorch 对上述结构和处理过程的封装","headline":"一般监督学习的数据结构和处理过程，以及 PyTorch 对上述结构和处理过程的封装","mainEntityOfPage":{"@type":"WebPage","@id":""},"url":"https://mountaye.github.io/blog/articles/pytorch-dataset-dataloader-sampler"}
</script>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1920275466226790"
     crossorigin="anonymous"></script>

    <link rel="stylesheet" href="/blog/assets/css/style.css?v=">
    <script src="https://code.jquery.com/jquery-3.3.0.min.js" integrity="sha256-RTQy8VOmNlT6b2PIRur37p6JEBZUE7o8wPgMvu18MC4=" crossorigin="anonymous"></script>
    <script src="/blog/assets/js/main.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!--[if lt IE 9]>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
  </head>
  <body>
    <header>
      <h1>阿掖山：一个博客</h1>
      <p>智力活动是一种生活态度</p>
    </header>
    <div id="banner">
      <span id="logo"></span>
      <span class="button fork">
        <a href="/blog/articles/pytorch-dataset-dataloader-sampler"><strong>汉</strong></a> | 
        <a href="/blog/en/articles/pytorch-dataset-dataloader-sampler"><strong>En</strong></a>
      </span>
      <div class="downloads">
        <span></span>
        <ul>
          <li><a href="/blog/history" class="button">历史</a></li>
          <li><a href="/blog/topics" class="button">分类</a></li>
          <li><a href="/blog/about" class="button">关于</a></li>
        </ul>
      </div>
    </div>

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section id="ad-head"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1920275466226790"
     crossorigin="anonymous"></script>
<!-- blog-header -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1920275466226790"
     data-ad-slot="4291489170"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></section>
<section class="outlined">
  <h1>.py | PyTorch 数据处理方面的封装</h1>
  <p style="text-indent: 0;">2022 年 9 月 1 日 </p>
  <p style="text-indent: 0;"><code>.md</code><code>.py</code><code>.ai</code></p>
  
  <hr>
  <h2 id="一般监督学习的数据结构和处理过程">一般监督学习的数据结构和处理过程</h2>

<h3 id="训练集验证集测试集">训练集、验证集、测试集</h3>

<p>所有数据整体构成一个大集合，这个集合的每一个元素都包含一个输入和一个目标，分别记作 x 和 y。</p>

<p>把这个大集合分成互相没有交集的三个子集，分别是训练集 (training set)、验证集 (validation set)、测试集 (test set)。</p>

<ul>
  <li>训练集和验证集在训练过程中使用。
    <ul>
      <li>训练集的数据带入模型时，模型处于训练模式，模型输出对参数的导数被记录。通过比较把“模型输出”和“训练目标 y”代入<strong>损失函数</strong>的损失，更新模型的参数。同时记录“模型输出”和“训练目标 y”带入验证函数的结果，和验证集比较。</li>
      <li>验证集的数据代入模型时，模型处于求值模式，模型只根据输入计算输出，对参数的导数不记录。通过观察“模型输出”和“训练目标 y”带入<strong>验证函数</strong>的结果，观察训练是否陷入“过拟合”。当训练集的验证函数结果不断下降，但是验证集的验证函数结果几乎不变时，可以认为模型过拟合。</li>
    </ul>
  </li>
  <li>测试集在训练完成之后使用，代入模型时，模型处于求值模式。用于评价训练结果的好坏。</li>
</ul>

<h3 id="epoch-vs-batch">epoch vs. batch</h3>

<p>如果把所有数据同时进行训练，所需要的空间一般都大于电脑内存。所以一般会将训练集随机分成若干批次 (batch)，一个批次的数据同时塞入模型进行训练，在一个 batch 里每一个模型输出对参数的导数累加在一起，整个 batch 结束后更新模型参数，同时导数清零。因为 batch 这个概念和内存有关，所以数值一般选择为 2 的指数。</p>

<p>将训练集所有的 batches 跑完一次称为而一个 epoch。一次训练一般需要很多 epochs，直到损失函数结果足够低，或验证集显示出现过拟合。</p>

<h2 id="pytorch-对上述结构和处理过程的封装">PyTorch 对上述结构和处理过程的封装</h2>

<h3 id="dataset"><code class="language-plaintext highlighter-rouge">Dataset</code></h3>

<p>前面已经说了，数据集包括输入和目标两部分，<code class="language-plaintext highlighter-rouge">Dateset</code> 及其子类的作用就是</p>

<p>如果在把数据装入 <code class="language-plaintext highlighter-rouge">Dataset</code> 之前就已经是规整的两个张量了的话——</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="c1"># ...
</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">):</span>
    <span class="c1"># do something with x and y
</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">trainset</span><span class="p">:</span>
    <span class="c1"># do something with x and y
</span></code></pre></div></div>

<p>——这一步确实没什么意思。</p>

<p>有意思的地方在于可以自己写一个数据集类，继承 <code class="language-plaintext highlighter-rouge">Dataset</code>，然后重载 <code class="language-plaintext highlighter-rouge">__getitem__()</code> 和 <code class="language-plaintext highlighter-rouge">__len__()</code> 方法，这样可以把一些不适合用张量表示的数据塞进 <code class="language-plaintext highlighter-rouge">Dataset</code> 里面，对图像进行学习的话可以在此处加入图像增强的步骤，并进一步用于 <code class="language-plaintext highlighter-rouge">DataLoader</code></p>

<h3 id="dataloader"><code class="language-plaintext highlighter-rouge">DataLoader</code></h3>

<p><code class="language-plaintext highlighter-rouge">DataLoader</code> = <code class="language-plaintext highlighter-rouge">Dataset</code> + <code class="language-plaintext highlighter-rouge">Sampler</code>，因为一般的教程里只需要讲数据集进行简单随机划分，也就只用到了 <code class="language-plaintext highlighter-rouge">batch_size</code> 等等参数，用到 Sampler 的地方很少。</p>

<p>最常见的用例就是 <code class="language-plaintext highlighter-rouge">WeightedRandomSampler</code> 。训练分类器的时候，有时其中一个类别的数据远少于其他，那么训练器就更难判断出这一分类（因为只要无脑排除这个类别就能获得不错的正确率），所以需要平衡不同组别之间的权重。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">list</span><span class="p">(</span><span class="nc">WeightedRandomSampler</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="c1"># [4, 4, 1, 4, 5]
</span><span class="nf">list</span><span class="p">(</span><span class="nc">WeightedRandomSampler</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="c1"># [0, 1, 4, 3, 2]
</span></code></pre></div></div>

<p>平衡完之后转化为 batch，搭配 <code class="language-plaintext highlighter-rouge">BatchSampler</code>：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">list</span><span class="p">(</span><span class="nc">BatchSampler</span><span class="p">(</span><span class="nc">WeightedRandomSampler</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="c1"># [[4, 4], [1, 4], 5]
</span><span class="nf">list</span><span class="p">(</span><span class="nc">BatchSampler</span><span class="p">(</span><span class="nc">WeightedRandomSampler</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="c1"># [[0, 1], [4, 3]]
</span></code></pre></div></div>

<h3 id="汇总一下">汇总一下</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>

<span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">rand</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nc">TensorDataset</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span><span class="n">train_y</span><span class="p">)</span>

<span class="c1"># either:
</span><span class="n">trainloader</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
    <span class="n">trainset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">sampler</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="nc">WeightedRandomSampler</span><span class="p">(</span>
        <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> 
        <span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
        <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="c1"># or:
</span><span class="n">trainloader</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span>
    <span class="n">trainset</span><span class="p">,</span>
    <span class="n">batch_sampler</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="nc">BatchSampler</span><span class="p">(</span>
        <span class="n">data</span><span class="p">.</span><span class="nc">WeightedRandomSampler</span><span class="p">(</span>
            <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> 
            <span class="n">num_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
            <span class="n">replacement</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> 
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
        <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">trainloader</span><span class="p">:</span>
        <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">loss_function</span><span class="p">)</span>
</code></pre></div></div>

<p>需要注意的是，<code class="language-plaintext highlighter-rouge">for x,y in trainset</code> 的 x 和 y 的维度是单个数据的维度，最简单的情况就是是 P 和 Q 维向量，而此时如果把 batch_size 记作 B，<code class="language-plaintext highlighter-rouge">for x,y in trainloader</code> 中的 x 和 y 是维度分别为 (B,P) 和 (B,Q) 的矩阵。<code class="language-plaintext highlighter-rouge">train()</code> 函数里面的计算要考虑到多出的这一个维度。</p>

<h2 id="参考链接">参考链接：</h2>

<ul>
  <li><a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">https://pytorch.org/tutorials/beginner/basics/data_tutorial.html</a></li>
  <li><a href="https://pytorch.org/tutorials/beginner/nn_tutorial.html">https://pytorch.org/tutorials/beginner/nn_tutorial.html</a></li>
  <li><a href="https://pytorch.org/tutorials/beginner/ptcheat.html">https://pytorch.org/tutorials/beginner/ptcheat.html</a></li>
  <li><a href="https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset">https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset</a></li>
  <li><a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader">https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader</a></li>
  <li><a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Sampler">https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.Sampler</a></li>
  <li><a href="https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#Dataset">https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#Dataset</a></li>
</ul>

  <hr>
</section>
<section id="ad-tail"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1920275466226790"
     crossorigin="anonymous"></script>
<!-- blog-header -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1920275466226790"
     data-ad-slot="4291489170"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></section>
<section id="comments">
  <script src="https://giscus.app/client.js"
        data-repo="MountAye/comments"
        data-repo-id="R_kgDOJe4FmQ"
        data-category="BLOG"
        data-category-id="DIC_kwDOJe4Fmc4CWQuC"
        data-mapping="title"
        data-strict="1"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-input-position="bottom"
        data-theme="light"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script>
</section>

    </div>
    <footer>
      <p><small>Hosted on GitHub Pages
            <br>Theme by <a href="https://twitter.com/mattgraham">mattgraham</a>
            <br>Modified by <a href="https://www.github.com/MountAye">MountAye</a>
      </small></p>
    </footer>

  </body>
</html>

  