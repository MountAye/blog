<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    

<title>.py | 一个 PyTorch 机器学习项目长什么样 | 阿掖山</title>
<link rel="shortcut icon" href="https://mountaye.github.io/blog/favicon.ico" >
<link rel="canonical" href="https://mountaye.github.io/blog/articles/what-a-PyTorch-project-looks-like" />
<meta name="generator" content="Jekyll v4.3.2" />
<meta name="author" content="MountAye" />
<meta name="description" content="官网的一个pytorch教程的笔记，原文先按照第一性原理，尽量用原生 python 写了一遍，然后一步一步重构成接近生产环境的代码。这里我把顺序反过来，先放出重构之后的最终结果" />
<meta property="og:title" content=".py | 一个 PyTorch 机器学习项目长什么样" />
<meta property="og:locale" content="zh-CN" />
<meta property="og:description" content="" />
<meta property="og:url" content="https://mountaye.github.io/blog/articles/what-a-PyTorch-project-looks-like" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-17 00:00:00 -0500" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content=".py | 一个 PyTorch 机器学习项目长什么样" />
<script type="application/ld+json">
    {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"MountAye"},"dateModified":"","datePublished":"2022-08-17","description":"官网的一个pytorch教程的笔记，原文先按照第一性原理，尽量用原生 python 写了一遍，然后一步一步重构成接近生产环境的代码。这里我把顺序反过来，先放出重构之后的最终结果","headline":"官网的一个pytorch教程的笔记，原文先按照第一性原理，尽量用原生 python 写了一遍，然后一步一步重构成接近生产环境的代码。这里我把顺序反过来，先放出重构之后的最终结果","mainEntityOfPage":{"@type":"WebPage","@id":"https://mountaye.github.io/blog/articles/what-a-PyTorch-project-looks-like"},"url":"https://mountaye.github.io/blog/articles/what-a-PyTorch-project-looks-like"}
</script>

    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3X9B5LN42L"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3X9B5LN42L');
</script>
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:ital,opsz,wght@0,8..60,400;0,8..60,700;1,8..60,400;1,8..60,700&display=swap" rel="stylesheet">
    <script>
      (function(d) {
        var config = {
          kitId: 'oau8puo',
          scriptTimeout: 3000,
          async: true
        },
        h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)
      })(document);
    </script>
    <!-- End Fonts -->
    <link rel="stylesheet" href="/blog/assets/css/main.css">
    <script src="/blog/assets/js/main.js"></script>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
  </head>
  <body>
    <div class="layout-all">
      <aside id="left" class="layout-left">
        <a class="left-avatar"
           href="https://mountaye.github.io/blog/"
        >
          <div id="avatar"></div>
          <div id="sitename">阿掖山</div>
        </a>
        <div class="left-quote">
          <div class="fade-out-left"></div>
          <div class="overflow-x side-vertical">
            <p><span id="quote-line">智力活动是一种生活态度</span></p>
            <p>——<span id="quote-author">阿掖山·一个博客</span></p>
          </div>
        </div>
        <footer class="left-footer side-vertical">
          <div id="social-icons">
            <a href="/blog/feed.xml" class="icon-Popular_RSS"></a>
            <a href="" class="icon-Popular_GitHub"></a>
            <a href="" class="icon-Popular_Twitter"></a>
            <a href="" class="icon-Popular_mail" style="font-size: 13px;"></a>
          </div>
          <!-- Please keep this to comply with MIT liscence -->
          <a href="https://www.github.com/MountAye" style="display: block; text-decoration: none; color: black;">
            <p>Fading Snow <br>
               a theme by MountAye</p>
          </a>
        </footer>
      </aside> 
      <!--  --> 
      <div class="layout-mid">
        <header id="header">
          <h1 id="header-title">阿掖山.py | 一个 PyTorch 机器学习项目长什么样</h1>
          <div id="toc-button" class="changable-icon dropdown-button" onclick="tocButton(this)">
            <div class="bar1"></div><div class="bar2"></div><div class="bar3"></div>
          </div>
          <div id="toc-dropdown-container" class="dropdown-content">
            <div id="toc-dropdown"></div>
          </div>
        </header>
      
        <div id="title-banner" class="written">
          
          <h1>.py | 一个 PyTorch 机器学习项目长什么样</h1>
          <div id="author-card">
            <div id="author-avatar" style='background-image: url("/blog/assets/img/before_h2.png");'></div>
            <div id="author-texts">
              <p><strong>MountAye</strong></p>
              <p>Aug 17, 2022</p>
            </div>
          </div>
          <hr>  
        </div>
      
        <main class="written">
          <p>自学，或者说一切学习和教学，本质就是在已经掌握的知识和未知的目标知识之间修路。路有两种修法，一是理论或者说是第一性原理路线，从不证自明的公理或者已经掌握的知识出发，通过逻辑推理一步步得到新的知识；另一种是实践或者说工程师路线，拿到一个已经可以工作的产品，划分成各个子系统，通过输入的改变来观察输出的不同，直到子系统简化到自己可以理解的地步，不再是黑箱，借此了解整个系统的功能。</p>

<p>但是当学习的对象复杂到一定程度之后，凭借一个人的自学能力，只用其中一种方法往往难以钻透。又或者两种方法学到的路线并非同一条路。对于机器学习，理论路线就是“让输入数据通过一个带有超多参数的函数，根据函数返回值和输出数据之间的差别修正参数，直到函数能够近似输入数据和输出数据之间的关系”；实践中代码往往会使用很多库作者封装好的函数，只读源码往往一头雾水。</p>

<p>所以，看到 PyTorch 官网的这篇教程 <strong>WHAT IS TORCH.NN <em>REALLY</em>?:</strong> <a href="https://pytorch.org/tutorials/beginner/nn_tutorial.html">https://pytorch.org/tutorials/beginner/nn_tutorial.html</a> 可以说是喜出望外，把两种路线写出的代码都给了出来，对于自学者来说，就像罗塞塔石碑一样可以互相对照。这里我把 CNN 相关的部分抽掉了，毕竟 CNN 只是深度学习的一个子集，深度学习只是机器学习的一个子集，和这篇文章的主题关系不大。</p>

<p>原文先按照第一性原理，尽量用原生 python 写了一遍，然后一步一步重构成接近生产环境的代码。这里我把顺序反过来，先放出重构之后的最终结果：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">pickle</span>
<span class="kn">import</span> <span class="n">gzip</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="n">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="n">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span><span class="n">DataLoader</span>

<span class="c1"># Using GPU
</span>
<span class="nf">print</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">())</span>
<span class="n">dev</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Wrapping DataLoader
# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html?highlight=dataloader
# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html?highlight=dataloader
</span>
<span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">dev</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">(</span>
        <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="nc">DataLoader</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">bs</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
    <span class="p">)</span>

<span class="k">class</span> <span class="nc">WrappedDataLoader</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dl</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dl</span> <span class="o">=</span> <span class="n">dl</span>
        <span class="n">self</span><span class="p">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">dl</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="nf">iter</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">dl</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
            <span class="nf">yield </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">func</span><span class="p">(</span><span class="o">*</span><span class="n">b</span><span class="p">))</span>

<span class="c1"># Define the neural network model to be trained
</span>
<span class="c1"># # If the model is simple:
# model = nn.Sequential(nn.Linear(784, 10))
</span>
<span class="c1"># generally the model is a class that inherites nn.Module and implements forward()
</span><span class="k">class</span> <span class="nc">Mnist_Logistic</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="c1"># self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))
</span>        <span class="c1"># self.bias = nn.Parameter(torch.zeros(10))
</span>        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">xb</span><span class="p">):</span>
        <span class="c1"># return xb @ self.weights + self.bias
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>

<span class="c1"># Define the training pipeline in fit()
</span>
<span class="k">def</span> <span class="nf">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">opt</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_func</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">opt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">opt</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="n">opt</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="nf">len</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
            <span class="nf">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>

        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">losses</span><span class="p">,</span> <span class="n">nums</span> <span class="o">=</span> <span class="nf">zip</span><span class="p">(</span>
                <span class="o">*</span><span class="p">[</span><span class="nf">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">multiply</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">nums</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span>

        <span class="nf">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">None</span>

<span class="c1"># __main()__:
</span>
<span class="c1"># data
</span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="sh">"</span><span class="s">data</span><span class="sh">"</span><span class="p">)</span>
<span class="n">PATH</span> <span class="o">=</span> <span class="n">DATA_PATH</span> <span class="o">/</span> <span class="sh">"</span><span class="s">mnist</span><span class="sh">"</span>

<span class="n">PATH</span><span class="p">.</span><span class="nf">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">URL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://github.com/pytorch/tutorials/raw/master/_static/</span><span class="sh">"</span>
<span class="n">FILENAME</span> <span class="o">=</span> <span class="sh">"</span><span class="s">mnist.pkl.gz</span><span class="sh">"</span>

<span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">exists</span><span class="p">():</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">URL</span> <span class="o">+</span> <span class="n">FILENAME</span><span class="p">).</span><span class="n">content</span>
        <span class="p">(</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">).</span><span class="nf">write</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
<span class="k">with</span> <span class="n">gzip</span><span class="p">.</span><span class="nf">open</span><span class="p">((</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">as_posix</span><span class="p">(),</span> <span class="sh">"</span><span class="s">rb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">latin-1</span><span class="sh">"</span><span class="p">)</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="n">train_dataloader</span><span class="p">,</span> <span class="n">valid_dataloader</span> <span class="o">=</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">)</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="nc">WrappedDataLoader</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">preprocess</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="nc">WrappedDataLoader</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">preprocess</span><span class="p">)</span>

<span class="c1"># hyperparameters/model
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span> <span class="c1"># loss function
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">Mnist_CNN</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span> <span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># training
</span><span class="nf">fit</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">valid_dataloader</span><span class="p">)</span>
</code></pre></div></div>

<p>可以看到，一个项目主干可以分成4部分：</p>

<ol>
  <li>准备数据</li>
  <li>定义模型</li>
  <li>描述流程</li>
  <li>实际运行</li>
</ol>

<p>下面把各部分拆分开来，把两种思路的代码进行对比。</p>

<h2 id="1-准备数据">1. 准备数据</h2>

<h3 id="重构之前">重构之前</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="sh">"</span><span class="s">data</span><span class="sh">"</span><span class="p">)</span>
<span class="n">PATH</span> <span class="o">=</span> <span class="n">DATA_PATH</span> <span class="o">/</span> <span class="sh">"</span><span class="s">mnist</span><span class="sh">"</span>

<span class="n">PATH</span><span class="p">.</span><span class="nf">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">URL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://github.com/pytorch/tutorials/raw/master/_static/</span><span class="sh">"</span>
<span class="n">FILENAME</span> <span class="o">=</span> <span class="sh">"</span><span class="s">mnist.pkl.gz</span><span class="sh">"</span>

<span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">exists</span><span class="p">():</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">URL</span> <span class="o">+</span> <span class="n">FILENAME</span><span class="p">).</span><span class="n">content</span>
        <span class="p">(</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">).</span><span class="nf">write</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
<span class="k">with</span> <span class="n">gzip</span><span class="p">.</span><span class="nf">open</span><span class="p">((</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">as_posix</span><span class="p">(),</span> <span class="sh">"</span><span class="s">rb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">latin-1</span><span class="sh">"</span><span class="p">)</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">n</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<h3 id="重构以后">重构以后：</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Wrapping DataLoader
# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html?highlight=dataloader
# https://pytorch.org/tutorials/beginner/data_loading_tutorial.html?highlight=dataloader
</span>
<span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="n">dev</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">(</span>
        <span class="nc">DataLoader</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">bs</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="nc">DataLoader</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">bs</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
    <span class="p">)</span>

<span class="k">class</span> <span class="nc">WrappedDataLoader</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dl</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">dl</span> <span class="o">=</span> <span class="n">dl</span>
        <span class="n">self</span><span class="p">.</span><span class="n">func</span> <span class="o">=</span> <span class="n">func</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">dl</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="n">batches</span> <span class="o">=</span> <span class="nf">iter</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">dl</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>
            <span class="nf">yield </span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">func</span><span class="p">(</span><span class="o">*</span><span class="n">b</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="2-定义模型">2. 定义模型</h2>

<h3 id="重构之前-1">重构之前</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">784</span><span class="p">)</span>
<span class="n">weights</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">()</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="p">.</span><span class="nf">exp</span><span class="p">().</span><span class="nf">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">log</span><span class="p">().</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">xb</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">log_softmax</span><span class="p">(</span><span class="n">xb</span> <span class="o">@</span> <span class="n">weights</span> <span class="o">+</span> <span class="n">bias</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">nll</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="nb">input</span><span class="p">[</span><span class="nf">range</span><span class="p">(</span><span class="n">target</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">target</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">nll</span>

<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="nf">return </span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">yb</span><span class="p">).</span><span class="nf">float</span><span class="p">().</span><span class="nf">mean</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="重构以后-1">重构以后</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># If the model is simple:
</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># generally the model is a class that inherites nn.Module and implements forward()
</span><span class="k">class</span> <span class="nc">Mnist_Logistic</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="c1"># self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))
</span>        <span class="c1"># self.bias = nn.Parameter(torch.zeros(10))
</span>        <span class="n">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">xb</span><span class="p">):</span>
        <span class="c1"># return xb @ self.weights + self.bias
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">lin</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>

</code></pre></div></div>

<h2 id="3-描述流程">3. 描述流程</h2>

<h3 id="重构之前-2">重构之前</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># learning rate
</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># how many epochs to train for
</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">((</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">bs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1">#         set_trace()
</span>        <span class="n">start_i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">bs</span>
        <span class="n">end_i</span> <span class="o">=</span> <span class="n">start_i</span> <span class="o">+</span> <span class="n">bs</span>
        <span class="n">xb</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">end_i</span><span class="p">]</span>
        <span class="n">yb</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">end_i</span><span class="p">]</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_func</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>

        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">weights</span> <span class="o">-=</span> <span class="n">weights</span><span class="p">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span>
            <span class="n">bias</span> <span class="o">-=</span> <span class="n">bias</span><span class="p">.</span><span class="n">grad</span> <span class="o">*</span> <span class="n">lr</span>
            <span class="n">weights</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>
            <span class="n">bias</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="nf">zero_</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="重构以后-2">重构以后</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">def</span> <span class="nf">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">opt</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_func</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">opt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">opt</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="n">opt</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">(),</span> <span class="nf">len</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
            <span class="nf">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>

        <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">losses</span><span class="p">,</span> <span class="n">nums</span> <span class="o">=</span> <span class="nf">zip</span><span class="p">(</span>
                <span class="o">*</span><span class="p">[</span><span class="nf">loss_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">multiply</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">nums</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span>

        <span class="nf">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">None</span>
</code></pre></div></div>

<h2 id="4-实际运行">4. 实际运行</h2>

<h3 id="重构之前-3">重构之前</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># __main()__:
</span><span class="nf">print</span><span class="p">(</span><span class="nf">loss_func</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">),</span> <span class="nf">accuracy</span><span class="p">(</span><span class="nf">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="重构以后-3">重构以后</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># __main()__:
</span>
<span class="c1"># data
</span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="sh">"</span><span class="s">data</span><span class="sh">"</span><span class="p">)</span>
<span class="n">PATH</span> <span class="o">=</span> <span class="n">DATA_PATH</span> <span class="o">/</span> <span class="sh">"</span><span class="s">mnist</span><span class="sh">"</span>

<span class="n">PATH</span><span class="p">.</span><span class="nf">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">URL</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://github.com/pytorch/tutorials/raw/master/_static/</span><span class="sh">"</span>
<span class="n">FILENAME</span> <span class="o">=</span> <span class="sh">"</span><span class="s">mnist.pkl.gz</span><span class="sh">"</span>

<span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">exists</span><span class="p">():</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">URL</span> <span class="o">+</span> <span class="n">FILENAME</span><span class="p">).</span><span class="n">content</span>
        <span class="p">(</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">wb</span><span class="sh">"</span><span class="p">).</span><span class="nf">write</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
<span class="k">with</span> <span class="n">gzip</span><span class="p">.</span><span class="nf">open</span><span class="p">((</span><span class="n">PATH</span> <span class="o">/</span> <span class="n">FILENAME</span><span class="p">).</span><span class="nf">as_posix</span><span class="p">(),</span> <span class="sh">"</span><span class="s">rb</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">latin-1</span><span class="sh">"</span><span class="p">)</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">,</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="n">train_dataloader</span><span class="p">,</span> <span class="n">valid_dataloader</span> <span class="o">=</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">,</span> <span class="n">bs</span><span class="p">)</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="nc">WrappedDataLoader</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">preprocess</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="nc">WrappedDataLoader</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">preprocess</span><span class="p">)</span>

<span class="c1"># hyperparameters/model
</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span> <span class="c1"># loss function
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">Mnist_CNN</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span> <span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># training
</span><span class="nf">fit</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">valid_dataloader</span><span class="p">)</span>
</code></pre></div></div>
    
        </main>
        <div class="giscus" style="margin-bottom: 2em;"><script src="https://giscus.app/client.js"
        data-repo="MountAye/comments"
        data-repo-id="R_kgDOJe4FmQ"
        data-category="BLOG"
        data-category-id="DIC_kwDOJe4Fmc4CWQuC"
        data-mapping="title"
        data-strict="1"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-input-position="bottom"
        data-theme="light"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
</script></div>
        <div><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1920275466226790"
     crossorigin="anonymous"></script>
<!-- blog-header -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-1920275466226790"
     data-ad-slot="4291489170"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script></div>
      </div>
      <aside id="right" class="layout-right">
        <div id="toc-side-container" class="right-toc">
          <div class="overflow-y">
            <div id="toc-side">
              <div class="fade-out-right"></div>
            </div>
          </div>
          <div class="fade-out-bottom"></div>
        </div>
        <div class="right-navbar">
          <a class="right-nav-button" href="https://mountaye.github.io/blog/history">
            <span class="material-symbols-outlined">calendar_month</span>
            <span class="right-nav-text">日期归档</span>
          </a>
          <a class="right-nav-button" href="https://mountaye.github.io/blog/topics" >
            <span class="material-symbols-outlined">bookmarks</span>
            <span class="right-nav-text">话题归档</span>
          </a>
          <a class="right-nav-button" href="/blog/articles/what-a-PyTorch-project-looks-like">
            <span class="material-symbols-outlined">language_pinyin</span>
            <span class="right-nav-text">简体中文</span>
          </a>
          <a class="right-nav-button" href="/blog/en/articles/what-a-PyTorch-project-looks-like">
            <span class="material-symbols-outlined">language_us</span>
            <span class="right-nav-text">English</span>
          </a>
        </div>
      </aside>
      <!--  -->
    </div>
    <footer id="nav-mobile">
      <a class="nav-mobile-item" href="https://mountaye.github.io/blog/history">
        <span class="material-symbols-outlined">calendar_month</span>
      </a>
      <a class="nav-mobile-item" href="https://mountaye.github.io/blog/topics" >
        <span class="material-symbols-outlined">bookmarks</span>
      </a>
      <a class="nav-mobile-item" href="https://mountaye.github.io/blog/"><div class="nav-mobile-avatar"></div></a>
      <a class="nav-mobile-item" href="/blog/articles/what-a-PyTorch-project-looks-like">
        <span class="material-symbols-outlined">language_pinyin</span>
      </a>
      <a class="nav-mobile-item" href="/blog/en/articles/what-a-PyTorch-project-looks-like">
        <span class="material-symbols-outlined">language_us</span>
      </a>
    </footer>
  </body>
</html>