<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-CN"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://mountaye.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mountaye.github.io/blog/" rel="alternate" type="text/html" hreflang="zh-CN" /><updated>2024-06-06T00:04:26-05:00</updated><id>https://mountaye.github.io/blog/feed.xml</id><author><name>MountAye</name></author><entry><title type="html">.pdf | 芥川赏作品·杨逸《時が滲む朝》</title><link href="https://mountaye.github.io/blog/articles/yang-yi-novel-about-tiananmen-square-protest" rel="alternate" type="text/html" title=".pdf | 芥川赏作品·杨逸《時が滲む朝》" /><published>2024-06-04T00:00:00-05:00</published><updated>2024-06-04T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/yang-yi-novel-about-tiananmen-square-protest</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/yang-yi-novel-about-tiananmen-square-protest"><![CDATA[<p>早听说有在日本的华人作家以六四事件为题材写了一篇小说，获得了日本文学界的一个很有分量的奖项。</p>

<p>通过推特上的只言片语，得知谈论的作品应该是作家杨逸的小说《時が滲む朝》。标题直译为“浸透了时光的早晨”。</p>

<p><del>这本书没有用中文出版，</del>这本书有一本台湾出版的中译本《时光浸染》，但是我没有 <del>找</del> 买到。花了大约一周的时间，边读日语本边翻译了一下。我不懂日语，所谓翻译，就是：</p>

<ul>
  <li>把几个自然段复制粘贴到翻译软件中，然后把结果复制粘贴回来；</li>
  <li>把两种语言并列排版；</li>
  <li>根据汉语语感，把明显不通顺的句子改写了一下；</li>
  <li>把本不需要翻译的汉语诗句和人名换回原文。</li>
</ul>

<p>时间仓促，可能有些人名仍未纠正，比如“梁浩远”就经常被误译为“浩源”“弘人”，“大雄”误译为“黛玉”，“民生”误译为“民夫”，“英露”误译为英国和俄国……</p>

<hr />

<p>我不懂日语，用翻译软件一段一段地读，原文看起来经常有省略主语的语法现象，所以不好判断原文究竟是用第一人称还是第三人称来写作。但无论哪种情况，文章很明显是梁浩远一人的视角，其心友谢志强占据了不少篇幅，但并非双线叙事。</p>

<p>故事从1988年主人公高考开始，两人从黄土高原的农村，考入了西部某省会的大学，学习文学专业。两人认识且爱上了同一个女同学。</p>

<p>在大学，受到老师甘先生的教育，和中国传统的“天下兴亡，匹夫有责”精神的感召，在 89 年学潮中先是参与了在省会的集会活动，后坐火车前往天安门，返校后一段时间才发生中国人民解放军的清场。</p>

<p>主角一行人因为六四遭受的迫害并非直接来自官方对运动的清算，而是在校外饭馆喝酒时，因为与一般市民对运动的理解不同，产生争吵，进而恶化成斗殴，因此被公安机关拘留，被学校开除。</p>

<p>主角前往海外的原因和六四无关，近乎天降巧合：主角的邻居中，有抗战胜利后遗留在中国的日侨，改革开放后返回日本。女儿回日本之后不能适应当地的文化，转学回来寄宿在主角的妹妹处，与主人公产生感情，两人结婚后一并赴日，过程一笔带过。</p>

<p>在海外的时间所占的篇幅不大，情节也不多。略写了海外反共组织之松散，对当地社会几乎没有声量，成员参加活动的目的主要是申请政治庇护签证，组织者有的爱财逐利，有的偏执专断。</p>

<p>故事到2001年北京申奥成功那年结束。妻子不再支持主人公在妻弟的餐厅里张贴反共海报，主人公得知了心友、老师、暗恋的女同学的下落，并且还和他们在日本见了面，回忆了往事，送别他们离开，接受了现实。</p>

<hr />

<p>作者的写作相当克制。</p>

<p>几乎没有使用倒叙插叙等时间剪辑手段，中间的情节按照时间顺序平铺直叙，每一部分所占篇幅都很平均。而且全文基本只作记叙和描写，不见抒情和议论。</p>

<p>虽无抒情，但是通过对让人产生情感的情节进行记叙，画面进行描写，使读者与主人公共情。通过消除作者在作品中的存在，尽力体现历史现实和个人命运本身的力量。</p>

<p>只采用一个人的视角，而且是一个平凡人物的视角，在当代文学天然有胜过英雄视角的道德高度。</p>

<p>而且也从侧面表现了这场运动空间范围上的广泛，不只限于北京等大城市；社会阶层参与的广泛，普通市民给学生送饭送大衣，并非只是少数精英大学生的表演，所谓境外敌对势力的煽动更非主要因素。</p>

<hr />

<p>但是，如果说作品有什么问题，那也源自于作者选择的视角。</p>

<p>以一名平凡人物为中心，就没办法介绍六四事件的起因，以“反贪污，反腐败”的简单口号动员起来的政治运动，为什么能够得到全国人民的响应，从书中得不到线索，来的莫名其妙，甚至连“反官倒”的口号在文中都没有出现。</p>

<p>主角团的退学并不明显来自于官方的报复，虽然退学的原因表现了学生运动与人民群众的脱节，但是这种情节安排缺乏对中共秋后算账的描写。</p>

<p>主角去国靠的是跨国婚姻，在文学上的巧合性强而典型性弱，而原文对此的伏笔与描写太少，以至于显得突兀。</p>

<p>这些情节设定本不应该成为批评的对象，因为在一个重大历史事件里，个例的巧合和不全面，无法反映历史的全貌，不仅是正常的，甚至可以说是客观描写下的唯一合理结果。当社会可以对这一事件普遍公开讨论之后，众多不全面的个例统计在一起，自然能让后人近似得到全面的认识。</p>

<p>但是现实是，时至 35 年后的今日，当局对此事依然如临大敌，在其执政范围内，对这一话题的讨论不普遍，不开放。身为在海外的华人，面对文学小说这样一个允许艺术创作的体裁，在有大量一手史料的环境里，稍微多花一点精力就可以在文学真实和情节全面之间取得平衡的情况下，选择对一个不完美素材作此白描，略显可惜。</p>

<hr />

<p>作者将故事结局定格在了 2001 年，也就是北京申奥成功的那年，而作品写于 2008 年，也就是北京奥运当年，两者都是中华人民共和国政府声望的里程碑。无怪乎文章最后悲情无奈地与现实“和解”。</p>

<p>真的能和解吗？</p>

<p>尽管运动的参与者不可能每人都熟知政治哲学理论，但民众的不满其来有自……[待续]</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[早听说有在日本的华人作家以六四事件为题材写了一篇小说，获得了日本文学界的一个很有分量的奖项。]]></summary></entry><entry><title type="html">.doc | 参加毕业典礼</title><link href="https://mountaye.github.io/blog/articles/doc-graduation-ceremony" rel="alternate" type="text/html" title=".doc | 参加毕业典礼" /><published>2024-05-26T00:00:00-05:00</published><updated>2024-05-26T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/doc-graduation-ceremony</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/doc-graduation-ceremony"><![CDATA[<blockquote>
  <p>写点尬的，先来首高雅音乐～</p>

</blockquote>

<p>【爱江山更爱美人.mp3】</p>

<p>美国的冬春学期五月份就结束了，毕业典礼中的 hooding ceremony 一般在此学期的最后一个周五，commencement 在接下来的周一。</p>

<p>我早就毕业了，但是答辩的时候刚刚过了毕业典礼的日期没多久。毕业之后回了一趟家，然后返回原实验室做博士后。</p>

<hr />

<p>今年春天，我们研究方向的师生每周茶聚的时候，我们老板盛赞我选择下一年的春天参加毕业典礼是个明智的选择，毕竟冬学期的活动太冷清了，都没有人重视。</p>

<p>当时我的面部肌肉稍微拉起来一个微笑，没有接话。</p>

<p>这是在提醒我，他可没有忘，所以请我也不要忘了报名今年的毕业典礼哟～</p>

<p>刚入学的时候，我觉得我们老板怎么这么水，数学水编程也水，就这还是两校出来的学生？现在的我真心地除了佩服还是佩服，我们老板不论安排什么任务，还是讲什么知识，说起来都笑吟吟的，我认识他六年有余了，从来没见他红过脸——这个世界如此地混沌，他却能微笑着一句话，剪断一个将来可能有无限枝叶的世界线分叉——那还有多少事，多少人的“自由意志”，都包含在他的自由意志之中呢？</p>

<hr />

<p>说第二年参加毕业仪式是一种“选择”，是因为至少还有两种做法：1. 答辩之前就参加当年的活动，我们组比我高一级的学姐就是这么干的；2. 毕业之后的冬季学期结束的时候还有一次 hooding ceremony, HK 兄弟就是这么干的。</p>

<p>两种做法我都没有选，因为我本来完全不打算参加任何毕业活动的。</p>

<p>毕竟对于迂腐的小知识分子，一个行为能带来的世俗荣誉感越大，做了就越庸俗，拒绝就越优雅～</p>

<p>我们本科的毕业纪念册上，居然有一个文本框要填什么“所获荣誉”，简直是人心不古世风日下，于是咱仗义执言：“物理学院院内足球联赛亚军；BiliBili 放映室写评论赢电影票活动获奖观众”——优雅，实在是太优雅了.gif</p>

<p><img src="https://syimg.3dmgame.com/uploadimg/xiaz/2022/0607/1654566377264.gif" alt="https://syimg.3dmgame.com/uploadimg/xiaz/2022/0607/1654566377264.gif" /></p>

<p>纪念册打印出来之后我一看，律神的第一行写着“珠峰物理实验班第一学年平均分数第一名”。律神是名副其实的大学霸，大一的时候专业课都接近满分。我只是个 90 分飘过的混子，而体育课思政课之类的我又碰巧分数比他高，算 GPA 的话居然比他还高了一点点。大一下学期的电磁学期末考试实在是太简单，直接把他气到在群里@老师，大二转学到了数学班。</p>

<p><del>对了，数学班的班花毕业纪念册好像写得也很优雅。我自己其实真无所谓，但我有个朋友真的很想知道一下人家的联系方式。</del></p>

<hr />

<p>出来混总是要还的嘛。</p>

<p>仗着成绩不错，在外校选修了拓扑学，尼玛人话都听不懂多少，就要去理解紧致啊同伦啊这些概念，这回 GPA 真的下来了。而且在外校的一个学期 <del>让喜欢的女孩子终于好意思拒绝了我的纠缠</del> 打断了之前在本校的研究进度，回来之后又去了一个完全不同的课题组混经验，到毕业也没混出什么名堂。</p>

<p>寄出去 19 封申请信，只回来 2.5 份录取通知书，那半份硕士录取的老师还发邮件催了好几次，意思是硕士录取就已经很给我面子了，不要不识好歹哟～</p>

<p>来到博士学校，才知道这份 offer 是因为和我同年招聘来了一个新老师，系里估计他需要学生，就把申请信里说对这个方向有兴趣的我给捞进来了。</p>

<p>来了之后我依然笑嘻嘻地在混，但是研究方向的不确定性，技术路线能不能走通都不好说，更别说知道能做出什么结论，结论的科学意义有多大了。</p>

<p>最焦虑的时候，我背着书包回家，包还在背后往床上一躺就睡着了，然后一个实验失败的噩梦又把我给惊醒，起身时屋内漆黑，窗外华灯初上。</p>

<p>确定答辩日期之后，其实是可以提前报名当年的毕业典礼的，但是我实在是怕给自己立 flag，觉得干脆就不参加典礼了更好，跟家里也是这么说的。</p>

<p>结果下半年， 比我晚入学两年的老乡 HK 兄弟毕业了，朋友圈发了很帅气的照片。这回破防的是我了，“富贵不发朋友圈，如锦衣夜行，谁知之者！”老板提了一嘴我就报名了。</p>

<hr />

<p>大三的时候，物理学院出钱，让我们班三个同学去美国一所学校做一个学期的访问学生。外校的新生报到时，我们刚进大厅，身前不远有一家三口，小姑娘转身面向爸爸妈妈，笑着说她要去排队咯，然后又转身，金发单马尾一蹦一跳地往前跑去了。确定她走远后，妈妈倒在了爸爸的怀中，眼中泪水不住地流。</p>

<p>然后我们几个相视一笑，就这？我们坐了快二十个小时的飞机，天没亮在麦当劳眯了好几个小时再过来，你们开了几个小时的车就感动成这样？</p>

<p>后来我觉得当年的自己真幼稚。人生道阻且长，怎能不抓紧一切可庆祝的机会去庆祝，给自己加油打气，说服自己正走在正确的方向呢？</p>

<p>现在我觉得当年觉得自己真幼稚的自己真幼稚。稍微没品且无自觉了一点，但当时的我们，其实也是在给自己打气啊。</p>

<p>【Fear brought me this far.mp3】</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[写点尬的，先来首高雅音乐～]]></summary></entry><entry><title type="html">.txt | 参加毕业典礼</title><link href="https://mountaye.github.io/blog/articles/txt-graduation-ceremony" rel="alternate" type="text/html" title=".txt | 参加毕业典礼" /><published>2024-05-26T00:00:00-05:00</published><updated>2024-05-26T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/txt-graduation-ceremony</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/txt-graduation-ceremony"><![CDATA[<blockquote>
  <p>今日发布的另一文，是写同一件事的姊妹篇。</p>

</blockquote>

<p>【Fear brought me this far.mp3】</p>

<p>美国的冬春学期五月份就结束了，毕业典礼中的 hooding ceremony 一般在此学期的最后一个周五，commencement 在接下来的周一。</p>

<p>我早就毕业了，但是答辩的时候刚刚过了毕业典礼的日期没多久，所以今年才参加毕业典礼。毕业之后回了一趟家，然后返回原实验室做博士后。</p>

<p>今年春天，我们研究方向的师生每周茶聚的时候，我们老板盛赞我选择下一年的春天参加毕业仪式，毕竟冬学期的活动太冷清了，都没有人重视——真是个机智的选择。</p>

<p>当时我的面部肌肉稍微拉起来一个微笑，没有接话。</p>

<hr />

<p>典礼之前气氛凝重。</p>

<p>去年10月份，驻在且主宰巴勒斯町 (Palestine) 之加沙地带的哈马斯组织突击以色列，随后以色列动员正规军反击。（我在博客上做了<a href="/blog/articles/war-in-2023-between-hamas-and-israel">新闻剪报。</a>）局势发展到典礼前两周的周五，包含本校学生在内的人群，要声援“巴勒斯坦 (Palestinian) 人民”，反对购买了美国军火的以色列进行“种族灭绝 (genocide)”，在学校扎帐篷、静坐、抗议。</p>

<p>典礼前两周的周六深夜，校内所有建筑上锁，警察以侵犯私有地产 (trespassing) 为名警告，后扫荡逮捕了空地上拒绝离去的人群，有人受伤，有人被控拒捕和袭警，有人指控暴力执法。</p>

<p>典礼前一周的周四深夜到周五凌晨，一夜之间，校方围绕校园一圈，以及在校内部分建筑之间，搭起了钢管作边框的预制栅栏，栅栏的底座钉在水泥地上，之间用铁皮绑住，尽头钉在建筑的墙上，只在个别位置留下专人把守的路口，下班时间门将走后上锁。</p>

<p>不过物理系正好位于这个铁网迷宫的一个拓扑范畴边界上，即使下班时间也可以从不同的门去往不同的路径同伦 (path homotopy) 等价类，算是影响不大。</p>

<hr />

<p>典礼前的周四上午，物理系年例集体合照，拍完照片去取预租的学位袍。一套衣服租需要 $90，嫌贵？买或者租而不还的话 $900，不穿参加不了典礼哟～</p>

<p>取衣服的位置在学校书店地下一层，看到队伍已经拍到一楼门口了，心里咯噔一下子。好在美国人排队的平均自由程比国内大不少，每个人在自己位置上跍踊的热运动温度也比较低，所以队伍排起来也不算压抑。问清楚了还衣服的时间和地点。</p>

<p>美国的学位袍是各校自己定的样式，连颜色都没有本黑硕蓝博红的规定。来这里的第一个寒假前，看到冬天毕业的学生都穿着土褐色的袍子，霍格沃茨里面最没有特点的赫奇帕奇的专属色，真想退学重新申请，唉，沉没成本啊沉没成本……</p>

<p>装学位服的袋子里有一帽子，一袍子，还有一扁三角形布料，应该是就是 hood。这个词的本意是兜帽，此处展开后前端是一个类似于 <del>JK制服</del> 水手服的三角形领子，后半截确实可以被理解成兜帽，但是长度够垂到大髀，估计没人想套头上。</p>

<p>Hooding 就是由导师把这个大领子套到学生身上，类似于国内的拨穗。所以邮件里才要求博士生集合的时候不要自己把领子穿上了。</p>

<hr />

<p>周四晚上睡不着，于是去校园里散步，顺便听秦晖先生的油管视频。自从养成散步的习惯以来，已经在校园里摸索出一条路线，可以全程户外的同时校园 WiFi 也不掉线，省流量。视频在全屏模式下，按电源键关掉屏幕，然后立即抬起屏幕点继续播放，可以熄屏且免广告。</p>

<p>很多学生呼朋引伴在校园里，大家都穿便服，毕业周也是期末考试周，可能既有毕业生也有觉得考试是件大事的屁孩。大家几人十几人一群庆祝和发泄，做一些平时不敢做的事，美其名曰创造回忆。</p>

<p>比如有一男生在中央草坪边一座亮黄色消防栓旁边酝酿半天，半蹲半跪，我经过之后，他身旁的朋友发出一阵欢呼。我什么也没有闻到。</p>

<p>比如有一女生坐在法学院门廊旁边的亮黄色消防栓上，我经过之后，她身旁的朋友发出一阵欢呼。除此以外我什么也没有看到。</p>

<p>比如有一群学生，在中央草坪一角的大树下，和我打照面经过，举起手里的易拉罐畅饮。我没看清易拉罐是何种饮料之容器。</p>

<hr />

<p>周五是 hooding ceremony 的正日子。早上穿便服去学校假装工作一上午，中午系里有烤肉自助，吃完回家换衬衫正装裤子和鞋，毕竟穿一天实在是太热了。</p>

<p>本来答辩的时候也想这么穿的，结果写论文期间吃饭不太克制，答辩那天早晨发现胖得裤子穿不上了。现在减肥初见成效，很高兴。</p>

<p>换衬衫回来之后赶紧去卫生间看打领带的教学视频，勉强赶在集合时间之前打好了。</p>

<p>学姐也赶回来参加庆祝活动，在我办公桌上放了一束花。</p>

<p>然后我们系的老师和同学一起往准备厅走。我老板也穿戴好了。 陈郝问他的学位袍是 H 家的还是 M 家的，我老板答曰 Amazon 家的——我们之前闲聊的时候说到学位袍很贵的事，陈郝一本正经地给我科普，如果留在学界的话，一般都是买本校的袍子将来正式场合一直穿的——这都让我知道你不懂装懂了～</p>

<p>在准备厅门口，让我们扫二维码填表，好让学校请的摄影师根据信息把照片发给我们。准备厅内签到，拿到自己预先填好的名片，学院的头儿问清楚每个人名字的读音，用笔在名字卡的读音位置补充标记。然后按导师的名字排队。</p>

<p>离开准备厅前往礼堂。整队很快，在路上等了一会。没话找话，我问我们老板最喜欢的球队是哪只，他说巴黎圣日尔曼，卧槽我不该问的，他问我，我只能照实答多特蒙德，然后他开始说奇怪的话，什么门柱啊运气啊，啊对对对，祝你们下赛季走得更远好吧……</p>

<p>进入堂内，先进去的家长们举着手机录视频拍照；落座后放音乐，原来管风琴是摆设；讲台后面的彩色玻璃很好看；老板问我们之前来没来过，我说维尔切克的讲座好像在这里，也可能是我记错了。</p>

<p>各种讲话，每人的讲稿倒都不长，校友代表是文学男博士，成就是创业写了个给图书馆使用的 APP；毕业生代表是生化女博士，丈夫是神父，说在这里讲话让她感受到了他工作的不易和家庭的重要。</p>

<p>然后依次上台，院长念名字，导师站上祭台，学生站在台前，挂上领子，和校教务长握手，合影，下台，拿一个毕业证书摆拍大头照，回座位。</p>

<p>仪式结束后，外面的院子里准备了酒水和零食。我和老板匆匆吃了两大盘，然后赶回系里，师妹上午通过了博士资格考试，我们回去之后开了一瓶香槟给她庆祝，然后闲聊胡扯。我们老板非常得意地发表了他对于为什么要按老师而不是学生名字排队的归因。</p>

<p>晚上，庆祝毕业的同学们一起去了一家中餐馆吃饭。老外们一个两个都在点地道中餐，于是我点了一个蜜汁核桃虾仁。</p>

<hr />

<p>周六穿着袍子和一起毕业的硕士学弟还有他妈妈一起，在校园里拍照。啊，妈妈不在身边的孩子像根草～</p>

<hr />

<p>周日搬家，新家远，需骑自行车上学，且是丘陵坡路。</p>

<hr />

<p>周一早晨 commencement，来学校的路上经过操场边，有抗议人群站在栅栏外举巴勒斯坦旗和标语牌示威。本来 commencement 还打算参加一下的，但是骑车过来实在是太累了，于是没去，中午时间到了就把袍子还回去了。</p>

<p>Commencement 结束后 <del>大宴群臣</del>，非毕业生对毕业最有实感的活动才开始：吃。校园里各处已经搭好了棚子，每个棚子有一家本地的餐厅在不限量供应食品，有韩式墨西哥菜、珍珠奶茶、烤肉三明治、冰淇淋、可乐……</p>

<p>不想喝可乐的话，也有白水。每个亮黄色的消防栓接出来一根银白色的金属装置，然后连到一个蓝色大水桶，桶底有水龙头可以接水喝。</p>

<p>你们谁爱喝谁喝，我反正不喝。</p>

<p><img src="/blog/assets/photos/2024-05-26-legal-high-SP.png" alt="" /></p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[今日发布的另一文，是写同一件事的姊妹篇。]]></summary></entry><entry><title type="html">.tex | 比较两个概率分布/两条信息</title><link href="https://mountaye.github.io/blog/articles/information-entropy-kl-divergence-cross-entropy-mutual-information" rel="alternate" type="text/html" title=".tex | 比较两个概率分布/两条信息" /><published>2024-05-14T00:00:00-05:00</published><updated>2024-05-14T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/information-entropy-kl-divergence-cross-entropy-mutual-information</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/information-entropy-kl-divergence-cross-entropy-mutual-information"><![CDATA[<blockquote>
  <p>自鸣得意了半天，发现这篇文章基本就是维基百科 <a href="https://en.wikipedia.org/wiki/Quantities_of_information">Quantities of Information</a> 词条英文版的翻译。但是对应的中文词条没有覆盖英文版那么多的内容，所以也不完全是无用功。</p>

</blockquote>

<h2 id="信息和概率">信息和概率</h2>

<p>一条信息由一个命题来表达。（这一个命题可以是对多个命题进行逻辑演算的一个表达式。）</p>

<p>而这个命题解答了人心中的某个疑问。既然这是个疑问，那么在得到确切的信息之前，有众多其他命题，和这条消息一样有可能是问题的答案。既然是有可能，那就是概率论可以派上用场的对方。所有这些可能成为答案的命题一起，构成一个随机变量空间。</p>

<p>比如说一道有 ABCD 四个选项的选择题，如果是单选题，那么答案的随机变量空间就是 {A, B, C, D}，如果是多选题，则是 {A, B, C, D, AB, AC, AD, BC, BD, CD, ABC, ABD, ACD, BCD, ABCD}，如果是排序题、不定项排序题、答案出错了的题……</p>

<h2 id="描述一个概率分布的信息量">描述一个概率分布的信息量</h2>

<h3 id="自信息self-information">自信息：Self Information</h3>

<p>自信息是一个随机事件的性质，也就是针对一个随机变量的<strong>某一个可能取值</strong>而言的。表达式为</p>

\[I(m) = -\log_n\left(p(M=m)\right)\]

<p>这是一个无量纲量，但是公式中指数的底数可以任意选择——</p>

<ul>
  <li><em>n</em> = 2 的时候自信息的单位是 bit，也叫香农 (shannon), 这里的 bit 和二进制位 bit 不完全相同，一个香农是一个二进制位所能表示信息的<strong>上限</strong>：当一个二进制位完全取决于其它位时，这个位不包含任何额外信息，香农数为 0，但这个二进制位依然物理上存在；</li>
  <li><em>n</em> = <em>e</em> 的时候单位是 nat, 因为 \(\log_e\equiv\ln\) 叫做自然对数；</li>
  <li><em>n</em> = 10 的时候单位叫 hartley</li>
</ul>

<p>——单位之间的换算关系由对数的换底公式给出。</p>

<p>这个量在信息论中的意义是，这条消息作为一个不方便问的问题的<strong>答案</strong>，<strong>最少可以</strong>用多少个 n 个选项的单选题套出答案。当 n=2 的时候，每个问题就是一个是非题，也就是一般疑问句。</p>

<p>码农面试的时候经常问一类问题：一堆看起来相同的东西里面有一个不一样，你有一种不能直接测出答案的测量工具，最少需要测量几次才能辨别出来……但是自信息的计算不能提供具体的辨别方法，具体方法还是需要你自己去凑，而面试刷人很多都是在刷这种细枝末节。</p>

<p>当然了，前提是你的面试官懂他自己在问什么，而不是相信美剧《硅谷》里压缩算法可以突破信息论极限的计算机民科～</p>

<p>当 <em>p</em> = 0 时，自信息发散为无穷大。不过问题不大，原因在下一节。</p>

<h3 id="信息熵entropy">信息熵：Entropy</h3>

<p>信息熵是一个随机变量的概率分布的整体性质。</p>

<p>算法很简单，就是自信息的概率期望，也就是按照随机变量每个取值的概率加权平均：</p>

\[S(p(M))=\mathbb{E}_p[-\log_n p(M)]=-\sum_{m\in M}p(m)\log_n p(m)\]

<p>当 <em>p</em> = 0 时，自信息发散，但是概率为零，强行定义两者的积也为零，对信息熵不构成贡献。</p>

<p>当我们只对某一特定的随机事件信息感兴趣，除此以外的所有事件合并为目标事件的补集，就得到二项信息熵 binary entropy:</p>

\[S_{binary} = -(1-p)\log(1-p)-p\log p = p\log\frac{1-p}{p}-\log(1-p)\]

<p>沿着自信息的意义往下走，信息熵在信息论中的意义是，一个将众多信息/命题的集合作为备选答案的<strong>问题</strong>，<strong>最少可以</strong>用多少道 n 个选项的单选题的集合来等价替代。</p>

<p>当这些最优的单选题确定之后，原问题的每一个选项，可以用单选题的答案序号来进行编码。指数的不同底数/信息量的不同单位就是数字的 n 进制，信息量就是相应进制下最大压缩编码后的位数。</p>

<p>当然要讨论压缩的话，还需要另找地方记录各个单选题和选项，也就是压缩字典。</p>

<h2 id="比较两个概率分布的信息量">比较两个概率分布的信息量</h2>

<p>而如何选择单选题，使之成为针对给定问题最优的问题集，会因为各个选项概率分布的不同而变化。即便是同一组信息/备选答案，两套不同的概率分布，各自会给出一套对自己最优的问题集，一套概率分布下的最优问题集不见得是另外一套概率分布下的最优问题集。</p>

<blockquote>
  <p>下面的表达式都只写出了离散变量的形式，连续随机变量需要将求和写成对应的积分。</p>

</blockquote>

<h3 id="相对熵kullbackleibler-k-l-divergence">相对熵：Kullback–Leibler (K-L) Divergence</h3>

<p>英文里也叫 relative entropy 或者 I-divergence</p>

<p>这里的两个概率分布映射自<strong>同一个</strong>随机变量空间。</p>

\[D_{KL}(p(X)|q(X))=\sum_{x\in X}p(x)\log\frac{p(x)}{q(x)}=-\sum_{x\in X}p(x)\log\frac{q(x)}{p(x)}\]

<p>这个量描述了当 <em>p</em>(<em>X</em>) 作为各选项的正确概率分布的情况下，用对 <em>q</em>(<em>X</em>) 最优的单选题去提问，<strong>没问出来的信息</strong>所需要的<strong>额外的</strong>单选题数目/编码数。</p>

<p>在科学应用中，<em>p</em>(<em>X</em>) 一般是从实验中测量出来的概率分布，<em>q</em>(<em>X</em>) 是理论模型的预测。</p>

<p>下面的例子计算了一个单选题，选 C、选 B、假想中一群学生的答案统计、胡猜四种概率分布 <em>p, q ,r , φ</em> 之间的 KL divergence。因为概率为零会出现发散问题，所以我们取 eps = 10^(-10) 把这些概率值截断：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">kl_div</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">eps</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">eps</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">eps</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">q</span><span class="p">,</span><span class="n">eps</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">eps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">p</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">log2</span><span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="n">q</span><span class="p">))</span>

<span class="n">p</span>   <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span>  <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>   <span class="mi">0</span><span class="p">])</span>
<span class="n">q</span>   <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span>  <span class="mi">0</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">])</span>
<span class="n">r</span>   <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="o">/</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">6</span><span class="p">])</span>
<span class="n">phi</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">4</span><span class="p">])</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">empty</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">v1</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">([</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">phi</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">v2</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">([</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">phi</span><span class="p">]):</span>
        <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nf">kl_div</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="n">v2</span><span class="p">)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>KL-div(行, 列)/bit</th>
      <th>p</th>
      <th>q</th>
      <th>r</th>
      <th>φ</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>p = [0,0,1,0]</td>
      <td>0</td>
      <td>33.219</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>q = [0,1,0,0]</td>
      <td>33.219</td>
      <td>0</td>
      <td>2.585</td>
      <td>2</td>
    </tr>
    <tr>
      <td>r = [1/6, 1/6, 1/2, 1/6]</td>
      <td>14.817</td>
      <td>25.890</td>
      <td>0</td>
      <td>0.208</td>
    </tr>
    <tr>
      <td>φ = [1/4,1/4,1/4,1/4]</td>
      <td>22.914</td>
      <td>22.914</td>
      <td>0.189</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>从结果中我们可以看到：</p>

<ul>
  <li>对角线为 0，符合其意义。</li>
  <li>\(D_{KL}(p,q)\) 和 \(D_{KL}(q,p)\) 都应该是 +∞，这里的有限值是 eps 截断的结果</li>
  <li>除个别巧合，对称位置的值一般不相等。这个量不同于两点之间的距离。</li>
</ul>

<h3 id="交叉熵cross-entropy">交叉熵：Cross Entropy</h3>

<p>这里的两个概率分布映射自<strong>同一个</strong>随机变量空间 X。</p>

<p>概率分布 <strong><em>q</em> 相对于 <em>p</em></strong> 的交叉熵 cross entropy</p>

\[CE(p(X),q(X))=-\sum_{x\in X}p(x)\log q(x)=S(p(X))+D_{KL}(p(X)|q(X))\]

<p>这个量描述了当 <em>p</em>(<em>X</em>) 作为各选项的正确概率分布的情况下，用对 <em>q</em>(<em>X</em>) 最优的单选题去提问，所需要的<strong>总共的</strong>单选题数目/编码数。</p>

<p>类似于二项熵，<em>p</em> 和 <em>q</em> 之间的 binary cross entropy:</p>

\[BCE(p,q)=-p\log q-(1-p)\log(1-q)=p\log\frac{1-q}{q}-\log(1-q)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">eps</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">eps</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">eps</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">q</span><span class="p">,</span><span class="n">eps</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">eps</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">p</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">log2</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">empty</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">v1</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">([</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">phi</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span><span class="n">v2</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">([</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">,</span><span class="n">r</span><span class="p">,</span><span class="n">phi</span><span class="p">]):</span>
        <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="n">v2</span><span class="p">)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>Cross Entropy(行, 列)/bit</th>
      <th>p</th>
      <th>q</th>
      <th>r</th>
      <th>\(\varphi\)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>p = [0,0,1,0]</td>
      <td>0</td>
      <td>33.219</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <td>q = [0,1,0,0]</td>
      <td>33.219</td>
      <td>0</td>
      <td>2.585</td>
      <td>2</td>
    </tr>
    <tr>
      <td>r = [1/6, 1/6, 1/2, 1/6]</td>
      <td>16.610</td>
      <td>27.683</td>
      <td>1.792</td>
      <td>2</td>
    </tr>
    <tr>
      <td>\(\varphi\) = [1/4,1/4,1/4,1/4]</td>
      <td>24.914</td>
      <td>24.914</td>
      <td>2.189</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>对角线上不一定为零，而是自己的信息熵</li>
  <li>其他位置和 KL divergence 相差大约为第一个输入分布的信息熵，误差 eps 的截断</li>
</ul>

<h3 id="互信息mutual-information">互信息：Mutual Information</h3>

<p>这里的两个概率分布一般来说映射自<strong>不同的</strong>随机变量空间。</p>

\[MI(X,Y)=\sum_{x,y}p(x,y)\log\frac{p(x,y)}{p(x)p(y)}=D_{KL}\left(p(X,Y)|p(X)p(Y)\right)\]

<p>从后一个等号可以看出，这一性质衡量的是 <em>X, Y</em> 两个随机变量的联合分布在多大程度上不同于“<em>X</em> 和 <em>Y</em> 相互独立”的零假设。两个随机变量相互独立时，互相不反映对方的信息，互信息 <em>MI</em> = 0。</p>

<p>当从 <em>X</em> 所在的随机变量空间取样的难度比较大的时候，我们需要用容易取样的<strong>另一个变量空间</strong>的随机变量 <em>Y</em> 来推测 <em>X</em> 的情况，互信息就可以用来论证我们这种选择的合理性。</p>

<h2 id="扯点闲篇">扯点闲篇</h2>

<h3 id="pytorch-中以此为基础的-loss-functions">PyTorch 中以此为基础的 loss functions</h3>

<p><code class="language-plaintext highlighter-rouge">torch.nn</code> 中有如下几个和今天的文章相关的 loss functions：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">torch.[nn.KLDivLoss](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss)</code></li>
  <li><code class="language-plaintext highlighter-rouge">torch.[nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)</code></li>
  <li><code class="language-plaintext highlighter-rouge">torch.[nn.BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)</code></li>
  <li><code class="language-plaintext highlighter-rouge">torch.[nn.BCEWithLogitsLoss](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss)</code></li>
</ul>

<p>之所以没直接用这些函数计算上面的例子，是因为 <code class="language-plaintext highlighter-rouge">KLDivLoss</code> 是按元素计算，随后需要自己求和；<code class="language-plaintext highlighter-rouge">CrossEntropyLoss</code> 又是按类别的，还不需要归一化，而且文档的解释很复杂，我到现在也没看明白；而且还要注意这些函数的设计输入是不是 logit，这是机器学习里的概念，在此不展开了。</p>

<h3 id="玻尔兹曼的墓志铭">玻尔兹曼的墓志铭</h3>

\[S=k\log W\]

<p>其中 <em>S</em> 是（微正则系综中的）热力学熵，<em>k</em> 是玻尔兹曼常数 \(k_B\)，<em>W</em> 是因为刻碑的师傅不会写 <em>Ω</em>。</p>

<p>W 或 Ω 是处于相同能量的热力学状态的数量。因为你都需要统计物理了，显然是只知道能量，没办法知道所考虑的微观粒子究竟处于哪一个热力学状态。那此时的零假设就是处于所有状态的可能性相等，<em>p</em> = 1/Ω，信息熵</p>

\[S =-\sum_{m\in M}p(m)\log_n p(m)= -\Omega\cdot(\frac{1}{\Omega}\log\frac{1}{\Omega})=\log\Omega\]

<p>和热力学熵只相差一个玻尔兹曼常数。这是因为信息熵是无量纲的，熵和温度的量纲相乘之后需要得到能量的量纲，只能由 \(k_B\) 把量纲凑齐，而数值是自由能相关的实验里测出来的。</p>

<p>好像这就是高中物理里熵的定义式是吧。</p>

<p>上了大学以后，正则系综和巨正则系综中的熵也分别就是各自体系中各状态的概率分布的信息熵，乘上玻尔兹曼常数。<del>（我也忘得差不多了，试图萌混过关）</del></p>

<h3 id="善卜者无先见之明">善卜者无先见之明</h3>

<p>公元 451 年，阿提拉 Attila 率领匈人攻入罗马领土，横扫有大量其他民族居住的高卢地区。西罗马帝国将军艾提乌斯 Aetius 联络了众多畏惧匈人的民族组成联军，其中包括西哥特人的王狄奥多里克 Theodoric，两军会战于卡塔隆 Catalaunian 平原。</p>

<p>本来想用这个故事举例子来着，因为我记得阿提拉在战前找了个大师算了一卦，说是一位国王将战死，一个国家将崩塌。于是阿提拉很高兴，以为哥特人和狄奥多里克要玩完了，结果战斗打响，狄奥多里克确实死于乱军，但是罗马和哥特等族的联军击败了匈人，阿提拉的霸业雨打风吹去。</p>

<p>于是试图说明算命的魅力就在于，用文字游戏表达一个自信息比较低的命题，同时误导对方相信一个自信息高得多的命题，在心理疏导之外，赚一个信息熵的差价。</p>

<p>结果查证的时候发现好像不是这么回事，Barbarian Rising 故事片里的预言内容不一样；维基百科上没给出处，说算命的很准，于是阿提拉推迟到下午作战，方便晚上跑路；其他地方甚至压根没有算命的情节。但是写都写了，需要积累高考作文素材的小朋友们还是可以假装被我误导了~</p>

<p>当然了，算命这个事还有一种情况，就是打着不确定的幌子，售卖确定但不方便承认自己确定的信息，那就是另一种生意，和另外的价格了~</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[自信息、信息熵、KL Divergence、交叉熵、互信息]]></summary></entry><entry><title type="html">.tex | 扩散方程和随机游走的等价</title><link href="https://mountaye.github.io/blog/articles/equivlance-between-diffusion-equation-and-random-walk" rel="alternate" type="text/html" title=".tex | 扩散方程和随机游走的等价" /><published>2024-04-25T00:00:00-05:00</published><updated>2024-04-25T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/equivlance-between-diffusion-equation-and-random-walk</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/equivlance-between-diffusion-equation-and-random-walk"><![CDATA[<blockquote>
  <p>这些内容总结自美国研究生级别的《数学物理方法》两次课的笔记，大约两个小时。
<br />如果是中国大学本科的话，认真的老师半个小时庶几可以讲完;
<br />念 PPT 就算上课的话 15 分钟可以讲完，附赠一个段子;
<br />翻转课堂的话也就布置个作业，老师一句话可以讲完。
<br />以上数据除第一句外纯属揣测，没有黑任何人的意思，love and peace~</p>

</blockquote>

<h3 id="扩散方程">扩散方程</h3>

<p>带有初值条件的扩散方程表述如下：</p>

\[\begin{cases}
u(x,t=0)=f(x) \\
\partial u(x,t)/\partial t=\sigma \cdot \partial^2 u(x,t)/ \partial x^2
\end{cases}\]

<p>方程的解为：</p>

\[u(x,t) = \frac{1}{\sqrt{4\pi \sigma t}} \int_{-\infty}^{+\infty} f(s)\ e^{-\frac{(x-s)^2}{4\sigma t}}\ ds\]

<p>解法是将 u(x,t) 对空间变量 x 作傅里叶变换为 U(k,t)，利用傅里叶变换的性质，变换后的方程将是关于时间 t 的一阶常微分方程。求解后作傅里叶逆变换 <del>即为上式。</del> <del>（完蛋，好久没做题了，那个 \(e^{-\frac{(x-s)^2}{4\sigma t}}\) 是怎么凑出来的，为什么我直接给消掉了啊）</del> 凑出来了凑出来了，初值条件代入频域 k 空间里的通解来确定积分常数，可以看到结果 \(F(k) e^{-\sigma t k^2}\) 是两项之积，所以根据傅里叶变换的卷积定理，实空间 x 里的解是 f(x) 和 \(\mathscr{F}_{k\rightarrow x}^{-1}\{e^{-\sigma t k^2}\}\) 的卷积（所以上式的指数项以 (x-s) 为宗量），而计算后者的时候需要用到高斯积分～</p>

<h3 id="随机游走">随机游走</h3>

<p>随机游走是一个离散过程，为了和连续时空中的扩散方程相对比，将空间变量 x 离散化为相隔 Δ 的格点 i，时间变量 t 离散化为相隔 δ 的 n。</p>

<p>当一个粒子在 n 时刻位于格点 i 时，在下一个时刻 n+1, 它有 1/2 的概率移动到 i-1, 1/2 的概率移动到 i+1.</p>

<p>所以，虽然每个进行随机游走的粒子在任意时刻都只有确定且唯一的位置，但是对于大量同样初始位置和运动规律的例子，n 时刻出现在 i 格点的概率 P(i,n) 有以下关系：</p>

\[\begin{cases}
P(i,0)= f_i \\
P(i,n)=\frac{1}{2}\left[P(i-1,n-1)+P(i+1,n-1)\right]
\end{cases}\]

<p>在初值条件为 \(f_i=\delta_{i=0}\) 时，递推结果如下：</p>

<table>
  <thead>
    <tr>
      <th>x 轴 —</th>
      <th>i = -4</th>
      <th>i = -3</th>
      <th>i = -2</th>
      <th>i = -1</th>
      <th>O</th>
      <th>i = 1</th>
      <th>i = 2</th>
      <th>i = 3</th>
      <th>i = 4</th>
      <th>→</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>n = 0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td> </td>
    </tr>
    <tr>
      <td>n = 1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1/2</td>
      <td>0</td>
      <td>1/2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td> </td>
    </tr>
    <tr>
      <td>n = 2</td>
      <td>0</td>
      <td>0</td>
      <td>1/4</td>
      <td>0</td>
      <td>1/2</td>
      <td>0</td>
      <td>1/4</td>
      <td>0</td>
      <td>0</td>
      <td> </td>
    </tr>
    <tr>
      <td>n = 3</td>
      <td>0</td>
      <td>1/8</td>
      <td>0</td>
      <td>3/8</td>
      <td>0</td>
      <td>3/8</td>
      <td>0</td>
      <td>1/8</td>
      <td>0</td>
      <td> </td>
    </tr>
    <tr>
      <td><strong>t 轴 ↓</strong></td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p><img src="/blog/assets/photos/2024-04-25-random-walk-probabilities.png" alt="" /></p>

<p>离散的情况，很难对任意的初值条件写出解的表达式，但是对于上面的特殊情况，课上不加证明地给出了（可能是根据上图凑出来的）下面的解：</p>

\[P(i,n)=\frac{1}{2^n}\frac{n!}{\left(\frac{n+i}{2}\right)!\left(\frac{n-i}{2}\right)!}\]

<p>对的，以上关系只能表示 (n+i = 偶数) 的情况，但是康托尔告诉了我们，所有偶数和所有自然数的“数量”一样多，所以也没差太多～</p>

<h3 id="方程的等价">方程的等价</h3>

<p>概率的递推公式可以变换为：</p>

\[\frac{1}{\delta}\left[P(i,n)-P(i,n-1)\right]=\frac{1}{2}\left [\frac{P(i-1,n-1)-2P(i,n-1)+P(i+1,n-1)}{\Delta^2}\right]\frac{\Delta^2}{\delta}\]

<p>因为 \(x=i\Delta,\ t=n\delta\), 对两个变量的微分可以离散化成差分：</p>

\[\frac{\partial}{\partial x}\rightarrow \frac{1}{\Delta}\left[()_i-()_{i-1}\right],\ \frac{\partial}{\partial t}\rightarrow \frac{1}{\delta}\left[()_n-()_{n-1}\right]\]

<p>直接就能看出扩散方程和随机游走的等价，且系数之间存在关系：\(\sigma = \frac{\Delta^2}{2\delta}\)</p>

<h3 id="解的等价">解的等价</h3>

<p>只讨论一个 δ(x) 函数作为初值条件的情况，我们要证明此时扩散方程的解：</p>

\[u(x,t) = \frac{1}{\sqrt{4\pi \sigma t}} e^{-\frac{x^2}{4\sigma t}}\ \xleftarrow[{\Delta,\delta \rightarrow 0;\ i,n\rightarrow \infty}]{x=i\Delta,\ t=n\delta} \frac{1}{2^n}\frac{n!}{\left(\frac{n+i}{2}\right)!\left(\frac{n-i}{2}\right)!} \frac{1}{2\Delta}\]

<p>只需讨论这一个情况，因为 δ(x-s) 函数可以看作将一个函数 f(x) 在自变量 x=s 时切片为 f(s)，而任何一个（性质比较“优美”的）函数都可以看作把它自己在定义域上的所有点切片后再重新叠加起来：</p>

\[f(x) = \int_{-\infty}^{+\infty}f(s)\delta(x-s)\ ds\]

<p>过程需要用到 Sterling 公式对阶乘的近似：\(n! \approx \sqrt{2\pi n}\ n^n e^{-n}\)</p>

\[\begin{array}{rcl}
\frac{P(i,n)}{2\Delta} &amp; \approx &amp; \frac{1}{2\Delta} \frac{1}{2^n} \frac{\sqrt{2\pi n}\ n^n e^{-n}}{\sqrt{\frac{2\pi (n-i)}{2}}\ \left(\frac{n-i}{2}\right)^{\frac{n+i}{2}} e^{-\frac{n+i}{2}}\sqrt{\frac{2\pi (n+i)}{2}}\ \left(\frac{n+i}{2}\right)^{\frac{n+i}{2}} e^{-\frac{n+i}{2}}} \\
&amp; = &amp; \frac{1}{2\Delta}\frac{\sqrt{2n}}{\sqrt{\pi(n^2-i^2)}}\frac{n^n}{(n-i)^{\frac{n}{2}-\frac{i}{2}}(n+i)^{\frac{n}{2}+\frac{i}{2}}} \\
&amp; = &amp; \frac{1}{2\Delta}\frac{\sqrt{2n}}{\sqrt{\pi(n^2-i^2)}}\frac{n^n/n^n}{(n-i)^{\frac{n}{2}}(n+i)^{\frac{n}{2}}(n-i)^{-\frac{i}{2}}(n+i)^{\frac{i}{2}}/n^n} \\
&amp; = &amp; \frac{1}{2\Delta}\frac{\sqrt{2n}}{\sqrt{\pi(n^2-i^2)}} \frac{1}{\left(1-\frac{i}{n}\right)^\frac{n}{2}\left(1+\frac{i}{n}\right)^\frac{n}{2}\left(1-\frac{i}{n}\right)^{-\frac{i}{2}}\left(1+\frac{i}{n}\right)^\frac{i}{2}} \\
&amp; = &amp; \frac{1}{\sqrt{2}\Delta}\frac{1}{\sqrt{\pi(n-\frac{i^2}{n})}} \frac{1}{\left(1-\frac{i^2}{n^2}\right)^\frac{n}{2}\left(1-\frac{i}{n}\right)^{-\frac{i}{2}}\left(1+\frac{i}{n}\right)^\frac{i}{2}} \\
&amp; \xrightarrow[\frac{i}{n}=\frac{x\Delta}{2\sigma t},\ \frac{i^2}{n}=\frac{x^2\delta}{\Delta^2 t}]{(1+a\epsilon)^{1/\epsilon}\rightarrow e^a} &amp; \frac{1}{\sqrt{4\pi\sigma t}}\frac{1}{e^\frac{x^2}{4\sigma t} e^\frac{x^2}{4\sigma t} e^{-\frac{x^2}{4\sigma t}} } \\
&amp; = &amp; \frac{1}{\sqrt{4\pi\sigma t}}e^{-\frac{x^2}{4\sigma t}}
\end{array}\]

<h3 id="之前-mcmc-讲错了">之前 MCMC 讲错了</h3>

<p>讲 Markov Chain Monte Carlo 模拟的时候举的例子是计算 \(\int_{-\infty}^{+\infty}e^{-x^2}dx\), 现在系数可以对上了：\(1=4\sigma t=4 \frac{\Delta^2}{2\delta} n\delta = 2\Delta^2n\), 随机游走的步数和步长之间存在一个确定的关系，在步长确定的情况下，我们需要重复模拟大量粒子作相同步数的随机游走，然后统计这一确定步数走完之后的每个粒子的终末位置。</p>

<p>所以，这并不是一个 Markov Chain Monte Carlo 模拟，只是一个普通的 Monte Carlo 模拟，我们拿到了想要知道的随机变量的原始概率分布，只不过取得符合这一概率分布的每一个样本的过程是一个 Markov 过程。</p>

<p>正经的 MCMC，应该是只模拟一个粒子作随机行走，然后把它每一步的位置记录下来，统计到样本里去。这样的话时间 t 的信息就被抹去了，而且由于扩散方程描述的状态并不是热力学平衡态，并不能通过统计物理中的遍历性 (ergodicity) 来得到正确结果。</p>

<p>采用了 Metropolis 算法的 MCMC, 一个粒子作随机行走只是其中的一个步骤，还要计算这一步之前和之后 \(e^{-x^2}\) 的值，来决定这一步是否被加入样本，不成立的话要退回前一步继续走。</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[之前 MCMC 讲错了]]></summary></entry><entry><title type="html">.tex | MC→MCMC 蒙特卡洛模拟，基于马尔科夫链采样</title><link href="https://mountaye.github.io/blog/articles/mc-mcmc-markov-chain-monte-carlo-gibbs-sampling" rel="alternate" type="text/html" title=".tex | MC→MCMC 蒙特卡洛模拟，基于马尔科夫链采样" /><published>2024-04-15T00:00:00-05:00</published><updated>2024-04-15T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/mc-mcmc-markov-chain-monte-carlo-gibbs-sampling</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/mc-mcmc-markov-chain-monte-carlo-gibbs-sampling"><![CDATA[<p>Monte Carlo 蒙特卡洛模拟，简称 MC.</p>

<p>Markov Chain Monte Carlo 是用马尔科夫链采样的蒙特卡洛模拟，简称 MCMC.</p>

<h2 id="monte-carlo-模拟">Monte Carlo 模拟</h2>

<p>这个比较简单了，举个例子，要计算 π 的近似值，可以在一块正方形板子里画一个内接圆，然后以均匀的概率往正方形里一粒一粒地扔沙子，每扔一粒，就判断并且记录这里沙子在圆内还是圆外，然后把沙子吹掉，如此往复。圆的面积是 πr²，正方形的面积是 4r²，所以落在圆内的概率（圆内沙子的数量和总数的比值）乘 4，就是所求。</p>

<p><img src="/blog/assets/photos/2024-04-15-monte-carlo-pi.png" alt="" /></p>

<p>归纳一下：当问题的解用一个随机变量的概率分布、期望值、二阶矩……等等来表示的时候，就生成一个符合该概率分布的随机样本，用样本的统计量去近似原概率分布。</p>

<h2 id="markov-chain-monte-carlo">Markov Chain Monte Carlo</h2>

<p>但是前述例子有一个步骤，就是我们往板子上扔完沙子要把沙子吹掉，每粒沙子，每次扔沙子之间也应该看不出区别，这是为了保证取样之间<strong>相互独立且来自同一个概率分布</strong>。</p>

<p>但是很多取样过程无法满足这种条件，或者达成条件所需的成本很高。比如计算一个高斯积分 \(\int_{-\infty}^{+\infty}e^{-x^2}dx\)，被积函数的取值范围涵盖整个实数集，想找一个在整个实数集上均匀分布的随机数发生器就比较难了。</p>

<p><img src="/blog/assets/photos/2024-04-15-monte-carlo-gaussian.png" alt="" /></p>

<p>但是学过物理的朋友应该知道，上面的被积函数是以狄拉克 δ(x) 函数为初值条件的一个扩散方程的解，在某一时刻的空间分布。（不想凑系数了，将就看吧）</p>

<p>而扩散方程又是随机游走 (random walk) 在连续近似下的极限。</p>

<p>所以我们直接模拟一堆粒子从原点出发作随机行走，向两个方向的概率相同，扩散系数以及积分里的常数对齐，统计粒子在整个过程中出现在不同 x 位置的频率，求和之后乘以步长就是积分结果。这个过程需要的随机数发生器容易获取得多，是一个以 0.5 为阈值的 [0,1) 的均匀分布，比如一个均匀硬币。</p>

<p>而随机行走过程中走完每一步的位置，都只取决于前一步的位置，而与更久远的历史无关——这样的过程叫做马尔可夫过程。用这种方法取样获得随机样本的蒙特卡洛模拟，就是 MCMC.</p>

<p>扩散方程和随机行走只是 MCMC 的一个很特殊很特殊的例子，而对于一般的 MCMC 模拟，有以下通用的 Markov Chain 采样的算法：</p>

<h3 id="metropolis-hastings-算法">Metropolis-Hastings 算法</h3>

<p>已知一个随机变量 x, 和一个与目标概率分布 P(x) 成正比的函数 f(x)（不要求 f 归一化）</p>

<ol>
  <li>初始化
    <ol>
      <li>选定初始采样点 \(x_0\)</li>
      <li>选定一个采样函数 proposal function，也就是在已知当前 x 的取值时，下一个 x’ 取值的概率分布 \(g(x’\vert x)\)；其中对于 Metropolis 算法，这个采样函数是对称的：\(g(x’\vert x)=g(x\vert x’)\). 常用以两者之差为宗量的高斯函数。</li>
    </ol>
  </li>
  <li>在得出 t 时刻的 \(x_t\) 之后：
    <ol>
      <li>根据 \(g(x'\vert x_t)\) 抽样得到一个 x’</li>
      <li>计算 α = f(x’)/f(x) = P(x’)/P(x)</li>
      <li>决定是否将 x’ 加入样本
        <ol>
          <li>如果 α ≥ 1, 直接加入</li>
          <li>如果 α &lt; 1, 以 α 为概率加入</li>
        </ol>
      </li>
    </ol>
  </li>
</ol>

<p>这种方法不保证采样的早期样本也符合目标概率分布，所以一般会抛弃最先加入的若干样本。</p>

<h3 id="gibbs-采样">Gibbs 采样</h3>

<p>只是一种思路，不算是完整的算法。</p>

<p>当被采样的随机变量是一个多维向量的情况，在不使用 Gibbs 采样的情况下，在迭代的某一步骤 t，每个分量都应该是前一步骤的函数：\(x_{i,t}=f(\{x_{j,\ t-1}\})\)</p>

<p>而 Gibbs 采样就是说，不必让每个维度 i 都根据前一个步骤的分量来取值，可以把当前 t 已经取样出来的分量直接带入到本回合后面的维度：\(x_{i,t}=f(\{x_{j,\ t}\}_{j&lt;i}\cup\{x_{k,\ t-1}\}_{k\ge i})\)</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[蒙特卡洛模拟、马尔科夫链采样、Metropolis-Hastings 算法、吉布斯采样]]></summary></entry><entry><title type="html">.doc | 爷爷没等到我回来</title><link href="https://mountaye.github.io/blog/articles/farewell-grandpa" rel="alternate" type="text/html" title=".doc | 爷爷没等到我回来" /><published>2024-04-08T00:00:00-05:00</published><updated>2024-04-08T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/farewell-grandpa</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/farewell-grandpa"><![CDATA[<p>去年春末夏初的时候，每周和爸妈视频电话的时间没人接听，一小时后他们发消息说爷爷住院了，接着视频电话就打过来了。爷爷听力早就不好了，画面里看他还戴着呼吸机，我没有看到他的反应，不知道听见我没有。</p>

<p>这就是我最后一次见到爷爷。本来接下来的周末听说情况稳定了，结果迅速恶化，总共住院不到两周。</p>

<p>看到消息的时候，脑子觉得我应该哭，心里却只是有点堵，哭不出来。当时这边是晚上，我在办公室，我们老板从来不黑脸，从他很有耐心的话中，我觉得他对我的论文初稿很不满意。于是浅呼一口气，继续作图继续写。</p>

<hr />

<p>我上小学前一直和爷爷奶奶住在一起，周末被爸爸妈妈接“回”家里去。那时候我爸白天工作，晚上复习考研；我妈在一个国企内部的小医院，经常上夜班。</p>

<p>那段日子的绝大多数时间并不开心。小孩子哪懂什么考研和夜班，只怀疑爸爸妈妈是不是不要我了。和爷爷奶奶在一起按理说是一种安慰，但是要上幼儿园。</p>

<p>奶奶退休前是小学老师。搞教育的人，经常对自己家孩子的教育有点不切实际的想法，入园就给我插到了中班去。发现跟大孩子一起根本融不进去之后，又给我调到小班，完美错过小孩子刚认识的时候交朋友的阶段。</p>

<p>再加上幼儿园学的东西真的好难，老师教折纸，先这样折，那样折，翻过来，在这个地方剪一刀——三步以后我必然听不懂。只能在其他小朋友举起劳动成果的时候偷瞟左右，趁大家不注意把自己的纸团藏到桌洞里去。开始是伸手放进去，后来熟练了，手腕一抖就投进去了。半个学期就能攒满一桌洞，需要老师举起桌子倒出一摊，拿笤帚扫成一堆。</p>

<p>于是毫无意外成为大家的笑柄，我们班里有个傻子，嘿嘿。</p>

<p>所以不想上幼儿园。早上和爷爷一起走着去幼儿园，走两步我就战战兢兢嘱咐一句“可千万别忘了来接我啊”，很短的一段路，我能一字不差地问三百遍。爷爷攥着我的手，严肃认真地回“嗯，一定不会忘”，一字不差地回答三百遍。</p>

<p>中午回家吃饭睡午觉，爷爷说，要是睡过头了的话，下午就不去幼儿园了吧。于是直到上小学的前一年，我每天中午都会睡过头，“睡醒了”就在家里跑来跑去，等到太阳西斜了，跟着爷爷去门球场，他跟老伙计们打门球，我在细红线勒出的边线外面玩沙子和计分板。</p>

<p>就这样一直玩到天色幽蓝，那样的幽蓝仿佛日日如此，总有爷爷带我回家。</p>

<hr />

<p>这样的日子回不去是理所当然，但是没想到连这样的回忆也再难听到了。这种糗事本来是家里聚餐时饭桌上最常听到的谈资，毕业回国和伯伯、姑姑、叔叔家相聚，席间还是他们在说，话题却变成他们记得的爷爷奶奶的故事，我成了远方来客，成了不便开玩笑的别人家的孩子。</p>

<p>我才意识到，和我记忆中的退休老人形象不同，父辈们眼中的爷爷，还是他年轻时候的样子。</p>

<p>我又意识到，不是爷爷年轻时候的样子，而是和我一样，是记忆中我们小时候他的样子。</p>

<p>那时候的爷爷在我市周围某县的一家半导体工厂，所谓半导体其实指的是收音机，所谓工厂是一间福利厂，就是给县里机关和事业单位的家属安排工作用的，不以赚钱为首要目的。比如厂里的会计是副县长的老婆，进厂的时候是个文盲，算账是和认字一起学的。</p>

<p>姑姑说爷爷是厂长；我爸说不对，爷爷是厂里唯一的技术员。</p>

<p>这些故事总有许多个版本，就比如厂房施工的时候，有辆满载一板车砖头的驴车上坡，结果有个熊孩子喊了一声“吁~”，驴子停在半坡不走了，把赶车的工人吓了一跳又气得不轻，但是不敢发作，因为不知道是谁家的孩子。</p>

<p>那熊孩子是谁来着，是不是我爸？我爸说不是，是会计的儿子。真实情节说不清楚，只有“吁”是全世界驴子停车的通用口令，是无数大语言模型在甚高维嵌入空间的交点。</p>

<p>后来改革开放，厂子散了，爷爷联系了隔壁县的一所师范类大专，成了一名物理老师。后来全家跟着学校搬迁到城市，我出生长大的地方。</p>

<p>很奇怪，这些回忆日常得异常，那些惊天动地的大事，模糊得像烛光投在墙上的影子。</p>

<p>日寇侵华的时候，往我们老家所在的海边渔村仍了一颗未爆的哑弹就再没来过；爷爷的叔叔带船队北上做生意，结果连人带货和船一起被扣了，爷爷的爸爸卖了好多田地去赎人，于是土改只被定了个中农；工农兵推荐取代高考前的一两届考上了大学；政治运动里整人没资格，被整也没把柄……</p>

<p>可能也不奇怪，能活到今天的大家，要么是惊涛骇浪的幸存者，要么是幸存者的后代，除了史书上主角中胜利的那一小撮，谁还不是有点运气在身上呢。除了胜利的一小撮，比起一句顶一万句，一天顶一万年的狂飙突进，谁不更希望打门球，看孩子玩沙子，玩到天色深蓝呢？</p>

<hr />

<p>于是继续玩沙子，玩到天色幽蓝，爷爷带我回家。</p>

<p>有一天在幼儿园里，画册上有一道益智题，一个四乘四的方阵，横竖斜线四个方向上四种水果排列起来。我觉得图案很漂亮很有趣，想回家给爷爷看，于是中午一到家，就要找纸笔要画下来。结果画到一半，剩下的图案就不记得了，急得我要哭。</p>

<p>爷爷在旁边微笑着看，见我画不出来了，把笔要了过去，把剩下的水果补全。爷爷画不好水果，就把水果的名字写在空白的地方。这么神奇的吗？爷爷不是没看过那本画册吗？这两字是什么，真的是菠萝没骗我吗？</p>

<p>这叫规律，世界上的所有事情都是有规律的。爷爷拉开木柜子上一个很沉的抽屉，金属和润滑油的气味飘散出来，他拿出好多小灯泡、电闸和电池盒，组了一个电路，拉下不同的电闸，不同地方的小灯泡次第亮起来。</p>

<p>我还是不信，把那几个水果的名字认全了，下午要去幼儿园验证一下爷爷猜的对不对。晚上回家吃完晚饭看新闻，播音员说的话和电视上写的字是对应的吗？只有爷爷很高兴，出门溜弯的时候，逢人就说他孙子脑子开窍了。</p>

<p>还是继续玩沙子，慢慢有其他小孩加入了进来，社恐的我也有了一两个朋友。在幼儿园还是不敢出去做广播体操，于是在教室里上凳子，算是帮老师打扫卫生。爷爷出门溜弯的时候，逢人就对他说，听说你孙子脑子开窍了……</p>

<hr />

<p>然后回到爸爸妈妈那里上小学，从朝夕相见，到周末不见，到只有周末相见，再到每个寒暑假相见，再到没能再见。</p>

<p>这次回家，爸妈开车去接我，回城那日天气极好，车在河边新城一侧的快速路行驶，对岸的天际线满满当当是已经炒到上万一平米的住宅楼。师专的图书馆曾经是河边唯一的高楼，如今隐没难寻，仔细找到后却发现像人群中站着个矮胖墩，尴尬，不如不复相见。</p>

<p>回到家里，旧桌旧椅旧沙发，其中一个沙发上坐着一只洗得干干净净的黄色玩具熊。小熊也已经等了我五年了啊，于是趁着爸妈还在收拾其他行李的机会，把行李箱推进自己房间，轻轻关门，无声地任由泪水流下。</p>

<hr />

<p>有一年我爸从外面回来，兴高采烈要找爷爷，进门就喊“老头儿呢？老头儿呢？”奶奶在包饺子，双手沾了面粉和馅料，只瞪了他一眼。当时的我坐在地上玩，抬头看我爸，感到很不高兴，这个大人怎么这么没大没小的。</p>

<p>如今我也快到了当年我爸的年龄，被他抓到他笔记本电脑面前，问他的网页浏览器图标上怎么有一个头像。原来是不知道什么时候无意中打开了个没用的功能，这点小事都整不明白，想叫他“老头儿”的冲动愈发强烈。</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[消息的时候，脑子觉得我应该哭，心里却只是有点堵，哭不出来。]]></summary></entry><entry><title type="html">.tex | 意识理论笔记</title><link href="https://mountaye.github.io/blog/articles/note-consciousness-theories" rel="alternate" type="text/html" title=".tex | 意识理论笔记" /><published>2024-01-10T00:00:00-06:00</published><updated>2024-01-10T00:00:00-06:00</updated><id>https://mountaye.github.io/blog/articles/note-consciousness-theories</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/note-consciousness-theories"><![CDATA[<blockquote>
  <p>本文是《<strong><a href="https://mp.weixin.qq.com/s/S_nZFZD72Kq3sJmoXKplww">一场意识理论大混战，甚至“伪科学”帽子都飞出来了</a></strong>》一文的读书笔记。</p>

</blockquote>

<h2 id="名词解释">名词解释</h2>

<ul>
  <li><strong>发放</strong>：对 spike 的翻译。发放率即 spike-count rate. <a href="https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%BB%8F%E7%BC%96%E7%A0%81">https://zh.wikipedia.org/wiki/神经编码</a></li>
  <li><strong>V1</strong>：初级视皮层。<a href="https://zh.wikipedia.org/wiki/%E8%A7%86%E8%A7%89%E7%B3%BB%E7%BB%9F">https://zh.wikipedia.org/wiki/视觉系统</a></li>
</ul>

<h2 id="事实陈述">事实陈述</h2>

<h3 id="科赫-vs-查默斯赌局信息整合理论作者之一打的一个赌">科赫 vs. 查默斯赌局：信息整合理论作者之一打的一个赌</h3>

<ul>
  <li>德裔美国神经科学家科赫 (Christof Koch) vs. 澳大利亚哲学家查默斯 (David Chalmers)</li>
  <li>内容：以下问题能否在25年内得到解决：
    <ul>
      <li>查默斯称为意识的“<strong>困难问题</strong>”（hard problem）：“主观的意识是怎样从客观的神经回路中涌现出来的”</li>
      <li>等价于，科赫和其忘年交克里克所说的“<strong>意识的神经相关集合</strong>”（Neural correlates of consciousness）</li>
    </ul>
  </li>
  <li>结果：没能解决，科赫认输，双方再约 25 年</li>
  <li>时间线
    <ul>
      <li>1990年，克里克和科赫《走向意识的神经生物学理论》（<a href="https://profiles.nlm.nih.gov/spotlight/sc/catalog/nlm:nlmuid-101584582X469-doc">Towards a Neurobiological Theory of Consciousness</a>）
        <ul>
          <li>观点：研究意识也是一样，应该从研究脑中哪些神经活动和视知觉相关——意识的神经相关集合开始。</li>
          <li>挑战：当主体受到视刺激后的脑活动变化，既可能是由于视知觉引起的，也可能是由于刺激变化本身引起的。</li>
        </ul>
      </li>
      <li>1996年，在德国工作的希腊神经科学家洛戈塞蒂斯（Nikos K. Logothetis）猴子双眼竞争实验
        <ul>
          <li><strong>双眼竞争</strong>：给主体的双眼分别看两个完全不同的景象时，主体看到的并非这两个景象的融合，而是轮流看到其中之一。</li>
          <li>结果：
            <ul>
              <li>在初级视皮层和次级视皮层，绝大多数细胞的 <strong>发放(?)</strong> 率与知觉的反复变化无关。总体来说，只要一只眼睛有输入刺激，神经元的发放就会增强。这与猴子究竟看到了什么无关。</li>
              <li>他们又发现在对猴子下颞叶（inferior temporal，IT）皮层及上颞叶沟（superior temporal sulcus，STS）的下侧（该区域与IT上部相邻）进行实验记录时，只有当猴子“看到”时才有发放。</li>
            </ul>
          </li>
          <li>推论：
            <ul>
              <li>一般认为 <strong>V1(?)</strong> 对意识贡献甚微。</li>
              <li>克里克对此非常兴奋，他认为这一技术已使科学家找到了研究视知觉神经相关集合的钥匙，并宣称到20世纪末就能发现意识的神经相关集合。</li>
              <li>像功能性核磁共振成像和光遗传学等新技术的出现，使科赫在当时认为，25年的时间去解决应该没问题。</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>科赫在1998年和查默斯打了这个赌。这个赌只与能否在2023年解决查默斯的“困难问题”有关，而与其他论点无关。</li>
    </ul>
  </li>
</ul>

<h3 id="意识的神经相关最小集合信息整合理论的预备知识">意识的神经相关最小集合：信息整合理论的预备知识</h3>

<ul>
  <li>定义
    <ul>
      <li>意识的神经相关集合就是“神经元的某种机制或事件的集合。该集合是形成某个特定知觉或体验所需要的最小集合。”（<a href="https://ajp.psychiatryonline.org/doi/10.1176/appi.ajp.162.2.407">科赫2004</a>）</li>
      <li>他和托诺尼又引申出对所有可能意识内容的意识神经相关集合的总体，并称之为全意识神经相关集合（full neural correlates of consciousness）。（<a href="https://www.nature.com/articles/nrn.2016.22">2016</a>）</li>
    </ul>
  </li>
  <li>方法与相应结果
    <ul>
      <li>需要排除对脑涌现意识非必要的事件，比如报告信号这件事本身（通过检测眼动或瞳孔放大）
        <ul>
          <li>这种“无报告范式（no‑report paradigms）”所确定的有特定内容的神经相关集合比需要报告时得到的更局限于皮层后部。（<a href="https://www.nature.com/articles/nrn.2016.22">2016</a>）</li>
        </ul>
      </li>
      <li>一种是“基于不同状态的方法”（state-based approaches）把清醒的健康受试者在不要求做任何任务而有意识时的脑活动和意识丧失时（如无梦睡眠、全身麻醉、昏迷或植物状态）的脑活动进行比较。
        <ul>
          <li>全意识神经相关集合往往包括额-顶叶网络，但是这里有些部分可能和受试者的警觉、注意等脑功能有关。</li>
        </ul>
      </li>
      <li>另一种“同样状态无任务范式”（within-state, no‑task paradigm）这主要是利用意识的自发波动，例如当受试者处于无快速眼动睡眠期时将其叫醒，有时受试者说是正在做梦，而有时则没有任何意识。把受试者在报告做梦或无意识前记录下来的脑电图进行比较，
        <ul>
          <li>全意识相关神经机制主要位于包括感觉区在内的后皮层热区（posterior cortical hot zone），也就是包括皮层后部颞-顶-枕叶交界处在内的脑区，这和根据有特定内容的意识神经相关集合所得的结果在总体上吻合得相当好，因此可以把后部皮层区看作意识神经相关集合的热门候选区。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="整合信息理论-vs-全局神经工作空间理论">整合信息理论 vs. 全局神经工作空间理论</h3>

<ul>
  <li>整合信息理论 (IIT) 同一把大伞之下，有两个很不相同的内容
    <ol>
      <li>（根据“同样状态无任务范式”）全意识相关神经机制主要位于包括感觉区在内的后皮层热区（posterior cortical hot zone），也就是包括皮层后部颞-顶-枕叶交界处在内的脑区，这和根据有特定内容的意识神经相关集合所得的结果在总体上吻合得相当好，因此可以把后部皮层区看作意识神经相关集合的热门候选区。这一观点笔者称之为“后脑理论”。</li>
      <li>托诺尼早已因他制定了一个度量意识的指标Φ并冠名为“整合信息理论”而闻名，而科赫也曾称赞过这一理论是“有关意识的唯一有希望的基本理论”，因此他们的这一观点也被称为IIT
        <ul>
          <li>托诺尼、埃德尔曼（Gerald Edelman）曾经提出过“整体性”和“信息性”（或称“神经复杂性”）作为衡量意识程度的定量指标。托诺尼正是在这一基础上考虑了意识更多的基本性质（其核心依然是整体性和信息性，但是却略去了“主观性”或“私密性”这一意识的根本属性），并以此作为“公理”。</li>
          <li>这些公理包括：內禀存在性（Intrinsic existence）、结构性（composition）、信息性、整体性（integration）、排他性（exclusion）。</li>
          <li>在这些公理的基础之上，托诺尼认为如果一个物理系统要有意识的话，那么这个系统就必须有和上述公理相应的性质，它应该是一个有数量极大的可能状态的统一整体，为此在有关脑区之间必须有交互作用。意识的程度可用该系统超越其各组成部分所含信息量的总和的信息量来度量，他们把这称为“整合信息（integrated information）”，并用符号Φ来表示</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>全局神经工作空间理论（global neuronal workspace hypothesis）
    <ul>
      <li>《<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3971003/">Consciousness and the Brain: Deciphering How the Brain Codes our Thoughts</a>》</li>
      <li>法国认知神经科学家德阿纳（Stanislas Dehaene）提出。由于对意识仍然没有明确和普遍接受的定义，德阿纳将他的研究集中在他所谓的“进入意识（conscious access）”（受试者意识到了其所受刺激并可以向其他人报告的现象）上。</li>
      <li>他们使用掩蔽、双眼竞争和其他方法表明，虽然刺激保持不变或几乎不变，但受试者的知觉却可能发生根本变化，例如从意识不到变成意识到，或正好相反，因此进入意识可以被视为唯一的变量，并可以通过实验对这一变量进行操控。</li>
      <li>发现如下标记：
        <ol>
          <li>刺激诱发的脑活动大大增强，扩大到多个脑区并突然引发前额叶皮层和顶叶皮层许多回路的活动；</li>
          <li>脑事件相关电位中的晚成分P3突然增强；</li>
          <li>在晚期突然爆发高频振荡；</li>
          <li>跨脑区域活动的同步化。</li>
        </ol>
      </li>
      <li>观点/结论
        <ul>
          <li>当有有意识的知觉时，神经元群以协调的方式开始发放，首先是在一些局部的特定区域，然后蔓延到皮层的广大范围。最终，它们侵入到许多前额叶和顶叶脑区，同时与前面的感觉区保持紧密同步。正是在这个时候，突然形成了一个协调一致的脑网络，有意识觉知也似乎由此产生。</li>
          <li>意识是一种在全脑范围里的信息共享。人脑中有高效的长距离网络，特别是在前额叶皮层，以选择相关信息并将其扩播到整个脑。意识是一种演化装置，它使我们能够注意某个信息并在这一扩播系统中保持活跃。一旦这个信息被意识到了，根据我们当时的目标，它可以被灵活地传送到其他区域。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="邓普顿世界慈善基金会5年对抗合作">邓普顿世界慈善基金会5年对抗合作</h3>

<ul>
  <li>权威杂志《科学》（<em>Science</em>）和《自然》（<em>Nature</em>）等载文称赞了这一对抗性合作</li>
  <li>有124位意识研究科学家联名发表公开信，把IIT谴责为“伪科学”</li>
  <li>六个独立实验室遵照双方预先商定的方案，并分别用功能性核磁共振、脑磁图和皮层电图技术对250名受试者测量其脑活动，以检验这两种理论对他们共同认同的两个实验方案中第一个方案的不同预测，双方自己并不参加实验。</li>
  <li>整合信息理论 IIT
    <ul>
      <li>有利：关于IIT，确实观察到，后皮层脑区持续有信息。</li>
      <li>不利：并没有发现IIT所预测的脑区之间有持续的同步活动</li>
    </ul>
  </li>
  <li>全局神经工作空间理论 GNWH
    <ul>
      <li>有利：意识的某些方面确实可以在前额叶皮层中表现出来</li>
      <li>不利：
        <ul>
          <li>并非一切意识活动都可以在此有所反映</li>
          <li>实验发现只有体验开始时才有信息扩布的证据，但未能发现在体验结束时也有扩布</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>124位意识研究者，其中包括巴尔斯（Bernard J. Baars）、丹纳特（Daniel C. Dennett）和丘奇兰（Patricia S. Churchland）等著名学者，联名发布一封公开信，指责《科学》《自然》等媒体做了不实报道，并指责IIT是伪科学。抓住了和托诺尼的Φ值有关的问题全盘否定。</li>
</ul>

<h2 id="作者观点">作者观点</h2>

<ul>
  <li>解决意识的神经相关集合的问题呢，还是解决查默斯的困难问题，科赫似乎把这两个问题认为是同一个问题，作者不同意</li>
  <li>科赫/托诺尼和德阿纳的对抗性合作实际上是关公战秦琼。</li>
  <li>124人公开信故意回避了在对抗性合作中的IIT实际上是指后脑理论，而和Φ没有直接关系，因此他们对对抗性合作的批评就像是枪打稻草人，但是他们对Φ理论的批评却有其合理之处。
    <ul>
      <li>像意识这样复杂的对象能不能用公理化的方法来进行研究</li>
      <li>在托诺尼的5条公理中也故意丢掉了对意识来说最关键的“主观性”，不完备的公理系统推导出来的Φ指标，只能度量意识作为神经系统超越其各组成部分所含信息量的总和的信息量这一个方面，而非意识本身。</li>
    </ul>
  </li>
  <li>全局神经元工作空间假设对于进入意识标记的解释没问题，但对他的假设是否也能够解释意识或者即使只是进入意识本身持怀疑态度。
    <ul>
      <li>“进入意识标记”并不是“进入意识”本身，就像某人的签名并不就是他自己一样。</li>
      <li>除了用受试者的主观报告来判断他们是否意识到了什么之外，德阿纳的工作并没有触及意识的主观性问题。</li>
    </ul>
  </li>
  <li>后脑理论的一个重要依据是采用“无报告”范式的研究方法，但是也有科学家根据一些报道称在采用这种方法时，也能在前额叶皮层检测到有活动，因此把这种方法贬之为“误导”。
    <ul>
      <li>不过被贬一方则坚称“从总体上来说，前额叶皮层对意识来说既非必要，也不充分，这和皮层后部完全不同。”</li>
    </ul>
  </li>
  <li>动物行为学家戴维·培尼亚-古斯曼提出意识包括三个重要方面：主观意识、情感意识和元认知意识。
    <ul>
      <li>主观意识：主观存在感和具身的自我觉知感</li>
      <li>元认知意识：自己知道自己是有认知能力</li>
    </ul>
  </li>
</ul>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[整合信息理论 (IIT) vs. 全局神经工作空间理论 (GNWH)]]></summary></entry><entry><title type="html">·文革史笔记-2.4.1 | 对贺龙的诬陷和折磨</title><link href="https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-4-1" rel="alternate" type="text/html" title="·文革史笔记-2.4.1 | 对贺龙的诬陷和折磨" /><published>2023-12-18T00:00:00-06:00</published><updated>2023-12-18T00:00:00-06:00</updated><id>https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-4-1</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-4-1"><![CDATA[<p>本章各节相对独立，基本上每节迫害一个老干部。时间线放在一起过于混乱，故分节作笔记。</p>

<p>第一节讲贺龙。</p>

<h2 id="格式说明">格式说明</h2>

<ul>
  <li><em>下划线</em> 包括的内容，是对应章节的内容梗概。</li>
  <li><code class="language-plaintext highlighter-rouge">&gt; blockquote</code> 引用的内容是对原文的摘抄。</li>
  <li>没有下划线的内容，是根据引文的个人引申和感想。<del>一般来说是引文在前，感想在后</del>。各段感想之间以分割线 <code class="language-plaintext highlighter-rouge">&lt;hr /&gt;</code> 区分。</li>
  <li>无序列表的内容，是对应章节的时间线整理。很多章节的时间线互相重叠，这在第二卷和第三卷中会更加常见，所以我另外维护了一份总的时间线，笔记全部完成后发布。</li>
</ul>

<h2 id="内容梗概">内容梗概</h2>

<p><em>贺龙由于在延安期间与林彪之妻叶群结仇，文革中遭到林彪报复，被迫害致死。</em></p>

<h2 id="摘抄随想">摘抄随想</h2>

<blockquote>
  <p>在1980年中华人民共和国最高人民检察院特别检察厅起诉控告林彪、江青等十名主犯时，宋治国写的诬告信的原件公布了。下面抄录其中一部分内容：</p>

  <p>一、“罗瑞卿的家里办公桌，玻璃板底下压着一张照 片，其中有贺（龙）、薛明、罗（瑞卿）、郝治平四人合影，但没有主席的照片。”</p>

  <p>二、“我觉得贺（龙）与罗（瑞卿）、彭（真）、杨尚昆反党分子来住很为密切。他们经常密谈”。“常去他 （指贺龙）家的人神态不正常。”</p>

  <p>三、“贺（龙）本人自己房同里亲自保管着一支精致进口的小手枪，夜间睡觉时常压在自己的枕头底下，外出 带上。不知为了什么？”</p>

  <p>四、他对警卫人员的教育不是以政治挂帅，面是业务挂帅。如教育人家如何将枪法练妤，并要求每个螫卫人员要练得百发百中。</p>

  <p>五、“听说体委自动销毁了一百二十部电台，此亊甚为可疑”。</p>

  <p>六、据说贺龙家曾经“在电话上安过一个窃听器。”</p>

  <p>可以看出，曾窃居中国领导高位的林彪、叶群等人，在争 权夺利、发泄私愤时是多么无聊。</p>

</blockquote>

<p>能吐的槽都让作者吐了……</p>

<hr />

<blockquote>
  <p>上海“一月风暴” 派生出来的是整个中国好象航行在惊涛骇浪的无际海洋，颠簸得失去了控制。群众批斗“走资派”的“革命暴力行动”，经过数月的摸索实践不断升级。安徴省委第一书记李葆华，铁道都部长吕正操等人被迫站在无遮无蔽的大卡车上，顶着凛冽的寒风在天安门前游斗；杨勇作为“三反分子”被北京军区的造反派揪了出来；煤炭工业部部长张霖之被北京矿业学院的学生揪去，被戴上六十斤重的铁帽子接受批斗，还被关押了四十多天，最后被皮鞭活活抽打致死，中南海里也折腾起来了，许多中央负责人都受到冲击。</p>

</blockquote>

<hr />

<p>林彪还在军队最高层人士间有意诽谤贺龙，说：</p>

<blockquote>
  <p>“这个人手伸得很长，不仅军队到处伸手而且地方也到处伸手，贺龙搞大比武是个大阴谋，罗端卿的后台就是贺龙。贺龙是个大土匪，是土匪出身，拍肩膀，介绍老婆，搞旧军队一套，四十年来灵魂深处是个大野心家，吃了饭不干事，经常在家请客，拉拢于部。许多军区、军种兵种都有他的人，贺龙是反毛主席的。他是一个封建地主野心家，混入党内捞资本”他“到处搞夺权、搞山头主义，反而不炮轰……”</p>

</blockquote>

<hr />

<blockquote>
  <p>面对着许多老干部被加上莫须有的罪名挨揪被斗，面对着自己今天的处境，贺龙心潮澎湃，难以平静。他对“左”有了 切身的体会，对“洪湖肃反扩大化”等问题有了新的认识。三 月七日，贺龙写成了关于地区肃反扩大化问题的报吿，请周恩来转呈毛泽东。他多么希望已经发展得如火如荼的“文化大革命”能从中吸取点儿教训，能珍惜革命的宝责财产——干部和群众啊！</p>

</blockquote>

<p>所以贺龙在“洪湖肃反扩大化”中干了什么？</p>

<hr />

<p>贺龙的最后时光：</p>

<blockquote>
  <p>一九六九年冬春季节，身患糖尿病多年的七十三岁高龄的贺龙，不仅基本的饭菜营养得不到保证，而且必须不间断服用的降糖药物也“供不应求”。他与薛明合用的一块毛巾破得只剩下四个边儿，衣服鞋袜补了又补，连替换的都没有。在当时打出的“医疗要为专案服务”的招牌下，有一天，又突然以照顾为名，派去一个医生，强行取走了他们想方设法保留下来的一点点儿必备药品。不久，借口暖气坏了，不保证供暧，室内温度经常在6C左右。一天夜里，贺龙夫妇又被强迫搬离周恩来为他们安排的居所，住进了山下的一间房子里。</p>

  <p>从此，贺龙夫妇的生话条件每况愈下。饭吃不饱，菜则经常是白水煮白菜，糠萝卜，老得象甘蔗皮似的豆角，需要用饮食配合治疗的糖尿病病人不时被难以忍受的饥锇感和无法抑制的食欲骚扰得心烦意乱，一辈子戎马生涯的元帅，在夺得政权的和平年代里，听见杀猪声“真想吃点猪耳朵”的愿望至死都没能实现。用糖水抗拒饥锇感，对于糖尿病病人来说，犹如投石下并，但这却是贺龙可能得到的唯一“治疗”。</p>

  <p>贺龙的身体被拖垮了，虚弱得连独自迈步都有困难，由于缺乏必要的营养，人体抵抗力下洚，再加上糖尿病本身又是病菌滋生的温床，致使贺龙的脚气感染经久不愈，这反过来又加重了糖尿病，一九六九年六月八日早晨，贺龙连续呕吐，呼吸急促，全身软弱无力。当薛明再三求请医生时，一位姓王的医生才来打了止吐针。糖尿病敢中毒引起的全身反应继续蔓延着，直到晚上八时，在专案人员直接拿握“救治”的前提下，来了两名医生，做了简单的检査后，就给贺龙输注葡萄糖生理盐水，并声称“糖尿病昏迷了”。贺龙意识到情况或许要急转直下，乘医生不在时，对薛明说，”要小心，他们要害死我。”当时医生怀疑贺龙是药物中毒，但化验结果表明，病人并未服用过量的药品，医生仍不顾糖尿病人尿糖和血糖的多少，按中毒处理，一夜之间输了二千毫升葡萄糖液。</p>

  <p>一九六九年六月九日破晓之后，北京三〇一医院派来医生接贺龙去住院。贺龙表示，“我没有昏迷，我不能去住院，那个医院不是我住的地方。”但是，作为“组织决定”，贺龙服从了。贺龙告别了妻子，独自躺在救护车里。汽车驶向被人们视为能起死回生的现代化医院，但贺龙在迷蒙中却觉得是在走向坟墓。</p>

  <p>下午三时零九分，也就是贺龙离开薛明后整整六小时零九分钟时，贺龙的心脏停止了跳动。两年半的半幽禁生活中，贺龙最惦念的是他的孩子们，然而元帅却没能盼到见自己儿女们一面的这一天。他带着冤枉，带着爱，更带着恨，孤寂地走出了人生世界。</p>

  <p>贺龙生前，血糖曾高达1700毫克％。他死于高渗性非酮症糖尿病昏迷。</p>

</blockquote>

<p>最后的血糖单位应当有误，但原文如此。</p>

<p>医护人员在明知其有糖尿病的情况下大量注射葡萄糖水，可以说是谋杀。</p>

<h2 id="时间线">时间线</h2>

<ul>
  <li>1933年
    <ul>
      <li>熊贡卿以贺龙“早年友好”的名义来会贺龙，以谋策反，贺龙当即识破其阴谋，下令逮捕了熊贡卿并处以枪决。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>抗日战争时期
    <ul>
      <li>抗日战争时期，叶群在南京曾经在国民党所控制的电台当广播员，与国民党人士常有往来，并参加过国民党 CC 派学生“演讲比赛”，宣传三民主义，获得了第一名。同时，她还与一个叫“战斗”的 CC 派外围组织有来往。为此，当时共产党地下组织派薛明正式找叶群谈话，叶群表示，“要重新考虑今后要走的路”。【2.4.对贺龙的诬陷和折磨】</li>
    </ul>
  </li>
  <li>解放战争时期
    <ul>
      <li>林彪、贺龙去重庆参加谈判。贺龙夫人薛明重新提起抗战中叶群与国民党的活动，将叶群拉到中组部组织科长王鹤寿处。林彪、贺龙返回延安后，贺龙对林彪直言不讳要林彪“提高警惕”。林彪当时没有表态，后来说“整风是残害青年”。【2.4.对贺龙的诬陷和折磨】</li>
      <li>贺龙与毛泽东谈话时说过，1937年党中央派朱德、刘伯承、贺龙、林彪去洛阳参加蒋介石召开的会议时，林彪对蒋介石抱有幻想。林彪曾公开说与蒋介石谈判时，要说些好话。为此与贺龙发生意见分歧。贺龙还问过陶铸“知道不知道林彪在历史上有问题。”【2.4.对贺龙的诬陷和折磨】</li>
      <li>1946年，林彪率军进入东北，在东北特地为叶群的这件事平反。【2.4.对贺龙的诬陷和折磨】</li>
    </ul>
  </li>
  <li>解放后
    <ul>
      <li>贺龙担任了副总理，授元帅军衔，兼管体育工作。【2.4.对贺龙的诬陷和折磨】</li>
    </ul>
  </li>
  <li>1966年2月4日
    <ul>
      <li>1966年初，中央军委指示，北京军区为卫戍区组建一个团，准备负担民兵训练任务。一时找不到营房，而北京各大学有部分师生在农村搞“四清”，空出一些房屋，卫戍区向北京大学、中国人民大学借房。借房时间与“二月提纲”事件的时间接近，被当作“二月兵变”事件。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1966年7月27日
    <ul>
      <li>7月，在“怀疑一切”的感应下，北京大学校团委的一个干部贴出《触目惊心的二月兵变》大字报，提出卫戍区借房是要搞兵变的假说，并认为是“彭真、刘仁企图搞政变的准备”。康生有意在此事上大做文章。【2.4.对贺龙的诬陷和迫害】</li>
      <li>康生在北师大群众大会上公开宣称后，中央文革定下了“二月兵变”事件。还加进了“贺龙私自调动军队，在北京郊区修了碉堡”等骇人听闻的军事色彩。北京各院校开始搜集“二月兵变”的素材，以至于把1966年2月，彭真为首的北京市委在北大试点的到北京郊区半工半读，也加进“二月兵变”中去了。贺龙的“罪行”增加了新的内容。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1966年8月25日
    <ul>
      <li>8月，空军准备在北京召开一次会议，几位同事找到贺龙，对报喜不报忧的不良作风不满，对突然通知会议停开有意见。贺龙劝说道：“可以给他们提意见”，被林彪得知。【2.4.对贺龙的诬陷和折磨】林彪制造了以吴法宪为正确的一方，另一方要夺权的“八·二五”反革命事件，把贺龙定为后台。将一些与贺龙公事过的干部逮捕、逼供。要求吴法宪“要警惕和防备”。同时召见李作鹏，告诉他“要注意贺龙，他实际上是罗瑞卿的后台”。【2.4.对贺龙的诬陷和折磨】</li>
    </ul>
  </li>
  <li>1966年9月3日
    <ul>
      <li>吴法宪把他写给毛泽东的有关贺龙的材料送给了林彪。【2.4.对贺龙的诬陷和折磨】</li>
    </ul>
  </li>
  <li>1966年9月7日
    <ul>
      <li>李作鹏也给林彪写了一封有关贺龙问题的信件。【2.4.对贺龙的诬蔑和迫害】</li>
      <li>叶群多次向中央军委办公厅警卫处处长宋治国唠叨贺龙的材料，要宋治国写信揭发，并嘱咐：“要以你主动向我反映情况的口气写，不要以我叫你了解的口气写。”9月7日至24日，宋治国根据叶群的材料，写了4封揭发信给林彪。【2.4.对贺龙的诬蔑和迫害】</li>
    </ul>
  </li>
  <li>1966年9月14日
    <ul>
      <li>毛泽东接到吴法宪的信后，把贺龙请到自家的游泳池会面。毛把吴的信给贺龙看。毛宽慰贺龙，贺龙表示要找吴法宪谈，毛泽东劝阻，最后贺龙仍觉得应当找他们解释一下，毛表示“也可以”。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1966年9月19日
    <ul>
      <li>毛泽东再次在他的游泳池接见了贺龙，表示“问题解决了，没事了。”【2.4.对贺龙的诬陷和迫害】</li>
      <li>贺龙亲自到林彪家征求意见。林彪说：“你的问题可大可小，今后要注意一个问题，支持谁，反对谁。”贺龙说：“谁反对毛主席，我就反对谁”。林彪认定在与贺龙的较量中不能手软。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1966年9月27日
    <ul>
      <li>9月7日至24日，宋治国的揭发信送到林彪办公室主任叶群那里时，叶群当着办公室3位秘书问宋：“你写的这些材料是否都是事实？是，我们就送；不是，我们就不送了。”宋治国心领神会。叶群又叫3位秘书写了一份《关于宋治国写材料情况的说明》，用以证明写信是宋治国的自发行为。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1966年12月30日
    <ul>
      <li>江青和叶群达成的互相交换迫害对方“仇人”的协议向前推进了。江青找到贺龙的儿子贺鹏飞。不久又在一次群众大会上宣布，“要把贺龙端出来。”【2.4.对贺龙的诬陷和迫害】</li>
      <li>接着，贺龙的家被抄。一家人被包围在“坚决揪斗”贺龙的巨大声浪中，多次搬迁，然呼叫接踵而至。贺龙一家求援于周恩来，周接通贺龙住处的电话，要围攻的群众撤走，邀请贺龙夫妇住进中南海的自己家中。一月风暴后，林彪把贺龙作为打倒对象在军内宣布后，周恩来把贺龙继续留在中南海已不可能。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1967年1月18日
    <ul>
      <li>周恩来约请李富春、江青与贺龙进行一次正式谈话。江青拒不参加，还指使群众在会议时间，将宣传车开到中南海外，用高音喇叭叫喊“打倒贺龙”等口号。周恩来对贺龙说：“为了你的安全，另外给你找个安静的地方，去休息一下。”【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1967年1月19日
    <ul>
      <li>凌晨3时，周恩来派杨德中和负责贺龙警卫工作的杨青成护送贺龙夫妇到北京近郊山区。为了安全，周安排中途换车，不让带工作人员，以便严格保密。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1967年3月7日
    <ul>
      <li>三月七日，贺龙写成了关于洪湖地区肃反扩大化问题的报吿，请周恩来转呈毛泽东。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1967年9月-10月
    <ul>
      <li>九月间，贺龙正式被列为专案审查对象。十月以后，便断 绝了与周恩来总理的一切联系。经林彪一伙人的批准，从外地调派来一个脑系科护士，冒充卫戍区医生，把原来护理贺龙的医生换走。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1968年5月12日
    <ul>
      <li>以中央名义，把全国体育系统定为“独立王国”，从1952年起就兼任国家体委主任的贺龙便成了 体育系统头号“反革命修正主义分子”并因此受到攻击。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1968年5月16日
    <ul>
      <li>康生说，“贺龙历史上就搞投敌叛变，现在不可能没有问题。”康生的一句话使得贺龙在精神上和生活 上所受到的折磨又成倍增长。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1968年9月18日
    <ul>
      <li>给贺龙送去了一封以中央军委办 公厅的名义写的信，要他交待“1933年，蒋介石派熊贡卿到湘鄂西与贺龙是怎样谈判的？参加谈判的是哪些人？最后达成计么协议？……”贺龙看完这封信，不停地书写“冤枉”、“寃枉”几个字。“我本来就是在共产党最背时的时候参加革命的，所以，无论多么背时，我都不怕。”【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1969年6月8日
    <ul>
      <li>贺龙连续呕吐，呼吸急促，全身软弱无力。医生才来打了止吐针。晚上八时，给贺龙输注葡萄糖生理盐水，并声称“糖尿病昏迷了”。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
  <li>1969年6月9日
    <ul>
      <li>破晓之后，北京三〇一医院派来医生接贺龙去住院。下午三时零九分，贺龙的心脏停止了跳动。【2.4.对贺龙的诬陷和迫害】</li>
    </ul>
  </li>
</ul>

<hr />

<blockquote>
  <p>回到本系列的目录：<a href="/blog/articles/great-cultural-revolution-ten-years-0">.pdf | 高皋、严家其《文化大革命十年史》笔记</a></p>
</blockquote>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[本章各节相对独立，基本上每节迫害一个老干部。第一节讲贺龙。]]></summary></entry><entry><title type="html">·文革史笔记-2.3 | 搭起上升的舷梯</title><link href="https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-3" rel="alternate" type="text/html" title="·文革史笔记-2.3 | 搭起上升的舷梯" /><published>2023-11-26T00:00:00-06:00</published><updated>2023-11-26T00:00:00-06:00</updated><id>https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-3</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-3"><![CDATA[<h2 id="格式说明">格式说明</h2>

<ul>
  <li><em>下划线</em> 包括的内容，是对应章节的内容梗概。</li>
  <li><code class="language-plaintext highlighter-rouge">&gt; blockquote</code> 引用的内容是对原文的摘抄。</li>
  <li>没有下划线的内容，是根据引文的个人引申和感想。<del>一般来说是引文在前，感想在后</del>。各段感想之间以分割线 <code class="language-plaintext highlighter-rouge">&lt;hr /&gt;</code> 区分。</li>
  <li>无序列表的内容，是对应章节的时间线整理。很多章节的时间线互相重叠，这在第二卷和第三卷中会更加常见，所以我另外维护了一份总的时间线，笔记全部完成后发布。</li>
</ul>

<h2 id="内容梗概">内容梗概</h2>

<p><em>林彪从积极投身文革，到跻身中共党、国二号人物的过程。</em></p>

<p><em>本章几乎未涉及整人的桥段，以林彪在宣传口的发挥为主。积极投身之前整掉的障碍，和荣誉加身之后的报复自己的旧仇，分别在之前之后两章。</em></p>

<h2 id="摘抄随想">摘抄随想</h2>

<p>无。</p>

<p>对林这种拍马屁的手法，没有学习的兴趣。更重要的是，这种积极马屁导致了自己走上权力斗争的前台，风险太高，收益波动太大，因此是一种失败的教训。这一点上，林远不如周。</p>

<h2 id="时间线">时间线</h2>

<ul>
  <li>1966年5月18日
    <ul>
      <li>林彪作了一个 实际上是会议总结的讲话。他除了对彭、罗、陆、杨问题作了结论之外，为了迎合毛泽东的心理，用大量篇幅谈了政权及政变 问题，歌颂毛泽东是马克思、恩格斯、列宁之上的天才，因此，“毛主席活到那一天，九十岁，一百多岁，都是我们党的最高领袖，他的话还都是我们行动的准则。谁反对他，全党共诛之，全国共讨之。在他身后，如果有谁作赫鲁晓夫那样的秘密拫告，一定是野心家，一定是大坏蛋。全党共诛之，全国共讨之！”而与会者似乎得到这祥一种印象，在中国共产党内， 林彪的地位异常重要了。【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年8月1日
    <ul>
      <li>中国共产党八届十一中全会开始。会议朗间，林彪经常与毛泽东见面，商谈“文化大革命”中的大事。毛泽东还利用林彪直接指挥中央文革小组，以北京为起点推进“文化大革命”。【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年8月8日
    <ul>
      <li>林彪接见中央文革小组成员后，已经活跃在“文化大革命”第一线的中央文革的鼓噪声更大了，他们更起劲地支持反对刘少奇的群众，鼓动对毛泽东的崇拜。【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年8月10日
    <ul>
      <li>林彪两次接见军队高级 干部，明确指出，“今后我们的干部政策应该是，谁反对毛主席，就罢谁的官，谁反对突出政治，就罢谁的官。不管他有天 大的本事。”【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年8月11日、12日
    <ul>
      <li>林彪指使叶群两次（第一次）找中国人民解放军总参谋部作战部副部长雷英夫，将他们诬陷刘少奇的材料口授给他，以便让他写出有关刘少奇的材料。【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年8月12日
    <ul>
      <li>中共中央八届十一中全会闭幕。【2.3.从《五·一六通知》到八届十一中全会】</li>
      <li>林彪指使叶群两次（第二次）找中国人民解放军总参谋部作战部副部长雷英夫，将他们诬陷刘少奇的材料口授给他，以便让他写出有关刘少奇的材料。【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年8月13日
    <ul>
      <li>林彪看了雷英夫写的（诬陷刘少奇的）材料。【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年8月14日
    <ul>
      <li>林彪将雷英夫找到家里，要他用给林彪、毛泽东写信的形式将材料递交上来。当天，雷英夫就将信和村料递送给了林彪，林彪则立即批送 给江青，“酌转”毛泽东。【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年8月18日
    <ul>
      <li>在毛泽东开创的接见红卫兵的活动中，林彪代表党中央在会上讲话，他说，“我首先代表我们伟大领袖毛 主席，向大家问好！ ”在一阵阵狂热的欢呼声中，林彪在人们 心目中的地位上升了，在某种程度上，他取得了代表毛泽东的资格。到处宣传的“毛主席和他的亲密战友林彪同志”使党中央终于变成了“以毛主席为首、林副主席为副的党中央”。【2.3.从《五·一六通知》到八届十一中全会】</li>
    </ul>
  </li>
  <li>1966年10月9日
    <ul>
      <li>会议开始后不久，林彪向全军发出号召： “把活学活用毛泽东著作的群众运动推向新阶段”【2.3.“第二号人物”】</li>
    </ul>
  </li>
  <li>1966年10月11日
    <ul>
      <li>《解放军报》发表《坚决响应林彪同志号召把活学活用毛主席著作群众运动推尚新阶 段》的社论，并在群众中广泛地组织学习。【2.3.“第二号人物”】</li>
    </ul>
  </li>
  <li>1966年10月12日
    <ul>
      <li>林彪在中央工作会议小组会上多次发言。【2.3.“永不停火的战争”】</li>
    </ul>
  </li>
  <li>1966年10月25日
    <ul>
      <li>林彪发表的长篇演讲，极端颂扬毛泽东的伟大，他说，“毛泽东思想同马克思列宁主义是统一的东西， 只有时代的区别，是更髙级的更发展了的马克思列宁主义。”【2.3.“永不停火的战争”】</li>
    </ul>
  </li>
  <li>1966年10月27日
    <ul>
      <li>为纪念“毛泽东号”机车命名二十周年，林彪书写了“毛泽东思想指引下的人民革命是历史前进的火车头”的题词。题词的手迹被广泛宣传，人们虽然觉得这位“副统帅”的字写得不怎么样，伹不失他在群众中的威望。【2.3.“永不停火的战争”】</li>
    </ul>
  </li>
  <li>1966年10月28日
    <ul>
      <li>10月9日召开的中央工作会议结束。【2.3.“第二号人物”】</li>
    </ul>
  </li>
  <li>1966年12月3日
    <ul>
      <li>林彪在中央政洽局常委会议上，就工交系统的“文化大革命”和抓革命促生产的关系问题作了讲话。不久，又在中央工交系统“文化大革命”座谈会上作了长篇发言。【2.3.“永不停火的战争”】</li>
    </ul>
  </li>
  <li>1966年12月16日
    <ul>
      <li>林彪又为《毛主席语录》写了《再版前言》，并在群众中掀起了学习、背诵《再版前言》的热潮，结果是，林彪的名字更加响亮了，林彪的权威也随之提高了。【2.3.“永不停火的战争”】</li>
    </ul>
  </li>
  <li>1967年10月1日
    <ul>
      <li>庆祝大会上，林彪“代表我们伟大的领袖毛主席，代表党中央，代表中华人民共和国政府，代表中央军委，代表中央文革 小组讲话。他在毛泽东视察了华北、中南和华东地区后，对一年多来的“文化大革命”作了总结，他说，“我们的无产阶级文化大革命，已经取得了决定性的胜利”。并用列举“文化大革命”中的一系列成绩，来说明无产阶级“文化大革命”成绩是“最大最大最大”。【2.3.林彪的总结：“最大最大最大”、“最小最小最小”】</li>
    </ul>
  </li>
</ul>

<hr />

<blockquote>
  <p>回到本系列的目录：<a href="/blog/articles/great-cultural-revolution-ten-years-0">.pdf | 高皋、严家其《文化大革命十年史》笔记</a></p>
</blockquote>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[林彪从积极投身文革，到跻身中共党、国二号人物的过程中，在宣传口的发挥。]]></summary></entry></feed>