<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="zh-CN"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://mountaye.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mountaye.github.io/blog/" rel="alternate" type="text/html" hreflang="zh-CN" /><updated>2023-10-11T09:37:39-05:00</updated><id>https://mountaye.github.io/blog/feed.xml</id><author><name>MountAye</name></author><entry><title type="html">.css | TailwindCSS 笔记</title><link href="https://mountaye.github.io/blog/articles/notes-on-TailwindCSS" rel="alternate" type="text/html" title=".css | TailwindCSS 笔记" /><published>2023-10-11T00:00:00-05:00</published><updated>2023-10-11T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/notes-on-TailwindCSS</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/notes-on-TailwindCSS"><![CDATA[<blockquote>
  <p>一直听说“全栈项目 = Next.js + TailwindCSS + HeadlessUI”
但是 TailwindCSS 到底是啥，之前一直妹整明白</p>

</blockquote>

<h2 id="思路utility-first">思路：utility-first</h2>

<blockquote>
  <p><a href="https://tailwindcss.com/docs/utility-first">https://tailwindcss.com/docs/utility-first</a></p>

</blockquote>

<p>传统设计需要根据 html 中的结构，在 CSS 中给相应的元素/class/id 定义所需要的所有样式 style。</p>

<p>问题很明显：</p>

<ul>
  <li>最低效的情况下，每个 <code class="language-plaintext highlighter-rouge">&lt;div/&gt;</code> 都要定义一个 class。</li>
  <li>每个定义里包含若干不同的性质，背景颜色、字体、边框样式等等都挤在一个大括号里，耦合过强。</li>
</ul>

<p>TailwindCSS 的思路名叫 utility-first, 预先定义一批“性质-取值”的组合，每个组合给出一个有规律命名的类。使用时，一个 <code class="language-plaintext highlighter-rouge">&lt;div/&gt;</code> 后面声明几个甚至几十个不同的 class。缺点就是不灵活了，每个性质只搭配有限几种取值，且类的数量很多。好处是——</p>

<ul>
  <li>不用绞尽脑汁给类取名字</li>
  <li>CSS 不会再变大了（也可以说已经大得不能再大了）</li>
  <li>修改视觉效果时更换一个类，而不是修改类的定义，也就不用担心对类的修改在自己不记得的地方生效。</li>
</ul>

<p>与之相对的另一种思路，是直接用 html 元素的 style 属性，或者用 module.css 让样式只对某一 component 生效。TailwindCSS 派对这种方法的批评是：</p>

<ul>
  <li>每个取值都是设计者拍脑袋想出来的，一个项目要拍太多次脑袋，容易风格不统一。</li>
  <li>难以做 responsive design （真的吗？很怀疑）</li>
  <li>难以处理鼠标悬浮、聚焦等等状态（这玩意应该由 CSS 处理吗？）</li>
</ul>

<p>utility-first 在维护性方面收到批评的一点是，很多地方要不断重用相同的组合，少了一点封装和抽象。TailwindCSS 对此的辩护是，可以抽象出 components 和 partials（见下节），或者使用编辑器的多光标功能。（绷……）</p>

<h2 id="技术细节">技术细节</h2>

<ul>
  <li>样式重用</li>
  <li>状态，比如鼠标悬浮、聚焦</li>
  <li>Responsive design</li>
  <li>夜间模式</li>
  <li>添加自定义样式</li>
  <li>函数和 directives</li>
</ul>

<h3 id="状态比如鼠标悬浮聚焦">状态，比如鼠标悬浮、聚焦</h3>

<p>在正常的类名字之前添加 <code class="language-plaintext highlighter-rouge">&lt;状态&gt;:</code> 标记，用来指明在相应状态时的样式。这些状态可以叠加，之间用 <code class="language-plaintext highlighter-rouge">:</code> 分隔。比如 <code class="language-plaintext highlighter-rouge">&lt;button class="hover:bg-sky-700"&gt;</code></p>

<p>可以标记的状态：<a href="https://tailwindcss.com/docs/hover-focus-and-other-states#appendix">https://tailwindcss.com/docs/hover-focus-and-other-states#appendix</a></p>

<ul>
  <li>Pseudo-classes
    <ul>
      <li>举例： <a href="https://tailwindcss.com/docs/hover-focus-and-other-states#pseudo-class-reference">https://tailwindcss.com/docs/hover-focus-and-other-states#pseudo-class-reference</a>
        <ul>
          <li><code class="language-plaintext highlighter-rouge">hover:</code>, <code class="language-plaintext highlighter-rouge">focus:</code>, <code class="language-plaintext highlighter-rouge">active:</code></li>
          <li><code class="language-plaintext highlighter-rouge">first:</code>, <code class="language-plaintext highlighter-rouge">last:</code>, <code class="language-plaintext highlighter-rouge">odd:</code>, <code class="language-plaintext highlighter-rouge">even:</code></li>
          <li><code class="language-plaintext highlighter-rouge">required:</code>, <code class="language-plaintext highlighter-rouge">invalid:</code>, <code class="language-plaintext highlighter-rouge">disabled:</code>: 主要用在 <code class="language-plaintext highlighter-rouge">&lt;form&gt;</code> 中</li>
        </ul>
      </li>
      <li>需要父元素的状态信息时，
        <ul>
          <li>如果因为嵌套，存在多个 group 时，可以给每一个父元素的类命名 <code class="language-plaintext highlighter-rouge">group/&lt;name&gt;</code>, 子元素的类名需要写在伪类的后面，有点反直觉 <code class="language-plaintext highlighter-rouge">group-hover/&lt;name&gt;:</code></li>
          <li>给父元素添加 <code class="language-plaintext highlighter-rouge">group</code> 的 class，然后给需要变化的子元素添加 <code class="language-plaintext highlighter-rouge">group-&lt;pseudo-class&gt;:</code> 前缀。如 <code class="language-plaintext highlighter-rouge">group-hover:</code></li>
          <li>当需要更细致的选择时，可以在子元素的 group 后面添加自定义内容，如 <code class="language-plaintext highlighter-rouge">group-[.is-published]:</code>, <code class="language-plaintext highlighter-rouge">group-[:nth-of-type(3)_&amp;]:</code></li>
        </ul>
      </li>
      <li>需要姊妹元素的状态信息时：
        <ul>
          <li>给被跟踪的姊妹元素添加 <code class="language-plaintext highlighter-rouge">peer</code> class, 被跟踪的元素只能在跟踪元素的前面。</li>
          <li>其余特性类比 group</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="https://tailwindcss.com/docs/hover-focus-and-other-states#pseudo-elements">Pseudo-elements</a>, like <code class="language-plaintext highlighter-rouge">::before</code>, <code class="language-plaintext highlighter-rouge">::after</code>, <code class="language-plaintext highlighter-rouge">::placeholder</code>, and <code class="language-plaintext highlighter-rouge">::selection</code>
    <ul>
      <li>写作 <code class="language-plaintext highlighter-rouge">before:</code> 等等，默认相当于 <code class="language-plaintext highlighter-rouge">before:content-['*']</code></li>
      <li>当想要调整 content 以外的性质时，需要指明 <code class="language-plaintext highlighter-rouge">before:block</code>, <code class="language-plaintext highlighter-rouge">before:absolute</code>, <code class="language-plaintext highlighter-rouge">before:-inset-1</code> 等等</li>
      <li><code class="language-plaintext highlighter-rouge">placeholder:</code> 用于调整表格中代填内容的样式</li>
      <li><code class="language-plaintext highlighter-rouge">file:</code> 上传文件按钮的样式</li>
      <li><code class="language-plaintext highlighter-rouge">list:</code> 列表开头的</li>
      <li><code class="language-plaintext highlighter-rouge">selection:</code> （鼠标）选中文字之后的样式</li>
      <li><code class="language-plaintext highlighter-rouge">first-line:</code>, <code class="language-plaintext highlighter-rouge">first-letter:</code> 杂志常用的首行、首字母的特殊样式</li>
    </ul>
  </li>
  <li><a href="https://tailwindcss.com/docs/hover-focus-and-other-states#media-and-feature-queries">Media and feature queries</a>, like responsive breakpoints, dark mode, and <code class="language-plaintext highlighter-rouge">prefers-reduced-motion</code>
    <ul>
      <li>结合响应式设计 responsive design 一节，使用 <code class="language-plaintext highlighter-rouge">md:</code>, <code class="language-plaintext highlighter-rouge">lg:</code> 等前缀</li>
      <li><code class="language-plaintext highlighter-rouge">dark:</code> 黑夜模式</li>
      <li><code class="language-plaintext highlighter-rouge">motion-reduce:</code> 用户选择屏蔽动画效果时的样式，<code class="language-plaintext highlighter-rouge">motion-safe:</code> 只有不屏蔽动画才会生效的样式</li>
      <li><code class="language-plaintext highlighter-rouge">portrait</code>,<code class="language-plaintext highlighter-rouge">landscape</code> 屏幕朝向</li>
      <li><code class="language-plaintext highlighter-rouge">print:</code> 打印时的样式</li>
      <li><code class="language-plaintext highlighter-rouge">supports-[...]</code> 当浏览器支持某种特性时启动。也可在 <code class="language-plaintext highlighter-rouge">tailwind.config.js</code> 文件中设置 <code class="language-plaintext highlighter-rouge">theme.supports</code> 变量</li>
    </ul>
  </li>
  <li><a href="https://tailwindcss.com/docs/hover-focus-and-other-states#attribute-selectors">Attribute selectors</a>, like <code class="language-plaintext highlighter-rouge">[dir="rtl"]</code> and <code class="language-plaintext highlighter-rouge">[open]</code>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">aria-*</code> modifier to conditionally style things based on <a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/Attributes">ARIA attributes</a>.</li>
      <li><code class="language-plaintext highlighter-rouge">data-[key=value]</code> data 参数的值</li>
      <li><code class="language-plaintext highlighter-rouge">ltr:</code> &amp; <code class="language-plaintext highlighter-rouge">rtl:</code> 从右往左书写的文字</li>
      <li><code class="language-plaintext highlighter-rouge">open:</code> &amp; <code class="language-plaintext highlighter-rouge">close:</code> 用于可以展开的元素</li>
      <li>自定义选择符：用中括号包围，<code class="language-plaintext highlighter-rouge">&amp;</code> 开头选择元素，下划线表示空格，如 <code class="language-plaintext highlighter-rouge">[&amp;:nth-child(3)]:</code>, <code class="language-plaintext highlighter-rouge">[&amp;_p]:mt-4</code>, <code class="language-plaintext highlighter-rouge">[@supports(display:grid)]:grid</code></li>
    </ul>
  </li>
</ul>

<h3 id="responsive-design">Responsive design</h3>

<table>
  <thead>
    <tr>
      <th>Breakpoint prefix</th>
      <th>Minimum width</th>
      <th>CSS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sm</td>
      <td>640px</td>
      <td>@media (min-width: 640px) { … }</td>
    </tr>
    <tr>
      <td>md</td>
      <td>768px</td>
      <td>@media (min-width: 768px) { … }</td>
    </tr>
    <tr>
      <td>lg</td>
      <td>1024px</td>
      <td>@media (min-width: 1024px) { … }</td>
    </tr>
    <tr>
      <td>xl</td>
      <td>1280px</td>
      <td>@media (min-width: 1280px) { … }</td>
    </tr>
    <tr>
      <td>2xl</td>
      <td>1536px</td>
      <td>@media (min-width: 1536px) { … }</td>
    </tr>
  </tbody>
</table>

<p>移动端优先的思路，所有尺寸限定的都是大于该宽度时的样式。</p>

<p>要限定上限，要用 <code class="language-plaintext highlighter-rouge">max-&lt;size&gt;:</code> 比如 <code class="language-plaintext highlighter-rouge">md:max-xl:flex</code></p>

<p>要想自定义 breakpoints，可以看 <a href="https://tailwindcss.com/docs/breakpoints">customizing breakpoints documentation</a>.</p>

<p>也可以单独设定 <code class="language-plaintext highlighter-rouge">min-[320px]:</code>, <code class="language-plaintext highlighter-rouge">max-[600px]:</code> 等等</p>

<h3 id="夜间模式">夜间模式</h3>

<p>默认使用操作系统的设定。</p>

<p>要想手动设定，须在 tailwind.config.js 中加入</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/** @type {import('tailwindcss').Config} */</span>
<span class="nx">module</span><span class="p">.</span><span class="nx">exports</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">darkMode</span><span class="p">:</span> <span class="dl">'</span><span class="s1">class</span><span class="dl">'</span><span class="p">,</span>
  <span class="c1">// ...</span>
<span class="p">}</span>
</code></pre></div></div>

<p>然后含有 <code class="language-plaintext highlighter-rouge">class=’dark’</code> 的元素的子元素都时夜间模式的效果</p>

<p>这个<a href="https://tailwindcss.com/docs/dark-mode#supporting-system-preference-and-manual-selection">链接</a>包含了同时兼容系统设置和手动设置的做法</p>

<h3 id="样式重用">样式重用</h3>

<ul>
  <li>编辑器的多光标功能：<a href="https://code.visualstudio.com/docs/editor/codebasics#_multiple-selections-multicursor">https://code.visualstudio.com/docs/editor/codebasics#_multiple-selections-multicursor</a></li>
  <li>标记语言的循环语法</li>
  <li>react 等框架的 component 概念</li>
  <li><code class="language-plaintext highlighter-rouge">@apply</code> and <code class="language-plaintext highlighter-rouge">@layer</code> in the <a href="https://tailwindcss.com/docs/functions-and-directives#layer">Functions &amp; Directives</a> documentation.</li>
  <li>避免提前过度抽象</li>
</ul>

<h3 id="添加自定义样式">添加自定义样式</h3>

<ul>
  <li>编辑 <code class="language-plaintext highlighter-rouge">tailwind.config.js</code>, 文档在此：<a href="https://tailwindcss.com/docs/theme">https://tailwindcss.com/docs/theme</a></li>
  <li><a href="https://tailwindcss.com/docs/adding-custom-styles#arbitrary-properties">Arbitrary properties</a> 和 <a href="https://tailwindcss.com/docs/adding-custom-styles#arbitrary-variants">arbitrary variants</a></li>
  <li><a href="https://tailwindcss.com/docs/adding-custom-styles#using-css-and-layer">Using CSS and @layer</a>, 使用多个 CSS 文件时，需在 postcss.config.js 文件中添加 <code class="language-plaintext highlighter-rouge">plugins: {’postcss-import’:  {},}</code> 字段</li>
  <li><a href="https://tailwindcss.com/docs/adding-custom-styles#writing-plugins">Writing plugins</a></li>
</ul>

<h3 id="函数和-directives">函数和 directives</h3>

<p>directives 是 CSS 文件中的 <code class="language-plaintext highlighter-rouge">@</code> 开头的语句</p>

<p><code class="language-plaintext highlighter-rouge">@layer</code> 用来把一些需要打包的样式绑在一起，后面三个取值：base, components, utilities</p>

<p><code class="language-plaintext highlighter-rouge">@apply</code> 后面接 TailwindCSS 已经定义的类，表示把类的定义移植于此处。</p>

<p><strong><a href="https://tailwindcss.com/docs/functions-and-directives#config"><code class="language-plaintext highlighter-rouge">@config</code></a></strong> 指定所在 CSS 文件需要使用的 TailwindCSS 配置文件，放在 @import 语句后面</p>

<div class="language-css highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">@tailwind</span> <span class="n">base</span><span class="p">;</span>
<span class="k">@tailwind</span> <span class="n">components</span><span class="p">;</span>
<span class="k">@tailwind</span> <span class="n">utilities</span><span class="p">;</span>

<span class="k">@layer</span> <span class="n">base</span> <span class="p">{</span>
  <span class="nt">h1</span> <span class="p">{</span>
    <span class="err">@apply</span> <span class="err">text-2xl;</span>
  <span class="p">}</span>
  <span class="nt">h2</span> <span class="p">{</span>
    <span class="err">@apply</span> <span class="err">text-xl;</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="k">@layer</span> <span class="n">components</span> <span class="p">{</span>
  <span class="nc">.btn-blue</span> <span class="p">{</span>
    <span class="err">@apply</span> <span class="err">bg-blue-500</span> <span class="py">hover</span><span class="p">:</span><span class="n">bg-blue-700</span> <span class="n">text-white</span> <span class="n">font-bold</span> <span class="n">py-2</span> <span class="n">px-4</span> <span class="n">rounded</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="k">@layer</span> <span class="n">utilities</span> <span class="p">{</span>
  <span class="nc">.filter-none</span> <span class="p">{</span>
    <span class="nl">filter</span><span class="p">:</span> <span class="nb">none</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="nc">.filter-grayscale</span> <span class="p">{</span>
    <span class="nl">filter</span><span class="p">:</span> <span class="n">grayscale</span><span class="p">(</span><span class="m">100%</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div>

<p>TailwindCSS 还自定义了一些 CSS 函数：</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">theme()</code>: 返回 config 文件中的参数，比如</p>

    <div class="language-css highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nc">.content-area</span> <span class="p">{</span>
    <span class="nl">height</span><span class="p">:</span> <span class="n">calc</span><span class="p">(</span><span class="m">100vh</span> <span class="n">-</span> <span class="n">theme</span><span class="p">(</span><span class="n">spacing</span><span class="m">.12</span><span class="p">));</span>
  <span class="p">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><a href="https://tailwindcss.com/docs/functions-and-directives#screen"><code class="language-plaintext highlighter-rouge">screen()</code></a>: 以预定义的 breakpoint 为参数，避免代码中间出现硬编码的数值</p>

    <div class="language-css highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="k">@media</span> <span class="n">screen</span><span class="p">(</span><span class="n">sm</span><span class="p">)</span> <span class="p">{</span> <span class="c">/* ... */</span> <span class="p">}</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="在-nextjs-项目中安装-tailwindcss">在 Next.js 项目中安装 TailwindCSS</h2>

<blockquote>
  <p><a href="https://nextjs.org/docs/pages/building-your-application/styling/tailwind-css">https://nextjs.org/docs/pages/building-your-application/styling/tailwind-css</a></p>

</blockquote>

<p>在命令行</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npm <span class="nb">install</span> <span class="nt">-D</span> tailwindcss postcss autoprefixer
npx tailwindcss init <span class="nt">-p</span>
</code></pre></div></div>

<p>如此会在项目的根目录新建 <code class="language-plaintext highlighter-rouge">tailwind.config.js</code> &amp; <code class="language-plaintext highlighter-rouge">postcss.config.js</code> 文件</p>

<p>然后编辑 <code class="language-plaintext highlighter-rouge">tailwind.config.js</code> 文件，添加需要用到 TailwaindCSS 的路径</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/** @type {import('tailwindcss').Config} */</span>
<span class="nx">module</span><span class="p">.</span><span class="nx">exports</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">content</span><span class="p">:</span> <span class="p">[</span>
    <span class="dl">'</span><span class="s1">./app/**/*.{js,ts,jsx,tsx,mdx}</span><span class="dl">'</span><span class="p">,</span> <span class="c1">// Note the addition of the `app` directory.</span>
    <span class="dl">'</span><span class="s1">./pages/**/*.{js,ts,jsx,tsx,mdx}</span><span class="dl">'</span><span class="p">,</span>
    <span class="dl">'</span><span class="s1">./components/**/*.{js,ts,jsx,tsx,mdx}</span><span class="dl">'</span><span class="p">,</span>
 
    <span class="c1">// Or if using `src` directory:</span>
    <span class="dl">'</span><span class="s1">./src/**/*.{js,ts,jsx,tsx,mdx}</span><span class="dl">'</span><span class="p">,</span>
  <span class="p">],</span>
  <span class="na">theme</span><span class="p">:</span> <span class="p">{</span>
    <span class="na">extend</span><span class="p">:</span> <span class="p">{},</span>
  <span class="p">},</span>
  <span class="na">plugins</span><span class="p">:</span> <span class="p">[],</span>
<span class="p">}</span>
</code></pre></div></div>

<p>在全局样式表 <code class="language-plaintext highlighter-rouge">styles/globals.css</code> 中引入 TailwaindCSS</p>

<div class="language-css highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">@tailwind</span> <span class="n">base</span><span class="p">;</span>
<span class="k">@tailwind</span> <span class="n">components</span><span class="p">;</span>
<span class="k">@tailwind</span> <span class="n">utilities</span><span class="p">;</span>
</code></pre></div></div>

<p>在 <code class="language-plaintext highlighter-rouge">pages/_app.js</code> 中引入全局样式表。<code class="language-plaintext highlighter-rouge">@</code> 的含义不明</p>

<div class="language-jsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// These styles apply to every route in the application</span>
<span class="k">import</span> <span class="dl">'</span><span class="s1">@/styles/globals.css</span><span class="dl">'</span>
<span class="k">import</span> <span class="nx">type</span> <span class="p">{</span> <span class="nx">AppProps</span> <span class="p">}</span> <span class="k">from</span> <span class="dl">'</span><span class="s1">next/app</span><span class="dl">'</span>
 
<span class="k">export</span> <span class="k">default</span> <span class="kd">function</span> <span class="nf">App</span><span class="p">({</span> <span class="nx">Component</span><span class="p">,</span> <span class="nx">pageProps</span> <span class="p">}:</span> <span class="nx">AppProps</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="p">&lt;</span><span class="nc">Component</span> <span class="si">{</span><span class="p">...</span><span class="nx">pageProps</span><span class="si">}</span> <span class="p">/&gt;</span>
<span class="p">}</span>
</code></pre></div></div>

<p>在项目的 components 中使用 TailwindCSS 的类：</p>

<div class="language-tsx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">export</span> <span class="k">default</span> <span class="kd">function</span> <span class="nf">Page</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">return</span> <span class="p">&lt;</span><span class="nt">h1</span> <span class="na">className</span><span class="p">=</span><span class="s">"text-3xl font-bold underline"</span><span class="p">&gt;</span>Hello, Next.js!<span class="p">&lt;/</span><span class="nt">h1</span><span class="p">&gt;</span>
<span class="p">}</span>
</code></pre></div></div>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[一直听说“全栈项目 = Next.js + TailwindCSS + HeadlessUI”，但是 TailwindCSS 到底是啥，之前一直妹整明白]]></summary></entry><entry><title type="html">如是我闻 | 生成式人工智能</title><link href="https://mountaye.github.io/blog/articles/afaik-generative-ai" rel="alternate" type="text/html" title="如是我闻 | 生成式人工智能" /><published>2023-09-11T00:00:00-05:00</published><updated>2023-09-11T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/afaik-generative-ai</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/afaik-generative-ai"><![CDATA[<h2 id="生成式语言模型">生成式语言模型</h2>

<h3 id="模型">模型</h3>

<ul>
  <li>OpenAI/GPT</li>
  <li>Claude</li>
  <li><code class="language-plaintext highlighter-rouge">bloomchat</code>, 可以商用 [<a href="https://github.com/sambanova/bloomchat">GitHub</a>]</li>
  <li><code class="language-plaintext highlighter-rouge">falcon40B</code>
    <ul>
      <li>apache 2.0 许可证，可商用[<a href="http://huggingface.co/tiiuae">huggingface</a>]</li>
      <li>gpt3 的性能，更少的运算资源，其中Falcon 7B可以跑在苹果Mac上 [<a href="https://twitter.com/rickawsb/status/1666148546285043714">推特</a>]</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">TigerBot</code>: 一款国产自研的多语言任务大模型，70亿参数和1800亿参数两个版本 [<a href="https://github.com/TigerResearch/TigerBot">GitHub</a>]</li>
  <li><code class="language-plaintext highlighter-rouge">QLoRA</code>: 单个GPU，ChatGPT 99%的能力，消费级GPU微调12个小时就可以达到97%的ChatGPT水平，4B就可以保持16B精度的效果 [<a href="https://www.notion.so/Endocytic-trafficking-promotes-vacuolar-enlargements-for-fast-cell-expansion-rates-in-plants-6b8f0a313c184ccba9fb5a035bb04a0e?pvs=21">论文</a>] [<a href="https://www.notion.so/pdf-14a94950d61c42d3b03bb132f7655589?pvs=21">GitHub</a>]</li>
  <li><code class="language-plaintext highlighter-rouge">MBT 30B</code>: 开源商用模型为数不多的选择里出现了一个比Falcon 40B更好的模型 [<a href="https://twitter.com/fi56622380/status/1672137540281974784">Twitter</a>]</li>
  <li><code class="language-plaintext highlighter-rouge">GLM-6B</code> &amp; <code class="language-plaintext highlighter-rouge">GLM2-6B</code>: 智谱AI发布，对学术研究完全开放，并且在完成企业登记获得授权后，允许免费商业使用。[<a href="https://twitter.com/GanymedeNil/status/1679892021807550465">Twitter</a>][<a href="https://mp.weixin.qq.com/s?__biz=MzkxNjMzMjM3NA==&amp;mid=2247484214&amp;idx=1&amp;sn=e42153f987a74d1ffc7882f7cc09670d">微信公众号@GLM大模型</a>]</li>
  <li><code class="language-plaintext highlighter-rouge">Llama 2</code>: Meta开源大语言模型Llama 2，可免费商用. [<a href="https://mp.weixin.qq.com/s/9pcmrCEyp2AQsL3MbPYx-Q?utm_source=pocket_saves">微信</a>介绍]
    <ul>
      <li>Jim Fan 评论 [<a href="https://twitter.com/dotey/status/1681553916373135362?utm_source=pocket_saves">推特，翻译</a>]</li>
      <li>很多团队几乎都达成共识， RLHF 不重要，SFT 就够了。现在 Llama2 的论文说 RLHF 非常非常重要。[<a href="https://twitter.com/oran_ge/status/1681793774685659136?utm_source=pocket_saves">推特</a>]</li>
      <li><code class="language-plaintext highlighter-rouge">LLaMA-2-7B-32K</code>, context为32K的模型 [<a href="https://twitter.com/JefferyTatsuya/status/1685423475979325440">推特</a>][<a href="https://twitter.com/togethercompute/status/1685048832168714240">Twitter</a>]</li>
    </ul>
  </li>
</ul>

<h3 id="基于模型直接可用的产品">基于模型，直接可用的产品</h3>

<ul>
  <li>OpenAI/GPT
    <ul>
      <li>ChatGPT
        <ul>
          <li>2023年6月13日，GPT提供了函数调用，让ChatGPT来自己调用函数。[<a href="https://twitter.com/cryptonerdcn/status/1668733300070924288">Twitter</a>][<a href="https://openai.com/blog/function-calling-and-other-api-updates">OpenAI</a>][<a href="https://twitter.com/dotey/status/1668728109376450566">用法 Twitter@宝玉</a>]</li>
        </ul>
      </li>
      <li>ChatGPT - Code Interpreter
        <ul>
          <li>介绍 [<a href="https://twitter.com/fuyufjh/status/1684191835210809344">推特</a>][<a href="https://www.youtube.com/watch?v=4wGlRrir_u4">YouTube</a>]</li>
          <li>《ChatGPT 探索：Code Interpreter 高级指南》[<a href="https://mp.weixin.qq.com/s/K_csi1oWDv5tEaeeKSlvwA?utm_source=pocket_saves">微信@浮之静</a>]</li>
          <li>源码可能被套出。[<a href="https://twitter.com/fuergaosi/status/1679457847237820416">Twitter</a>]</li>
          <li>对 code interpreter 的逆向工程 [<a href="https://twitter.com/Yampeleg/status/1678045605527003136">Twitter</a>][<a href="https://mem.ai/p/xyy8ULiAce1BecTxnU0M">Mem</a>]</li>
        </ul>
      </li>
      <li>OpenAI API
        <ul>
          <li>2023年8月23日，OpenAI 开放了 GPT-3.5 的微调的API [<a href="https://twitter.com/dotey/status/1694207797351616703">推特</a>]</li>
        </ul>
      </li>
      <li>OpenAI on Azure 内置了一个内容过滤器 [<a href="https://twitter.com/jw1dev/status/1666613728106938368">推特1</a>][<a href="https://twitter.com/jw1dev/status/1666622878962548740">推特2</a>]</li>
      <li><code class="language-plaintext highlighter-rouge">forefront</code>: 完全免费 GPT-4 的工具 [<a href="https://accounts.forefront.ai/">登录</a>]，大概基于 <code class="language-plaintext highlighter-rouge">gptfree-ts</code> [<a href="https://github.com/xiangsx/gpt4free-ts">GitHub</a>]</li>
      <li><code class="language-plaintext highlighter-rouge">BratGPT</code>: ChatGPT的激进版本。[<a href="https://bratgpt.com/">官网</a>]</li>
      <li><code class="language-plaintext highlighter-rouge">SmartStudy</code>: 提供文本文档，创建10个问题的小测验。[<a href="https://smartstudy.streamlit.app/">官网</a>]</li>
      <li><code class="language-plaintext highlighter-rouge">XrayGPT</code>: 通过给定的 X 光片来促进围绕胸部 X 光片的自动化分析的研究。[<a href="https://twitter.com/CarsonYangk8s/status/1661588037892198401">GitHub</a>]</li>
      <li><code class="language-plaintext highlighter-rouge">FinGPT</code>: 类似BloomBerg的开源方案，RLHF 和 Lora 的低秩技术 [<a href="https://twitter.com/JefferyTatsuya/status/1668433680887615488">Twitter</a>]</li>
    </ul>
  </li>
  <li>微软
    <ul>
      <li>BingAI
        <ul>
          <li>本地部署方案 [<a href="https://twitter.com/geekbb/status/1665692703055552513">推特</a>][<a href="https://github.com/adams549659584/go-proxy-bingai">GitHub</a>]</li>
        </ul>
      </li>
      <li>VsCode Copilot</li>
      <li>Office 365 Copilot: 每月每名用户30美元. [<a href="https://www.theverge.com/2023/7/18/23798627/microsoft-365-copilot-price-commercial-enterprise">verge</a>][<a href="https://mp.weixin.qq.com/s/9pcmrCEyp2AQsL3MbPYx-Q?utm_source=pocket_saves">微信</a>]</li>
    </ul>
  </li>
  <li>Claude+
    <ul>
      <li>例子：阅读多份行业报告 [<a href="https://twitter.com/iamshaynez/status/1684398211958730753">推特</a>]</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Llama</code>
    <ul>
      <li>llama2.ai: 一个基于 llama 2 的聊天机器人，非官方。[<a href="https://llama2.ai/">网站</a>]</li>
      <li>WizardCoder 34B based on Code Llama 写代码 [<a href="https://twitter.com/dotey/status/1696202647269785875">推特</a>]</li>
    </ul>
  </li>
  <li>WebGLM: 清华开源的带网络搜索功能的 GLM 实现 [<a href="https://www.notion.so/pdf-14a94950d61c42d3b03bb132f7655589?pvs=21">GitHub</a>]</li>
  <li>mendable: 根据开发文档进行问答 [<a href="https://www.mendable.ai/usecases/documentation">官网</a>]</li>
  <li>阅读 PDF 文档
    <ul>
      <li>Humata.ai</li>
      <li>explainpaper</li>
      <li>ChatPDF</li>
      <li>[<a href="https://twitter.com/oran_ge/status/1683432444169711616?utm_source=pocket_saves">对比</a>] Claude2支持超长上下文，摘要信息量更大，更适合长文提炼。ChatDOC 具有页码溯源、表格解析、原文定位功能，数据找得准，也方便二次验证，能够限制大语言的幻觉问题。</li>
    </ul>
  </li>
  <li>Obsidian-copliot: 快速获取文字的核心观点</li>
  <li>视频内容梗概
    <ul>
      <li>Glarity: 浏览器插件，基于ChatGPT和字幕生成Youtube摘要，20秒看完梗概 [<a href="https://twitter.com/starzqeth/status/1640867876109422595">Twitter</a>]</li>
      <li>summarize-tech: 5分钟了解长视频的要点. [<a href="https://twitter.com/starzqeth/status/1640867876109422595">Twitter</a>]</li>
    </ul>
  </li>
  <li>webpilot: 可联网可读网页链接的插件 Webpilot 推出的 Chrome 版插件 [<a href="https://chrome.google.com/webstore/detail/webpilot-copilot-for-all/biaggnjibplcfekllonekbonhfgchopo?utm_source=link">chrome</a>]</li>
</ul>

<h3 id="模型教程评论二次开发">模型教程、评论、二次开发</h3>

<ul>
  <li>一般性原理
    <ul>
      <li>《Prompt 编写模式》[<a href="https://prompt-patterns.phodal.com">phodal</a>]</li>
      <li>《LLM+Embedding构建问答系统的局限性及优化方案》[<a href="https://zhuanlan.zhihu.com/p/641132245">知乎</a>]</li>
      <li>基于检索的 LM，外挂一个数据库用来检索。[<a href="https://twitter.com/cosmtrek/status/1678077835418955781">推特</a>][<a href="https://acl2023-retrieval-lm.github.io/">GitHub.io</a>]</li>
      <li>一篇泼冷水的论文 [<a href="https://aclanthology.org/2023.findings-acl.426/">ACL Anthology</a>]</li>
      <li>即刻出的Prompt调试工具。[<a href="https://twitter.com/vista8/status/1678784460786135040">Twitter</a>][<a href="https://promptknit.com/">官网</a>]</li>
    </ul>
  </li>
  <li>GPT
    <ul>
      <li>GPT best practice [<a href="https://platform.openai.com/docs/guides/gpt-best-practices?utm_source=pocket_saves">OpenAI</a>]</li>
      <li>Andrew Ng 吴恩达 &amp; Isa Fulford from OpenAI 《Build system with <a href="https://twitter.com/hashtag/ChatGPT?src=hashtag_click">#ChatGPT</a> API》[推特@<strong><a href="https://twitter.com/JefferyTatsuya">金田達也</a></strong>]
        <ul>
          <li>借助 CoT 的思路，翻译字幕，返回正确的 JSON 格式 [<a href="https://twitter.com/dotey/status/1665476562219573249">推特</a>]</li>
          <li>同样的加入了CoT（Chain of Though）的Prompt，如果让GPT打印出来步骤，效果非常好，但是如果不让GPT打印（省点token，以及更容易解析），那么GPT就会偷懒 [<a href="https://twitter.com/dotey/status/1668736426286915590">Twitter</a>1][<a href="https://twitter.com/dotey/status/1664335473500626946">Twitter2</a>]</li>
        </ul>
      </li>
      <li>熊猫吃短信是 Twitter@威力狈 开发的垃圾短信过滤工具。将其与 GPT 结合的一些讨论
        <ul>
          <li><a href="https://twitter.com/waylybaye/status/1664253928970788864">Twitter@威力狈</a>：尝试了下用 ChatGPT 自动标注数据，效果太差了。</li>
          <li><a href="https://twitter.com/dotey/status/1669028955842650139">Twitter@宝玉</a>：通常如果我写的话，会做一些小调整</li>
          <li><a href="https://twitter.com/IIInoki">Twitter@IIInoki</a>：是的，感觉八爷用 API 用得有点糙……就只是很简单的 prompt 达到的效果都还不错</li>
        </ul>
      </li>
      <li>《ChatGPT 越过山丘之后，再来谈谈 LLM 应用方向》[<a href="https://quail.ink/orange/p/chatgpt-cross-over-the-hills-and-discuss-llm-application-directions">橘子汽水铺</a>]</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">LangChain</code>:
    <ul>
      <li>官方教程 [<a href="https://twitter.com/LangChainAI/status/1665009694627250176">推特</a>][<a href="https://blog.streamlit.io/langchain-tutorial-1-build-an-llm-powered-app-in-18-lines-of-code/">streamlit</a>]</li>
      <li>一个使用 LangChain 和 GPT Index 的教程 [<a href="https://leanpub.com/langchain">leanpub, 收费</a>][<a href="https://getpocket.com/read/3839490971">Pocket</a>]</li>
      <li>LangChain for LLM Application Development 基于LangChain的大语言模型应用开发 [<a href="https://t.co/JXV1SBI2OA">YouTube</a>]
        <ul>
          <li>基于Embedding的文档问答。stuff, map reduce, refine, map rerank [<a href="https://twitter.com/dotey/status/1667790801420558342">Twitter@宝玉</a>]</li>
        </ul>
      </li>
      <li>Chanin Nantasenamat: LangChain tutorial #1: Build an LLM-powered app in 18 lines of code [<a href="https://blog.streamlit.io/langchain-tutorial-1-build-an-llm-powered-app-in-18-lines-of-code/?utm_source=pocket_saves">streamlit</a>]</li>
      <li>把一篇很长的 PDF 内容喂给 ChatGPT，然后向他提问
        <ul>
          <li>纯 JS 开源工具推荐 [<a href="https://twitter.com/Barret_China/status/1638119945749037056">推特</a>]</li>
          <li>用 <code class="language-plaintext highlighter-rouge">LangChain</code> 六七行代码就可以搞定了 [<a href="https://js.langchain.com/docs/get_started/introduction">LangChain</a>]</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">AutoChain</code>
    <ul>
      <li>介绍 [<a href="https://twitter.com/zhangjintao9020/status/1683996172980199429">推特</a>][<a href="https://github.com/Forethought-Technologies/AutoChain">GitHub</a>]</li>
      <li>《我为什么放弃了 LangChain》[<a href="https://twitter.com/Barret_China/status/1683135367862718465">推特</a>][<a href="https://mp.weixin.qq.com/s/jIbz9JYc8-_ua-QLENX__A">微信</a>] 推友提出的 AutoChain 替代方案 [<a href="https://twitter.com/Barret_China/status/1684211570186887170?utm_source=pocket_saves">推特</a>]</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">OpenDAN</code>: 为各类 AI 模块提供运行环境，并提供它们之间的互操作性协议。可创建诸如律师、医生、教师，甚至男女朋友等角色 [<a href="https://twitter.com/Barret_China/status/1666455683758161920">GitHub</a>]</li>
  <li>“视频语音↔文字”任务相关
    <ul>
      <li>指定视频URL，识别文字，翻译 [<a href="https://github.com/lewangdev/autotranslate">GitHub</a>]</li>
      <li><code class="language-plaintext highlighter-rouge">WhisperX</code>: 按照单词对齐时间戳，生成的字幕都是完整的句子 [<a href="https://github.com/m-bain/whisperX">GitHub</a>]。[<a href="https://twitter.com/dotey/status/1667394662628204546">Twitter@宝玉</a>] 写了一个可以根据 YouTube Url 识别 YouTube 字幕的 <a href="https://github.com/JimLiu/whisper-subtitles/blob/main/whisperx_youtube_subtitle.ipynb">Jupyter Notebook</a></li>
      <li><code class="language-plaintext highlighter-rouge">audiocraft</code>: audio processing and generation with deep learning. [<a href="https://github.com/facebookresearch/audiocraft">GitHub</a>]</li>
      <li><a href="https://twitter.com/Barret_China/status/1684218981639413760">[推特]</a> 小作文</li>
      <li><code class="language-plaintext highlighter-rouge">yt-dlp</code> 一行命令下载视频字幕的工具，不需 puppeteer 无头浏览器 [<a href="https://twitter.com/Barret_China/status/1684228477644570624">推特</a>][<a href="https://github.com/yt-dlp/yt-dlp">GitHub</a>]</li>
    </ul>
  </li>
  <li>ChatGPT + AI agent + ScholarAI + Noteable 写的小综述 [<a href="https://t.co/eqVc2LIfSz">链接失效</a>]</li>
  <li><code class="language-plaintext highlighter-rouge">MusicGen</code>: 将文本和旋律转化为完整乐曲 [<a href="https://twitter.com/Fenng/status/1668141100610248705">Twitter</a>][<a href="https://www.notion.so/3753e42dc4204a99ab83a725b655a632?pvs=21">ReadHub</a>]</li>
  <li><code class="language-plaintext highlighter-rouge">MMS</code>: 一个声音模型 [<a href="https://huggingface.co/docs/transformers/main/en/model_doc/mms">HuggingFace</a>]</li>
  <li><code class="language-plaintext highlighter-rouge">FRVR Forge</code>: AI-Powered End-to-End Game Creation [<a href="https://twitter.com/FRVRGames/status/1669758477789540365">Twitter</a>][<a href="https://www.notion.so/ai-University-Cloud-8078b4682e454a5fba982f67e4530498?pvs=21">官网</a>]</li>
</ul>

<h3 id="开发平台">开发平台</h3>

<p>Runpod: 租用 GPU 跑模型并创建 Serverless API 一站式服务，最低只要0.2刀/hr。[<a href="http://runpod.io">官网</a>]</p>

<h3 id="杂项">杂项</h3>

<ul>
  <li>2023年5月27日、28日，OpenAI 使用 Sentry 审计工具封禁来自中国的用户，解决方案：
    <ul>
      <li>路由器 Clash 规则 [<a href="https://twitter.com/wey_gu/status/1663003950214438912?utm_source=pocket_saves">推特</a>]</li>
      <li>改用 Azure OpenAI service [<a href="https://twitter.com/zhangjintao9020/status/1662865819041402880">推特</a>]</li>
      <li>Cloudflare WARP [<a href="https://haoel.github.io/">左耳朵</a>]</li>
    </ul>
  </li>
</ul>

<h2 id="生成式图像模型">生成式图像模型</h2>

<p>2023年5月31日，Adobe 添加人工智能相关功能 generative fill。[<a href="https://twitter.com/CodeByPoonam/status/1663824055164887040">推特</a>]</p>

<ul>
  <li>配置要求极低，连Win掌机都能跑，但是不能断网。[<a href="https://twitter.com/OfflineHelper/status/1666042746866663424">推特</a>]</li>
  <li>填充将横屏的视频转换为竖屏。[<a href="https://twitter.com/Alex_Cerrato/status/1681677307843432449">推特</a>]</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">MidJourney</code></p>

<ul>
  <li>在提示词中添加相机镜头信息。[<a href="https://twitter.com/4rtofficial/status/1663310457854099458">推特</a>]</li>
  <li>zoom [<a href="https://twitter.com/jesselaunz/status/1674210886695923712">Twitter</a>]</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">StableDiffusion</code></p>

<ul>
  <li>Eric Fu: 训练指南. [<a href="https://ericfu.me/stable-diffusion-finetune-guide/?utm_source=pocket_reader">Coding Husky</a>]</li>
  <li>文字或者符号融合生成图片 [<a href="https://twitter.com/op7418/status/1680223090138316800">Twitter</a>][<a href="https://mp.weixin.qq.com/s/rvpU4XhToldoec_bABeXJw">微信</a>]</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">StyleDrop</code>: Google 基于 MUSE 的样式迁移 transformer [<a href="https://twitter.com/recatm/status/1665056017107886080">推特</a>][<a href="https://styledrop.github.io/">GitHub.io</a>]</p>

<p><code class="language-plaintext highlighter-rouge">Redream</code>: 从视频到二次元动画 [<a href="https://twitter.com/heyBarsee/status/1665034805384290307">推特</a>][<a href="https://github.com/Fictiverse/Redream">GitHub</a>]</p>

<p><code class="language-plaintext highlighter-rouge">Runway</code> Gen-2: 文本生成视频和图片生成视频, 4 秒钟 [<a href="https://twitter.com/op7418/status/1666461595818504192">推特</a>][<a href="https://app.runwayml.com/login">需注册</a>]</p>

<p>一个 AI 视频解决方案，来自南洋理工，代码尚未开源 [<a href="https://twitter.com/op7418/status/1669026494885285888">Twitter</a>] [<a href="https://anonymous-31415926.github.io/">GitHub.io</a>][<a href="https://twitter.com/rickawsb/status/1672310994390126593">Twitter2</a>][<a href="https://arxiv.org/abs/2306.07954">arxiv</a>]</p>

<p><code class="language-plaintext highlighter-rouge">AWPortrait1.1</code>: 图像生成 [<a href="https://twitter.com/dynamicwangs/status/1673730591462928385">Twitter</a>][<a href="https://www.liblibai.com/modelinfo/721fa2d298b262d7c08f0337ebfe58f8">LibLibai</a>]</p>

<p><code class="language-plaintext highlighter-rouge">Anything AI</code>: 可以取代照片中的任何物体。免费，不需要注册. [<a href="https://www.anything-ai.com/">官网</a>]</p>

<p><code class="language-plaintext highlighter-rouge">PixelLab</code>: 草图创建2D图像. [<a href="https://www.pixellab.ai/">官网</a>]</p>]]></content><author><name>MountAye</name></author></entry><entry><title type="html">.doc | 博客咨文 2023</title><link href="https://mountaye.github.io/blog/articles/state-of-blog-2023" rel="alternate" type="text/html" title=".doc | 博客咨文 2023" /><published>2023-08-15T00:00:00-05:00</published><updated>2023-08-15T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/state-of-blog-2023</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/state-of-blog-2023"><![CDATA[<p>以往过年的时候，都会在博客写一篇年终总结。今年没写，主要是当时觉得自己春季学期结束就要毕业了，需要努力工作，至少要摆出一副努力工作的样子。</p>

<p>之前的文章里大概也提到了，论文投稿之前各种小修小补、准备参加三月会、投简历、面试且自以为成功找到了工作，毕业已经是再努力也没办法在春季学期结束之前完成的事情，于是博客恢复了更新。</p>

<p>跟老板说了一下，毕业推后到了暑假，<del>上周</del> 上上周完成。45 分钟的演讲，理论上无限实际上 20 来分钟的问答，难度最高的环节是演讲之前打领带，温莎结。</p>

<p>越到这种时候越觉得，如果把人生比作道路，更准确的喻体应该是高速公路，显然不是因为速度高，而在于其中一个一个的进出口，真正留给人选择的机会有限，剩下的时间和路程里，能改变行程的基本都是事故。所谓答辩，不过是出口收费站过 ETC，其重要性还不如和老板半闲聊时，假装不经意地说自己想毕业。</p>

<hr />

<h3 id="数据">数据</h3>

<p>毕竟是博客咨文，说回博客和各个内容平台的事。</p>

<p>博客的流量比较稳定，每天都能有一点，一月无事也能有 300-400 访问，有更新的时候能到 600-700，碰巧击中流量密码的话能上千。最近新加了 Google Ads，迄今累计收益 50 美分，成了名副其实的洋五毛。(~_~;)</p>

<p>微信公众号一如既往地店大欺客，一篇文章的展示周期在三天以内，不加星标的话几乎看不到推送，打开率基本是关注人数的 1/10。两次例外，可能是击中了流量密码，分别是 《python decorator 装饰器笔记》和《PINN 基于物理的神经网络笔记》，完全不知道为什么，后一篇文章甚至因为格式问题，根本没放读书笔记的主体部分，就因为提了一句《三体》？总之关注人数比上次年终总结多了两倍，接近 200 人了…… (−_−＃)</p>

<p>Matters 吧，不提了，简体中文作者还剩几个？基本上成了微信被删文的备份站。(╯°□°）╯︵ ┻━┻</p>

<p>作为对比，我的前女友·隔壁课题组的学妹·托洛茨基主义者·未明子粉丝，在 B 站发了一个未明子式的视频（一个白板写写画画，旁边一张帅脸，讲授哲学，时长半小时甚至一小时以上），内容是从哲学角度批判高等教育的布尔乔亚劣根性，一把子攒了几千粉丝，几十万观看量。我只看了文字稿和评论区——我看不懂，但我大受震撼.jpg</p>

<p>两相比较，一言以蔽之，曰：彻底失败。</p>

<hr />

<h3 id="反省">反省</h3>

<p>既然已经做了流量生意，说自己从来就不在乎做没做好是在是有点虚伪了。</p>

<p>和前女友的交往，确实让我学到了很多东西。很多“常识”，要么不是那么寻“常”，要么只是观点而不是知“识”。世界的全貌，观众的参差，是从小走学习考试独木桥的我，需要时刻提醒自己才能意识到的现实。</p>

<p>另一方面，自己作为一个内容消费者，看自己喜欢和订阅的自媒体的时候，也试图摸索出来一些成功密码。一言以蔽之曰：同义反复，频率恰当（前提是以视频为媒介，微博既出，阅读已死）</p>

<p>看自媒体生产的内容这件事，毕竟是一个娱乐行为，只能从各种正事之外挤出来。正事不论多少，每天每周基本是固定的，自媒体要想干得长久，就必须把自己嵌入观众的生活习惯中，尽可能降低观众点进你作品的注意力成本。</p>

<p>频率要求必然导致同义反复，批量生产已被证明是算法青睐的模式。在前期已经做出规模的自媒体大号已经拉起团队，进行专业化分工的当下，个人还想作出点东西，这些模式大概率是自己之前的专业技能，比如做饭之于王刚师傅，下象棋之于徐银川特大，玩红警之于月亮3。暂时能想到的例外，就是时评键政，在此不表。</p>

<hr />

<h3 id="嘴硬">嘴硬</h3>

<p>作为一个物理博士·生物狗·小镇做题家·眼红美本富二代的苦逼研究生，我写博客的本意是践行费曼学习法，我的本职工作是学习，不是练习。</p>

<p>练习可以同义反复，甚至以耐得住枯燥为法门；学习不行，学习需要耐得住枯燥，但不能以枯燥为荣。</p>

<p>在公理化体系被发明之后，学习需要尽快摆脱同义反复的阶段，从排比句式的知识中识别逻辑关系，添加进自己已有的知识体系，用『逻辑推演』替代『倒背如流』，整个过程就叫领悟，如果这个相变过程比较快速，就叫顿悟。</p>

<p>很多学习类网红搞不清这个道理，也做不到，所以学习笔记一篇一篇地晒，一考试就是大专。</p>

<p>熟练之后，领悟也许可以重复，但无法保证频率的稳定，因为你不能保证所学的每件东西难度都相同。既然不能同义反复，这注定是个于流量无缘的分类，我们也看到，有些学人涉足流量之后，确实变了。</p>

<hr />

<h3 id="求职">求职</h3>

<p>说到本职工作，之前谈好的博士后岗位无了。</p>

<p>交上两封推荐信之后，那老哥来和我视频联系。他所在大学的研究生罢工活动前不久取得了胜利，博士和博士后的工资待遇提高了不少。老哥的入职 offer 是在工运之前谈妥的，所以启动资金不足以支付新的博士后工资。老哥推荐了一个基金会的资助机会，让我去申请一下。</p>

<p>毕业前 Paul 办了个在家聚会，同学听了我的事之后骂声一片，说这一看就说明之前只打算给最低工资。此事我办得也不太体面，只在申请截止日期之前，用 ChatGPT 随手糊了一套申请材料。差老哥自己的推荐信，他看了一眼说算了。然后说还是瞄准其他资助机会，我也没说啥，基本默认结束了。</p>

<p>老板写推荐信那周的全系茶歇，为了在同仁面前装叉，跟我说他认识那老哥的博导，我不如直接去找她，毕竟博后的门派声望重要得很——我心说，难道门派对博士就不重要了吗。</p>

<p>发邮件过去完全没有回复，老板又给我列了个接近20人的名单。用 ChatGPT 写邮件挨个轰炸了一遍。收到两份回信。</p>

<p>我比较感兴趣的是我们老板做博士时的隔壁。收到两封推荐信之后，约在答辩的第二天面试。面试的结果我拿不准，可能老大爷比较有经验吧，各方面都没有说死，比之前的老哥显得“渣男”一些。这样也好，博后本来就不是个稳定关系，像之前的老哥，话说得太好听反而更加让人失望。</p>

<p>有两条困难，一是经费获批的时间不确定，二是明年他会 sabbatical，不见得有很多时间指导我。最后说 8 月底会有一场相对公开的组会，让我在那之前联系他拿 zoom 链接，了解一下组里的工作方向。</p>

<p>即便顺利的话，入职时间也是明年，在此之前我会在现在的课题组里继续之前没完成的一些项目。</p>

<hr />

<h3 id="攀比">攀比</h3>

<p>说到工作，之前的同学基本上今年或去年也都毕业了。</p>

<p>本科同学里，风神在某公司深圳分部做量子计算，跟我说的年薪是 50 多万，因为入职的时机不好；木木在同一家公司的上海分部，做光刻胶材料，据风神说年薪 100。有望留在学界者，聊哥在锦屏山实验，毕业之后好像要 gap 一年；班长欧陆硕士英国两校读博，没听说毕业的消息，看 arxiv 好像在做凝聚态；潇洒哥继续在国内做天文。其他人都没有消息。</p>

<p>博士同学里，同实验室的学姐在一家生物公司做临时工，年薪 6 万有望转正；小马去了一家量化交易商实习；低我一级的阿卷年底毕业，先去大摩实习。我们年级的天文美国三人组应该都会留在本专业，国际学生则不一定。凝聚态热门组的两人都在本组或合作组继续做博士后。方做粒子物理，回国做博士后。美国博后的普遍工资也就是 5 万上下。比较在意者，和我关系不好的一个女生去某芯片硬件公司做软件工程师，年薪 16 万，上网查了一下，这个工资是“资深软件工程师”，博士刚毕业就能资深吗？狠狠地嫉妒了。</p>

<p>本来觉得毕业去搞钱挺划不来的，毕竟内卷一辈子，可能只是将将摸到别人的起跑线。而且学界身份比之企业界还是更唬人一点，作为一个自由派、民族主义者和中国人，看到前女友那种宗教狂热，又总觉得有些事需要有人做，而我依然有希望够身份去做。“够身份”是一种非形式逻辑谬误，但就像清教徒“上帝的选民”的信念一样，逻辑上不必然成立的东西，实践中却可能有效。</p>

<p>但是看到自己的本职工作投出去连同行评议环节都到不了，直接被编辑就给毙了；业余玩票的天文反而水了两篇文章了，又觉得这评价体系，这逼科研，谁爱做谁做吧。</p>

<p>现在的想法是，暂且做完下面一期的博士后，看看这个学界对我到底如何定价，稍不顺意，就去搞钱。趁休假改掉之前超时工作的毛病，业余时间继续搞点 IT 副业。以我的执行力，希望明年博客总结的时候能做出一些东西。</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[以往过年的时候，都会在博客写一篇年终总结。今年没写，主要是当时觉得自己春季学期结束就要毕业了，需要努力工作，至少要摆出一副努力工作的样子。]]></summary></entry><entry><title type="html">.tex | 什么是智能≠智能是什么</title><link href="https://mountaye.github.io/blog/articles/what-is-intelligence-not-same-as-intelligence-is-what" rel="alternate" type="text/html" title=".tex | 什么是智能≠智能是什么" /><published>2023-06-17T00:00:00-05:00</published><updated>2023-06-17T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/what-is-intelligence-not-same-as-intelligence-is-what</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/what-is-intelligence-not-same-as-intelligence-is-what"><![CDATA[<h2 id="0">0</h2>

<p>这是一篇酬和之作。</p>

<p>徵文标题说的是：</p>

<blockquote>
  <p><strong>機器會製造「內涵」嗎？</strong></p>

</blockquote>

<p>但是正文提出的问题是：</p>

<blockquote>
  <p>AI透過程式組合出回答你問題的文字組合，有「涵義」嗎？</p>

</blockquote>

<p>可是，「內涵」和「涵義」两个词的——内涵/涵义——就不完全一样啊……</p>

<p>“内涵”(connotation) 通常指词语或表达方式所隐含的情感、态度、暗示或附加的意义。它涉及到词语或表达方式所引起的情感、联想或隐含的观点。也就是弦外之音。</p>

<p>而“涵义”(meaning) 一般指词语、表达方式或行为所传达的字面意义或字面上的定义。它强调的是直接的、明确的意义。</p>

<p>看热闹不嫌事大，那我们再把问题搞复杂一点——在逻辑学里也有一个“内涵”(intension)，和“外延”(extension) 相对应。用<strong>面向对象编程</strong>的说法来理解，一个类里面定义的所有状态量和内部方法的集合，就构成这个类的“<strong>内涵</strong>”；所有（已经和将来能够）从这个类实例化出来的对象的集合，就构成这个类的“<strong>外延</strong>”。</p>

<p>所以看起来，征文者想问的是日常“内涵”也就是言外之意，但是怕杠精（比如我）用有严格定义的逻辑“内涵”解构掉，所以换了“涵义”一词。</p>

<p>这个问题很显然是因应最近大语言模型掀起的这一波 AI 浪潮。这个问题往前再问一句，就是“大语言模型是智能体/有智能吗？”</p>

<ul>
  <li>前两年 DeepMind 的 AlphaGo/AlphaZero 系列 AI 在围棋中击败人类棋手时，人们也在问这个问题。</li>
  <li>上世纪四五十年代专家系统 (expert system) 刚刚开发的时候，人们也在问这个问题。</li>
  <li>从电子计算机往前追溯到机械计算机，甚至是巴比奇的差分机的时候，人们就已经开始问这样的问题了。</li>
</ul>

<p>这些问题求并集，然后在问题数量趋近于无穷下的极限，就是“什么是智能”。</p>

<p>这样的问题每每得不到回答，是因为它的逆问题“智能是什么”没有答案。我们并没有智能的准确定义，只能一事一论。而之前的智能和非智能体的区别太明显，以至于作出判断也不能对智能的定义有所启发。</p>

<h2 id="1">1</h2>

<p>而对“智能是什么”的探究，哲学、逻辑学、计算机科学、生物学、管理学，不同领域的研究者有着不同的思路。</p>

<h3 id="古哲学洞穴之壁与理念世界">古哲学·洞穴之壁与理念世界</h3>

<p>古希腊哲学家柏拉图在《理想国》里提到了“洞穴之壁”的寓言故事。</p>

<p>有一群被囚禁在一个深洞的囚徒，从出生开始就被束缚在这个洞穴里，脖子和腿都被铁链锁住，没办法转身或离开。囚徒身后的洞穴入口处有一道火焰，火焰后有人持物体走过，物体的投射在洞穴内的墙壁上形成了影子。囚徒们就以为这些影子就是唯一的存在。</p>

<p>这里的囚徒代表着人类，洞穴代表着世界，影子则代表着我们对于现象世界的感知和观念。人们的知识和信念往往受限于自己的经验和感知，就像囚徒们只看到了洞穴墙壁上的影子，而在影子之外还存在一个理想的理性世界。柏拉图用这个寓言故事表达了他对于人类认识和智慧的理解。所谓智慧，就是从洞穴的影子反过去推测火把前物体的能力。</p>

<p>当然，这种思想被 Marx 主义定性为一种客观唯心主义、唯理论，是受其批判的。</p>

<h3 id="逻辑学从命题到希尔伯特算符">逻辑学·从命题到希尔伯特算符</h3>

<p>柏拉图的学生亚里士多德，今天在低年级的物理教科书里基本是个反面典型，但他对逻辑学进行了系统化和全面的研究，提出了许多逻辑学的基本概念和原理。这些成果后来成为了欧洲哲学和逻辑学的基石，对西方哲学和科学的发展产生了深远影响。</p>

<p>所谓逻辑，就是研究命题的对错，以及如何判断命题对错的学问。而命题，就是能被判断对错的句子。但是句子显然可以再分成不同成分，于是就发明/发现了主体、客体、谓词、谓词的量词……等等概念，以及用这些概念构造命题的方法。</p>

<p>但是要注意，虽然逻辑主要由语言来表达，但是逻辑还是和语言不同，主体、客体也不等于句子的主语、宾语。这两者的区别，基本可以类比于之前洞穴之壁寓言里的实体和影子。</p>

<p>这种努力到目前为止的巅峰，基本上要数希尔伯特形式化逻辑系统了。感兴趣的朋友可以自行查阅戈得门特《代数学教程》的第一章，这玩意相当于思想界的引体向上，反正我是一个也拉不上去……</p>

<h3 id="计算机从半导体到抽象语法树">计算机·从半导体到抽象语法树</h3>

<p>希尔伯特是德国的数学家，《代数学教程》也是数学而不是哲学教材。显而易见，逻辑虽然由哲学家奠基，但是主导权很快落到数学家，至少是哲学家兼数学家手里了。</p>

<p>命题的“真”与“非真”同构于 {1, 0}，各种逻辑运算都可以分解成“或”与“非”两种基本逻辑运算的组合，这就是以数学家乔治·布尔 (George Boole) 命名的布尔代数。因为 {1, 0} 又可以同构于半导体电路的高低电位，和各种类似继电器的门电路组合，所以很容易用计算机在物理世界表示出这些逻辑运算。</p>

<p>我们的电脑由上亿个这样的电位和逻辑门组成，一般的科普文章应该会去介绍芯片啊光刻机之类的东西，本文关注的是另一个方面：虽然生产电脑配件的厂商很多，不同的型号的元器件设计不同，组装出的成品应该千差万别，但是他们可以运行同样的程序，理想条件下（虽然实际工程中常常不理想）我们也可以期望他们跑出同样的结果。</p>

<p>这说明所谓计算机科学，并不等同于研究计算机元件的电子科学和工程，这里电科和电子工程相当于洞穴岩壁上的影子，而计算机科学就相当于火光前的物体。这种超越物理的计算本质，一般用一种叫做“抽象语法树”的数据结构来表示。</p>

<h3 id="生物学从神经元到神经网络">生物学·从神经元到神经网络</h3>

<p>人们发明计算机的时候，基本上还是把它当作工具，就没期望它有什么主体性和智慧。</p>

<p>而随着生物学逐渐发现了神经系统及其作用，也随着物理学在二十世纪初的大发展之后的相对平静，很多物理学家开始插手其他学科。既然生命和非生命体的背后都服从同一套物理规律，既然物理学的众多成功经验说明，搞清楚构成系统的所有微观组成就可以理解宏观的系统，那么搞清楚人类的智力器官的基本单元以及相互作用，按理说也就能够理解什么是智慧。</p>

<p><img src="/blog/assets/photos/2023-06-17-neuron.png" alt="a cartoon illustrating a neuron" /></p>

<p>上图是一个神经细胞的结构示意图。从其他神经细胞释放出来的名为神经递质的化学物质，到达神经元左侧短且密集的树突之后，激活细胞膜表面的离子泵，主动运输离子跨过细胞膜，从而产生电信号。电信号沿细胞膜传导到右侧的树突，刺激凸触释放神经递质给下一个细胞。</p>

<p><img src="/blog/assets/photos/2023-06-17-perceptron.png" alt="a handdrawing style illustration of perceptron" /></p>

<p>上图就是根据神经元的工作原理抽象出的数学模型，名为 perceptron。一个 perceptron 就是一个函数，接受多个输入的自变量，加权求和之后套一个非线性的激活函数，得到一个输出。很多个这样的 perceptron 并连和串联，就构成下图，计算机算法中的神经网络。</p>

<p><img src="/blog/assets/photos/2023-06-17-neural-network.png" alt="a handdrawing style illustration of a neural network" /></p>

<p>而从实验方向研究神经系统，我们隔壁系就有，经常来我们系招人。基本上就是在小鼠的天灵盖上锯开一个天窗，然后给它带上个头盔，头盔上有能从天窗伸进去的电极，采集脑神经的电信号。以前头盔有网线伸到实验室天花板，实时传到数据中心的超算。现在好像进步了，改用 Wi-Fi 了。</p>

<p>这实验怎么通过的伦理审查，咱也不知道，咱也不敢问……</p>

<h3 id="管理学dikw-数据-信息-知识-智慧模型">管理学·DIKW “数据-信息-知识-智慧”模型</h3>

<p><img src="/blog/assets/photos/2023-06-17-DIKW.png" alt="a pyramid of DIKW model" /></p>

<p>DIKW 四个字母分别代表 data, information, knowledge, wisdom，即数据、信息、知识、智慧，是一种知识管理中的心智模型。</p>

<p>四个层次，前一层都是后一层的基础，后一层都是对前一层的理解。</p>

<p>如果是书面文字，数据就是笔画和字母；如果是语言，数据就是人声的响度、频率和音色。由笔画/字母/声音组成的有含义的字词就是信息。表示信息之间的关系的，可以判断对错的命题就是知识。包含和统摄各条知识的思想体系，就是智慧。</p>

<p>反过来说，虽然智慧高于思想，但它仍需要通过把各条知识的表达汇总起来，才能被人感知。对知识的命题的理解依赖于构成名字的各个概念的涵义，属于信息水平的内容。而每个字都有不考虑其涵义的笔画字母构成。</p>

<p>这层与层之间<strong>看似</strong>并没有插入额外的内容，智慧可以直接由笔画构成。但是我们一层层理解的深入，其实是不自觉地借用了我们当前社会约定俗成的解读方式。</p>

<p>比如下面这个图片里的符号，对于现代人就只是数据，无法解读成信息。但是对于苏美尔人，这是用楔形文字表示的数字，是等腰直角三角形的腰和直角边的比值，也就是 \(\sqrt{2}\) 的近似值。</p>

<p><img src="/blog/assets/photos/2023-06-17-ancient-root-2.png" alt="sumerian numerical approximation to square root of two" /></p>

<p>约定俗成的数据解读方式，也就是关于<strong>数据的数据</strong>，根据西方的构词法，可以叫做“<strong>元</strong>数据”(meta-data)。</p>

<p>数据和元数据一起构成信息，信息和元信息一起构成知识，知识和元知识一起构成智慧。俺坚持写博客的动机，就是用费曼学习法，把无意间使用的元知识显式地表达出来，而且记录下来，争取学而不退转。</p>

<h2 id="2">2</h2>

<p>回顾了这些，再来看大语言模型，就会发现它落在了各方努力的延长线的交点。</p>

<p>大语言模型里有一个重要概念叫做“嵌入”(embedding)，就是把语言的基本字元 (token) 可逆地映射到一个超多维度的向量空间里。本来“国王”和“儿子”之间没办法加减乘除，但是嵌入后的向量空间里有加法和数乘，如果嵌入函数选得好，“国王”的向量 + “儿子”的向量，结果向量就约等于“王子”的向量。</p>

<p><img src="/blog/assets/photos/2023-06-17-vector-addition.png" alt="illustration of vector addition from wikipedia" /></p>

<p>生成式语言模型的核心就是一个超多元函数，接受前一个字嵌入后的向量作为输入，给出另一个向量作为输出，用嵌入函数的逆映射翻译成字元；再把旧的输出作为新的输入，直到输出结果是“语段结束”这样一个特殊字元为止。模型训练的过程，主要就是通过现成的语料，拟合这个超多元函数的参数。</p>

<p>从 DIKW 模型来看，语言模型操作的是最基本的数据，它的输出究竟是什么信息，是不是正确的知识，体现了多少智慧，是人根据当下的社会文化来解读的。</p>

<p>而实现 AI 的电子计算机，或是复杂生命的大脑，他们和智能之间的关系，应该就类似于具体的计算机电路和抽象语法树之间的关系。以此类比，未来的智能科学应该会成为一门独立的专业，它和计算机科学和神经生物学的区别，就像今天的电子科学与工程，和计算机科学之间的区别一样。当下神经生物学的热度，将来恐怕多半会被分流。</p>

<p>这种对字符的计算不同于逻辑运算，语言模型不判断输出结果在逻辑上的正确与错误，这既给了他啥都能说几句的 feature，又给了它经常编假消息的 bug。</p>

<p>想要改掉这种错误，引入对 AI 的纠错机制，治本之道恐怕还是诉诸于对世界的正确描述，与理论相关的还是要靠逻辑，与现实相关的还是要靠科学。</p>

<p>只不过，大语言模型提供了一种数据结构，有希望把人类已知的真理储存在一起。对这种数据结构本身的研究，有可能反过来启发科学的发展。柏拉图的洞穴之壁可能不再是一个比喻，未来更大的语言模型的，亿万维度的参数空间有希望成为洞穴门口的那团火。</p>

<p>只不过这一切都是“可能”，现在还只是 AI 的萌芽阶段，还没有足够的证据来证实或者证伪这种畅想。而且 AI 的参数量再大也是有限的，它所能表达的信息也就有限，而真理应当是无限的，就像科学一样，总要训练更新更大的模型，总要发现已知的未知，然后欣然接受更多未知的未知之存在。</p>

<p>如果电子计算机实现的 AI 独立于人类产生了意识和超出人类的智慧，很难想象他们会继续用人类语言这种对他们来说很不方便的方式来交流。</p>

<p>所以，哪怕是做个 AI 生成内容的质检员，科学家依然有事可做。这算是科学的堕落吗？当然不算，如果算的话，那从计算物理也被当作理论物理的那天起，人类就已经投降了（逃）</p>

<h2 id="3">3</h2>

<p>现在正面来回答问题：AI透過程式組合出回答你問題的文字組合，有「涵義」嗎？</p>

<p>答：有。</p>

<p>因为语言的「涵義」来自于语言的内容，和整个社会的文化，并不来自于这句话的作者的身份。即便是人与人之间的交流，诉诸身份也是一种非形式逻辑谬误，是理性不足的表现。只有在信息不足仍不得不下结论的时候才该使用，比如法律判决时的自由心证主义和/或法定证据主义。</p>

<p>而鹿妈眼里真人鹿酱与 AI 鹿酱的区别，如果有的话，好像主要体现在动机的区别。动机这种东西，很多智慧不高的生物，比如小猫小狗都会有；而现在的 AI，似乎还没有展现出超出编程者设计的动机。编程写入的信息有限，现有 AI 的动机也就有限，鹿酱的赢面还是很大的。</p>

<p>而动机是生物与非生物的区别吗？而什么是生物 ≠ 生物是什么，那就是另一个含混而复杂的问题了。</p>

<h2 id="4">4</h2>

<p>这篇博文发布的时候，高考应该已经结束了，马上该填报志愿了。</p>

<p>那么，西元 2023 年，AI 来袭的当下，该选个啥专业在 AI 浪潮中幸存，或者选个啥专业给 AI 老爷带路呢？</p>

<p><img src="/blog/assets/photos/2023-06-17-three-body-quotation.png" alt="a screenshot of a quotation from Three Body about attitudes towards aliens" /></p>

<p>我的建议是，不要听别人的建议，按自己的兴趣来就好了。</p>

<p>刚刚改开的时候，有一个超级热门的专业，叫科技英语。科技落下了好多年，对外开放需要语言交流，两者一结合应该是热门又稀缺了。结果呢，你现在还听说过这个专业吗？</p>

<p>科技很重要是不错，语言很重要也不错，但是搞科技的人自己可以学英语，学英语的有几个搞得了科技？社会的进步主要靠创新，而创新的方向难以预测，不论这种预测分析听起来多有道理。</p>

<p>如果真的找不到兴趣，那就在能力范围之内，找个难度最高的。如果想从事智力劳动，那数学含量是个不错的衡量标准；如果不排斥体力劳动，那训练时间越长越值得考虑。</p>

<p>但这只是填志愿来不及时的权宜之计，发掘兴趣是人一生的课题。</p>

<p>兴趣不是为了让你成功的时候更得意，毕竟成功的话不论做什么都很得意；</p>

<p>兴趣是为了你不成功时也可以不失意，毕竟平凡才是人生的真谛。</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[“什么是智能”的问题每每得不到回答，是因为它的逆问题“智能是什么”没有答案。]]></summary></entry><entry><title type="html">.doc | OPT 申请手续笔记</title><link href="https://mountaye.github.io/blog/articles/OPT-workshop-notes" rel="alternate" type="text/html" title=".doc | OPT 申请手续笔记" /><published>2023-05-19T00:00:00-05:00</published><updated>2023-05-19T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/OPT-workshop-notes</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/OPT-workshop-notes"><![CDATA[<p>OPT 是 Optional Practical Training 的缩写，指的是在美国完成学业期间或者之后，允许有一段实习时间，可以工作。但是此时这个人的身份依然是学生，不是工作签证，更不是移民签证。</p>

<h2 id="谁有资格申请">谁有资格申请</h2>

<p>已进入美国，并且维持了至少2个学期 F1 学生身份者。</p>

<h3 id="学业完成前-pre-completion">学业完成前 pre-completion</h3>

<p>在毕业前，学习过程中间可以申请，但是需要与导师商量，很少见。</p>

<h3 id="完成后-post-completion">完成后 post-completion</h3>

<p>毕业后找工作，应付非移民工作签证还没通过的那段时间，这是最常见的情况。</p>

<p>或者除了没提交论文，其他毕业要求都已满足的准毕业生 all but dissertation, 简称 ABD。申请这种情况的学生需要在EAD日期结束之前完成学位，否则需要回国完成学位（远程答辩）。</p>

<h2 id="opt-基础知识">OPT 基础知识</h2>

<p>每个有学位的学习阶段都有一次 OPT 机会，但是必须在毕业前申请，不申请就毕业视为放弃，不能攒到下一段学习中多用一次。</p>

<p>仍然是F1学生，不是工作签证。</p>

<p>申请时不需要已经找到工作。也允许换工作和同时干多个工作。可以做有偿/无偿工作，本大学不提供无偿工作的职位。</p>

<p>不需要雇主做任何事情，申请人自己赞助。</p>

<h2 id="在-opt-期间维持学生身份">在 OPT 期间维持学生身份</h2>

<blockquote>
  <p>也就是说，下面各条没做到的话会被取消合法居留身份。</p>
</blockquote>

<p><img src="/blog/assets/photos/2023-05-19-main-status.png" alt="how to maintain the OPT status" /></p>

<p>OPT 期间从事的工作必须与你的专业领域相关。</p>

<p>OPT 申请通过后会得到一张 EAD 卡作为资格证明。在获得 EAD 卡之前不具备工作资格，没有例外。</p>

<p>只能在 EAD 卡上指明的起止日期内工作。</p>

<h3 id="信息申报">信息申报</h3>

<p>在OPT获批并开始日期后，需要创建SEVP门户账户。</p>

<p>以下信息变更之后的 10 天之内，需要通过 SEVP 通知当局：美国家庭地址、雇主及其地址、就业起止日期。</p>

<h3 id="不超过90天的失业时间">不超过90天的失业时间</h3>

<p>每周工作少于20小时被视为失业。</p>

<p>在EAD卡的授权期内累计失业时间不能超过90天。</p>

<h3 id="上课">上课</h3>

<p>只能兼修与当前或未来领域无关的课程，具体情况可以联系 OISS 咨询。</p>

<h3 id="离开美国旅行">离开美国旅行</h3>

<p>可以，但是需要携带相关文件</p>

<ol>
  <li>护照</li>
  <li>有效F1签证</li>
  <li>带签名的I20</li>
  <li>EAD</li>
  <li>就业证明（可选，如果已经找到工作了的话）</li>
</ol>

<p><strong>在OPT申请挂起期间出美国也是可能的，但存在风险</strong>，因为EAD将会寄到申请人的美国地址。</p>

<p>再次进入美国后要在 I-94 记录 (<a href="http://i94.cbp.dhs.gov/">i94.cbp.dhs.gov</a>) 中确认自己的身份仍然是 F1 学生和 “D/S” 状态。</p>

<h2 id="谁可以申请延长-opt">谁可以申请延长 OPT</h2>

<h3 id="24个月stem-opt延期">24个月STEM OPT延期</h3>

<p>科学、技术、工程、数学专业的毕业生可以申请将 OPT 再延长24个月。</p>

<p>在OPT结束的最后90天内申请。USCIS必须在 OPT 结束前收到申请。</p>

<p>申请时必须有一份工作，雇主必须注册E-verify，需要填 I-983 表。</p>

<h3 id="h1b-申请获批之前可以申请配额间隙-cap-gap">H1B 申请获批之前，可以申请“配额间隙” Cap Gap</h3>

<p>配额间隙雇主在每年 4 月 1 日提交 H1B 申请。如果获批，H1B从10月1日开始。如果OPT在10月1日之前到期，“配额间隙”将在SEVIS中延长，直到H1B的决定出来为止。</p>

<h2 id="申请流程">申请流程</h2>

<ul>
  <li>必须在美国申请OPT，应做好准备直到收到 EAD 都一直呆在美国。
    <ol>
      <li>参加研讨会，获取一份申请资料包</li>
      <li>从 OISS 顾问处申请 OPT I-20 表格</li>
      <li>准备并提交 I-765 表格给USCIS，申请OPT</li>
    </ol>
  </li>
</ul>

<h3 id="需要上传的-i-765-文件与opt-i-20的证明文件">需要上传的 I-765 文件与OPT I-20的证明文件</h3>

<ul>
  <li>移民文件：护照、I-94</li>
  <li>之前的 OPT 和CPT，如果没有可以跳过</li>
  <li>2英寸 × 2英寸的白底照片；拍摄日期在30天内；公共图书馆、Walgreens和CVS提供此服务</li>
</ul>

<h3 id="时间窗口">时间窗口</h3>

<p><strong>估计申请审批过程需要4周时间。</strong>（往年是3个月）</p>

<p>申请窗口：学业结束日期前的90天 ↔ I-20 结束日期 ↔ 节目结束日期后60天</p>

<p>选择 OPT 的开始日期：I-20 结束日期后的第1天 ↔ 60天宽限期结束</p>

<p><img src="/blog/assets/photos/2023-05-19-time-window.png" alt="time window of OPT application" /></p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[快毕业了，学校组织了一个毕业实习 OPT 相关的签证手续的讲座，以下为讲座的笔记。仅供参考，可能有理解错误，不构成法律建议，不构成移民广告。]]></summary></entry><entry><title type="html">.doc | 三月会·两面试·一座谈</title><link href="https://mountaye.github.io/blog/articles/job-search-efforts-during-march-meeting" rel="alternate" type="text/html" title=".doc | 三月会·两面试·一座谈" /><published>2023-04-05T00:00:00-05:00</published><updated>2023-04-05T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/job-search-efforts-during-march-meeting</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/job-search-efforts-during-march-meeting"><![CDATA[<h3 id="会前">会前</h3>

<p>今年的三月会在拉斯维加斯。</p>

<p>距离会议大约两周，下巴有根胡子根部起了毛囊炎，很快恶化成带状孢疹，俗称上火。美国学年的下学期在5月份就结束了，毕业论文还没怎么写。找不到工作，博士后项目的申请季正忙着论文投稿，眼睁睁地看着滑过了两个项目的申请截至期；隔壁组老师转发的博后项目，在我发了申请材料之后不久，就在网上又发了一遍招聘广告；申请了两个德国研究所，一个已经发了拒信，另一个没回应……还要准备会议上的演讲，不上火才怪。</p>

<p>周五组里演讲排练，本打算重用去年开会的幻灯片，发现论文稿中的主要内容居然都没有，才意识到过去的一年着实也还是做了不少事情。收到德国研究所的拒信消沉了一天，但是很快 ChatGPT 热潮兴起，于是把读博期间所有听说过的教授拉了一个名单，把他们的课题组主页介绍，和 AI 生成的我论文稿的摘要一起喂给 ChatGPT，让它写套词邮件。效果还行，收到一条回复，约我会议期间见面。回信的老哥用跨尺度方法研究动物行为，同时在欧洲和东亚经营两个课题组，去年会上很出风头。会后不久来我校作讲座，我们一起吃过一顿午饭。会前不久 APS 的邮件列表里有人群发邮件招人，是今年即将在西部某校开始教职的现任博后，目前正工作于给我拒信的德国研究所，尽管嫉妒，但也让他吃了一发 ChatGPT 邮件。</p>

<h3 id="开会">开会</h3>

<p>步行去会场签到，领到了名牌，居然就是一张厚纸上挂了根绳，连个塑封都没有。</p>

<p>签到后勘查了一下会场的布置。生物物理有关的会场都在主走廊第一条岔路的两侧，每个门口有展板，上书每个时段的演讲主题。不像去年只有我一个人参会，今年组里三个人都有演讲，再加上之前在我们组的硕士凯蒂和她现在的同学，把日程一标记，发现感兴趣的小节基本上都冲突了。我虽然社恐，但还是觉得人际关系比较重要，或者说因为社恐所以觉得人际关系比较重要？</p>

<p>回到宾馆，收到了群发邮件哥的回复，要我确定三月会后一两周的时间，安排一次远程面试，介绍一下我现在的工作，以及说明我对他的实验室可以有何贡献。有点意外，因为他群发的邮件说了自己会来参加会议，我的邮件也说了自己愿意在会议期间见面，这个回信是兴趣缺缺的意思？略感失落。</p>

<h3 id="面试-1">面试 1</h3>

<p>在不同的分会场之间乱窜的时候，去得晚会场坐满的话需要在后排站着。在其中一个场子站听的时候，一个穿绿色冲锋衣，背运动背包的老哥走了进来，听了一会就出去了。感觉有点面熟，和群发哥个人网站上的照片有点像。</p>

<p>于是悄悄离场，看到他正在走廊里和朋友谈话，身前的名牌有名字那面翻过去了。暂时离开闲逛，发现主走廊里供应咖啡，排队接了一杯，回来再刺探，确定是他。</p>

<p>打招呼，原来是 ChatGPT 太啰嗦了，邮件最后才说我也在三月会，他没看到。问了我的演讲在什么时候，他会来听，就不需要 zoom 会议了。</p>

<p>我的演讲所在时段的题目十分古怪，感觉跟我做的东西关系不大。进去候场的时候发现，整个小节除了我们实验室的俩人，其余的演讲都是同一个方向，而且研究的都是同一模式生物的同一结构。我们组俩人的演讲在整个小节的最后，自我感觉表现不错，破题的时候拿小节的题目开了个玩笑，结束的时候时间正好用完。群发哥在我演讲前半小时左右到会场，我们结束之后就离开了，没有上来和我说话。</p>

<p>结束后回到宾馆，收到了他的邮件，约我第二天下午见面。在会议网站搜索了一下他的日程，发现正是在他的演讲结束之后。看他的演讲题目题目，似乎是关于自己的最近一篇论文的，把文章喂给 AI 工具生成了一份摘要，没来得及看就被同学拉出去玩了……</p>

<p>他的演讲在第二天下午，时间上处于整个时段的中间。我在时段开始的时候就坐进会场了，他比我晚来了一会，坐了一会又出去了，。会场比我演讲的时候大一倍，但是也没坐满。他在上面讲的时候，我在下面看昨天 AI 生成的文章总结，感觉信息量比截至当时听过的绝大多数演讲的内容丰富，演讲的水平也远在平均水平之上。研究对象比我现在的研究对象在生物系统的层次上高一个层级，但是感觉研究的方式和流程类似。研究的完成度高得多，理论和实验都有。虽然理论似乎是所在领域挺传统的一个模型，但是毕竟比我们只是摆实验数据好太多了。</p>

<p>会后见面，我们在走廊旁边找了俩座位，我拿出了自己的幻灯片，他从头到尾把细节问了一遍，确认我会做我们组模式生物的基因编辑，又问了我在整个项目中的工作占比。</p>

<p>然后就问了一个堪比谈恋爱时被表白一方“你为什么喜欢我”的天问：“你贯穿整个研究生涯的问题是什么？”啊这，大脑直接宕机。看我实在憋得不行了，老哥让我可以说中文的，原来他能听懂，但是不会说。最后实在逼急眼了，说了实话——我就是想在学界混吃等死，ChatGPT 都来了，强人工智能还会远嘛，物理学不存在了啦。老哥噗哧一声乐了。</p>

<p>然后让我提问，我问假期有多少，答曰按学校政策办，养过细胞的应该知道周末可能是要去学校的，所以只要工作量够，周中不作出勤要求。</p>

<p>感觉聊得比较顺利，最后说回头会发邮件给我，让我给他两三个联系方式，要推荐信。</p>

<h3 id="面试-2">面试 2</h3>

<p>本来感觉反馈不错的大佬，感觉开会第一天可能大家都还没安顿下来，于是周二才再发邮件确认见面时间，这样一来就约到了周五中午，在 DBIO 的服务台旁边见面。</p>

<p>本来打算事前准备的，他的课题组有三四个演讲，但是基本上都和我的演讲或者前一个面试冲突，最后只听了一个。</p>

<p>结果周五中午就是整个会议的最后一节了，DBIO 的桌子已经撤走了，大家心猿意马归心似箭。12点过了十分钟左右见到了人，五分钟之后和他谈话的人离开。到处都在收拾关门，我们找了一个桌椅已经搬空的房间，屋里只有一个学生躺在地上睡觉，我们两人相对席地而坐。</p>

<p>刚要掏电脑出来给他复述一下我的演讲，他摆了摆手，让我尽可能简短地口头概括自己的工作。后面的一系列问答都是这个风格，两个人在地上打坐，快问快答，跟禅宗的机锋一样。上来是为什么要做现在的工作，我自认为说的还行，但是说着说着发现这™不是上一场面试的答案嘛，早怎么没想到呢？然后得意忘形，忘了这位大佬不是做组织结构而是研究行为的，本来很容易圆过去的，没发挥好。然后是我本科时最喜欢的一门课是什么，这个问题上次吃午饭的时候他就说自己喜欢问，于是让我狠狠地装了一逼。再然后就是“臭做实验的怎么来我们理论组要饭来了”和“臭做结构的怎么来我们研究行为这儿要饭来了”两大问题，回答得不好。之前得意忘形，把自己手里另有 offer 的事说出去了，导致后半截我们双方又有点敷衍。</p>

<p>最后和我交底，东亚的研究所有足够的经费，虽然他一年还是花不少时间去当地，但是并不总是能见面指导。欧洲方面如果决意入职的话，他需要专门申请经费。这个意思已经比较明确了，所以我们很客气地互相说可以在花时间考虑一下，日后可以邮件联系。</p>

<h3 id="座谈">座谈</h3>

<p>座谈会其实发生在我演讲所在当天中午，两次面试之前。</p>

<p>所谓座谈，是德国几个研究机构联合组织的，在德国从事研究的相关信息的宣讲会。 ~~~~位置离生物物理的几个会场比较远，凯蒂朋友的演讲结束之后从会场溜出来，赶到的时候已经开始了。进门两侧有贝果面包、果酱和乳酪，这么多天第一次吃午饭。</p>

<p>会场有六七个圆桌，每个桌上放了一个写有研究机构名字的小标签，桌边坐一两个对应研究所的工作人员。主持人依次介绍了每个桌的研究机构，然后给机构的负责人三五分钟的时间介绍自己。之后就是自由时间，我看马普所的桌子就在面包附近，其他机构也不怎么做基础科学的研究，就找了个椅子坐下了。马普所的负责人是一个满头白发的长者，着装在与会者中偏正式，气场很足，神似觉爷。</p>

<p>第一个问题关于移民德国的难度，以及德国是不是有点排外。长者答曰德国现在是移民政策最为开放的国家之一，考虑到“之一”，再考虑到灯塔国的外国人毕业在非学术岗位连工作签证都要抽签才能拿到，不算边境“走线”的话，这个回答确也不能算错。德国之声之前也出过一个视频，也有同样的论断，但是那个视频后面还有半截 “aber…”。</p>

<p>随后有人问马普所的项目和岗位结构。回答的结果和之前了解的差不多。每个研究所有自己的招生权，一期博士后的时间一般是两年，只在必要时延长至三年或更长。新知识是马普所的研究职位除所长之外几乎没有终身职务，研究所就是研究者找终身教职之前的副本村。但是不知是政府还是啥，有条规则说拿到博士学位的九年后雇佣单位必须提供终身职，结果就是九年之期以前就会被清退。此条是否与前一个回答相矛盾，没问。</p>

<p>被问到马普所更青睐于何种研究时，长者明确说是更困难更有野心的题目，而非为了拿到教职而做的安全题目，甚至很明确地说，就是要发掘那些将来有可能拿诺奖的题目和学者。这一点自然是不同于美国式的口头上的自由放任和实际操作中的专打安全球，有趣是也和国内的看法不同。当年 CLS 面试的时候，我也不知天高地厚地说自己有鸿鹄之志，台下老师们答曰“不要那么功利嘛”，没想到两个视计划与顶层设计为制度优势的文化，对于功利的理解竟有如此大的不同。</p>

<p>还有人问马普所选择申请人的标准。回答是每个研究所有自己的标准。但是他也谈到了自己的标准：学习成绩为主，<em>做研究的时候应该很清楚自己在做的东西底层的物理是什么。</em>那么如何判断学习成绩呢？主要是来自名校，然后是成绩排名，如果是没太听说过名字的学校，成绩排名的要求也就更高。回答很真诚，让人对如此明显的第一学历歧视也反感不起来，甚至没有反驳的意愿。</p>

<p>这个回答显然是针对美国模式，选拔以科研经历为主，在论文作者栏占位更重要。研究组的骨干是不需要花时间上课的博士生，申请博士的本科生，能对整个项目有多少贡献呢？而且这些贡献基本上都是献祭对课业努力得来的，上方标注的句子就是对此的吐槽。更何况考虑到国内学术环境的昭著臭名，基本上都需要海外的研究经历，除了珠峰计划这类特殊项目提供公派名额，基本都是自费联系国外导师，不仅把学术选拔变成了与学术无关的信息差，和学生经济条件的选拔，还豢养了一个倒卖此类信息的中介产业，此种政策的学术正义性何在？</p>

<p>但是再回来看呢，成绩单能反映出多少成绩？想出国的学生，有多少明目张胆地跟上课老师要成绩？某校直到几年前还有“及格重修”这种合法的更改成绩单的操作，配合上国内各科考试历年题目的高度相似性，不利于安定团结的话就不说了。既然要求名校，那么高中出国又比本科毕业出国优势不止一点半点，又是阶级筛选，殊途同归。</p>

<p>两者一邱之貉，都是在不同的大义名分之下，落实为可执行的操作时，原有的大义不断被解构和歪曲，过程中不断把自己的判断力外包。外包无所谓，毕竟分工既是社会发展的表现，又是重要的动力。然而，拿飞机举例，把乘客安全送到目的地需要机组和地勤配合和信任，但是安全送达毕竟是有客观标准的。而教育和研究系统，其培养成果本身就由自己消化，选拔过程天然构成运动员兼任裁判员的现象，我选出来的人有不行的，没被选中的也有行的，那好办，把资源全圈给胜选者，再把落选者的路掐断就好了嘛……</p>

<p>两种模式菜鸡互啄，谁也取代不了谁，归根到底，还是今天的物理学自己乏善可陈。量子力学和相对论肇起之时的摧枯拉朽不提，就连标准模型构建过程中的萧规曹随，今天也难望其项背。扎实理解知识，你的实际研究中能用到多少？早早上手研究，这么多年有多少有价值的工作自己心里没数？年轻人觉得攸关前途命运的大事，不过是老板平凡一天中收件箱里的一段字节罢了，录不录你，录你还是录他，区别不大。</p>

<p>一言以蔽之，时无英雄，遂使竖子成名。</p>

<p>下午，前一天和群发哥聊天的一个女士在他之后不久演讲，看幻灯片首页的工作单位，似乎是他博士实验室的后辈，今天即将入职他现在的研究所，<del>也就是说，这位正是抢走了我 offer 的仇雠</del>。于是在朋友圈发了一条吐槽。她的演讲超时被主持人叫停了，刚想追加一条评论“超时了，真菜”，想到最近几天朋友圈发的有点多，忍住了。</p>

<p>大学四年我唯一佩服过的人峰神在下面回复，说他本来也想申请同一个研究所。我问他现在去哪，过了几分钟看到回复“上班了”，赶紧揶揄说“富哥V我50”，但是座谈会上的话在此刻反刍，叹息收敛成深呼吸，默默收起了手机。</p>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[记录今年三月会上找工作的相关努力和随想。]]></summary></entry><entry><title type="html">.tex | 基于物理的神经网络 (PINN) 综述笔记</title><link href="https://mountaye.github.io/blog/articles/physics-based-neural-network-review-note" rel="alternate" type="text/html" title=".tex | 基于物理的神经网络 (PINN) 综述笔记" /><published>2023-03-20T00:00:00-05:00</published><updated>2023-03-20T00:00:00-05:00</updated><id>https://mountaye.github.io/blog/articles/physics-based-neural-network-review-note</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/physics-based-neural-network-review-note"><![CDATA[<blockquote>
  <p>本文是《<a href="https://link.springer.com/article/10.1007/s10915-022-01939-z">Scientific Machine Learning Through Physics–Informed Neural Networks: Where we are and What’s Next</a>》这篇综述的读书笔记。</p>

</blockquote>

<p>年前，今年新入职的天文学方面的一位老师给我们群发邮件，宣传某国家实验室超算的 GPU 编程马拉松活动，他可以担任指导老师。于是毫不意外地，我报了名。该编程马拉松项目还需要专门申请，申请材料里要写清楚打算干什么，于是报名的五六个人七嘴八舌地想创意。基于物理的神经网络 PINN 就是天文老师的点子。</p>

<p><del>写到这里，我才意识到，老哥是不是想拿我们当免费劳动力啊</del>~</p>

<p>神经网络可以看作是一个复杂的非线性函数，接受一个（一般来说维度很高的）向量作为输入，一番计算后输出另一个向量。训练神经网络，就是找到这个函数的参数，绝大多数找参数的方法涉及计算网络输出对参数的偏导数，因此神经网络计算框架的核心功能就是自动微分 (auto-differentiation)。</p>

<p>而很多物理问题，都可以用（偏）微分方程来描述，微分方程的解不是变量，而是函数，而且往往是复杂的非线性函数。所以基于物理的神经网络 (PINN) 就是以神经网络来表达这个函数，然后把这个函数带入到物理的微分方程中，把神经网络输出和真正的物理解之间的差距当作损失函数，反向传播回去来优化神经网络的参数。代入方程时的微分计算，正好可以利用现成框架的自动微分功能。</p>

<p>在以 GPT 为代表的 transformer 类神经网络模型出现之前，自然语言处理类的机器学习项目，往往要在网络之外，利用人类的语法知识，对语段进行语义分割等等“中间任务”。Transformer 一出，算力出奇迹，中间任务逐渐变得没有必要了。</p>

<p>在 GPT 崭露头角，并且越来越有迹象表明其将会涌现出通用人工智能的今天，这些基于物理的神经网络，会不会还未成熟就已过时？这种心情，就和《三体》第二卷开始，章北海和吴岳面对焊渍未漆的“唐”号航空母舰时差不多吧……</p>

<hr class="slender" />

<ul>
  <li>Abstract
    <ul>
      <li>PINNs are neural networks that encode model equations. a NN must fit observed data while reducing a PDE residual.</li>
    </ul>
  </li>
</ul>

<ol>
  <li>Introduction
    <ul>
      <li>The “curse of dimensionality” was first described by Bellman in the context of optimal control problems. (Bellman R.: Dynamic Programming. Sci. 153(3731), 34-37 (1966))</li>
      <li>Early work: MLP (<a href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multilayer perceptron</a>) with few hidden layers to solve PDEs. (<a href="https://doi.org/10.1109/72.712178">https://doi.org/10.1109/72.712178</a>)</li>
      <li>感觉可能更全面的一篇综述：<a href="https://doi.org/10.1007/s12206-021-0342-5">https://doi.org/10.1007/s12206-021-0342-5</a>。该文关注 what deep NN is used, how physical knowledge is represented, how physical information is integrated，本文只关于 PINN, a 2017 framework。</li>
    </ul>

    <ol>
      <li>What the PINNs are
        <ul>
          <li>PINNs solve problems involving PDEs:
            <ul>
              <li>approximates PDE solutions by training a NN to minimize a loss function</li>
              <li>includes terms reflecting the initial and boundary conditions</li>
              <li>and PDE residual at selected points in the domain (called <strong>collocation points</strong>)</li>
              <li>given an input point in the integration domain, returns an estimated solution at that point.</li>
              <li>incorporates a <a href="https://en.wikipedia.org/wiki/Residual_neural_network">residual network</a> that encodes the governing physical equations</li>
              <li>can be thought of as an <strong>unsupervised strategy</strong> when they are trained solely with physical equations in forward problems, but <strong>supervised learning</strong> when some properties are derived from data</li>
            </ul>
          </li>
          <li>Advantages:
            <ul>
              <li><a href="https://en.wikipedia.org/wiki/Meshfree_methods">mesh-free</a>? 但是我们给模型喂训练数据的时候往往已经暗含了 mesh 了吧</li>
              <li>on-demand computation after training</li>
              <li>forward and inverse problem using the same optimization, with minimal modification</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>What this Review is About
        <ul>
          <li>提到了一个做综述找文章的方法：本文涉及的文章可以在 Scopus 上进行高级搜索：<code class="language-plaintext highlighter-rouge">((physic* OR physical)) W/2 (informed OR constrained) W/2 “neural network”)</code></li>
        </ul>
      </li>
    </ol>
  </li>
  <li>The Building Blocks of a PINN
    <ul>
      <li>question:</li>
    </ul>

\[F(u(z);\gamma)=f(z),\quad z\ \in\ \Omega \\ B(u(z))=g(z), \quad z\ \in\ \partial \Omega\]

    <ul>
      <li>solution:</li>
    </ul>

\[\hat u_{\theta}(z)\approx u(z)\\ \theta^* = \arg\min_{\theta}\left(\omega_F L_F(\theta)+\omega_BL_B(\theta)+\omega_{data}L_{data}(\theta)\right)\]

    <ol>
      <li>Neural Network Architecture
        <ul>
          <li>DNN (deep neural network) is an artificial neural network that is deeper than 2 layers.</li>
        </ul>

        <ol>
          <li>Feed-Forward Neural Network:
            <ul>
              <li>
\[u_{\theta}(x) = C_{K} \circ C_{k-1} ...\alpha \circ C_1(x),\quad C_k(x) = W_k x_k + b_k\]
              </li>
              <li>Just change CNN from convolution to fully connected.</li>
              <li>Also known as multi-layer perceptrons (MLP)</li>
            </ul>

            <ol>
              <li>FFNN architectures
                <ul>
                  <li>Tartakovsky et al used 3 hidden layers, 50 units per layer,  and a hyperbolic tangent activation function. Other people use different numbers but of the same order of magnitude.</li>
                  <li>A comparison paper: <em>Blechschmidt, J., Ernst, O.G.: Three ways to solve partial differential equations with neural networks –A review. GAMM-Mitteilungen 44(2), e202100,006 (2021).</em></li>
                </ul>
              </li>
              <li>multiple FFNN: 2 phase <a href="https://en.wikipedia.org/wiki/Stefan_problem">Stephan problem</a>.</li>
              <li>shallow networks: for training costs</li>
              <li>activation function: the swish function in the paper has a learnable parameter, so — <a href="https://discuss.pytorch.org/t/how-could-i-create-a-module-with-learnable-parameters/28115">how to add a learnable parameter in PyTorch</a></li>
            </ol>
          </li>
          <li>Convolutional Neural Networks:
            <ul>
              <li>I am most familiar with this one.</li>
              <li>
\[f_i(x_i;W_i)=\Phi_i(\alpha_i(C_i(W_i,x_i)))\]
              </li>
              <li>performs well with multidimensional data such as images and speeches</li>
            </ul>

            <ol>
              <li>CNN architectures:
                <ul>
                  <li><code class="language-plaintext highlighter-rouge">PhyGeoNet</code>: a physics-informed geometry-adaptive convolutional neural network. It uses a coordinate transformation to convert solution fields from irregular physical domains to rectangular reference domains.</li>
                  <li>According to Fang (<a href="https://doi.org/10.1109/TNNLS.2021.3070878">https://doi.org/10.1109/TNNLS.2021.3070878</a>), a Laplacian operator can be discretized using the finite volume approach, and the procedures are equivalent to convolution. Padding data can serve as boundary conditions.</li>
                </ul>
              </li>
              <li>convolutional encoder-decoder network</li>
            </ol>
          </li>
          <li>Recurrent Neural Network
            <ul>
              <li>\(f_i(h_{i-1})=\alpha\left(W\cdot h_{i-1}+U\cdot x_i+b\right)\), where f is the layer-wise function, x is the input, h is the hidden vector state, W is a hidden-to-hidden weight matrix, U is an input-to-hidden matrix and b is a bias vector. 我认为等号左边的 \(h_{i-1}\) 应当作为下标</li>
              <li>
                <p>感觉有点像 hidden Markov model，只不过 Markov 中间的 hidden layers 好像与序号无关（记不清了），<del>RNN 看起来各个 W 和 H 似乎不同</del>。<strong>RNN cell is actually the exact same one and reused throughout.</strong> (from <a href="https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/">https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/</a>). Cartoon from Wikipedia:</p>

                <p><img src="/blog/assets/photos/2023-03-20-rnn-unit.png" alt="Untitled" /></p>
              </li>
              <li>
                <p>From <a href="https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/">https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/</a>:</p>

                <p><img src="/blog/assets/photos/2023-03-20-rnn-types.png" alt="Untitled" /></p>
              </li>
            </ul>

            <ol>
              <li>RNN architectures
                <ul>
                  <li>can be used to perform numerical Euler integration</li>
                  <li>基本上输出的第 i 项只与输入的第 i 和 i-1 项相关。</li>
                </ul>
              </li>
              <li>LSTM architectures
                <ul>
                  <li>比 RNN 多更多中间隐变量，至于怎么做到整合长期记忆的，技术细节现在可以先略过</li>
                </ul>
              </li>
            </ol>
          </li>
          <li>other architectures for PINN
            <ol>
              <li>Bayesian neural network: weights are distributions rather than deterministic values, and these distributions are learned using Bayesian inference. 只介绍了<a href="https://doi.org/10.1016/j.jcp.2020.109913">一篇文章</a></li>
              <li>GAN architectures:
                <ul>
                  <li>two neural networks compete in a zero-sum game to deceive each other</li>
                  <li>physics-informed GAN uses automatic differentiation to embed the governing physical laws in stochastic differential equations. The discriminator in PI–GAN is represented by a basic FFNN, while the generators are a combination of FFNNs and a NN induced by the SDE</li>
                </ul>
              </li>
              <li>multiple PINNs</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>Injection of Physical Laws
        <ul>
          <li>既然是要解常/偏微分方程，那么微分计算必不可少。四种方法：hand-coded, symbolic, numerical, auto-differentiation，最后一种显著胜出。所谓 auto-differentiation, 就是利用现成框架，框架自动给出原函数的导数的算法。</li>
          <li>Differential equation residual:
            <ul>
              <li>
\[r_F[\hat u_\theta](z)=r_\theta(z):=F(\hat u_\theta(z);\gamma)-f\]
              </li>
              <li>\(r_F[\hat u_\theta](z)=r_\theta(x,t)=\frac{\partial}{\partial t}\hat u_\theta(x,t)+F_x(\hat u_\theta(x,t))\): 原文给出了来源，但是从字面上看不出来与前式的等价性</li>
            </ul>
          </li>
          <li>Boundary condition residual: \(r_B[\hat u_\theta](z):=B(\hat u_\theta(z))-g(z)\)</li>
        </ul>
      </li>
      <li>Model Estimation by Learning Approaches
        <ol>
          <li>Observations about the Loss
            <ul>
              <li>\(\omega_F\) accounts for the fidelity of the PDE model. Setting it to 0 trains the network without knowledge of underlying physics.</li>
              <li>In general, the number of \(\theta\) is more than the measurements, so regularization is needed.</li>
              <li>The number and position of residual points matter a lot.</li>
            </ul>
          </li>
          <li>Soft and Hard Constraints
            <ul>
              <li>Soft: penalty terms. Bad:
                <ul>
                  <li>satisfying BC is not guaranteed</li>
                  <li>assignment of the weight of BC affects learning efficiency, no theory for this.</li>
                </ul>
              </li>
              <li>Hard: encoded into the network design. <a href="https://doi.org/10.1007/s00466-020-01952-9">Zhu et. al</a></li>
            </ul>
          </li>
          <li>Optimization methods
            <ul>
              <li>minibatch sampling using the Adam algorithm</li>
              <li>increased sample size with L-BFGS (limited-memory Broyden-Fletcher-Goldfarb-Shanno)</li>
            </ul>
          </li>
        </ol>
      </li>
      <li>Learning theory of PINN: roughly in DE, consistency + stability → convergence
        <ol>
          <li>convergence aspects: related to the number of parameters in NN</li>
          <li>statistical learning error analysis: use <em>risk</em> to define <em>error</em>
            <ul>
              <li>Empirical risk: \(\hat R[u_\theta]:=\frac{1}{N}\sum_{i=1}^N \left\|\hat u_{\theta}(z_i)-h_i\right\|^2\)</li>
              <li>Risk of using approximator: \(R[\hat u_{\theta}]:=\int_{\bar \Omega}(\hat u_{\theta}(z)-u(z))^2dz\)</li>
              <li>Optimization error: the difference between the local and global minimum, is still an open question for PINN. \(E_O:=\hat R[\hat u_{\theta}^*]-\inf_{\theta \in \Theta}\hat R[u_\theta]\)</li>
              <li>Generalization error: error when applied to unseen data. \(E_G:=\sup_{\theta \in \Theta}\left\|R[u_\theta]-\hat R[u_\theta]\right\|\)</li>
              <li>Approximation error: \(E_A:=\inf_{\theta \in \Theta}R[u_\theta]\)</li>
              <li>Global error between trained deep NN \(u^*_\theta\) and the correct solution is bounded: \(R[u^*_\theta]\le E_O+2E_G+E_A\)</li>
              <li>有点乱，本来说 error 是误差，结果最后还是用 risk 作为误差</li>
            </ul>
          </li>
          <li>error analysis results for PINN</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>Differential Problems Dealt with PINNs：读来感觉这一部分意义不大，将来遇到需要解决的问题时，回来看看之前有没有人做过就行了——另一方面看，一类方程就需要一类特殊构造的神经网络来解，那么说明神经网络解方程的通用性并不好~
    <ol>
      <li>Ordinary differential equations:
        <ul>
          <li>Neural ODE as learners, a continuous representation of <strong>ResNet</strong>. [<a href="https://doi.org/10.1016/j.jsv.2021.116196">Lai et al</a>], into 2 parts: a physics-informed term and an unknown discrepancy</li>
          <li>LSTM [<a href="https://doi.org/10.1016/j.cma.2020.113226">Zhang et al</a>]</li>
          <li><a href="https://doi.org/10.1016/j.compstruc.2020.106458">Directed graph models</a> to implement ODE, and Euler RNN for numerical integration</li>
          <li>Symplectic Taylor neural networks in <a href="https://doi.org/10.1016/j.jcp.2021.110325">Tong et al</a> use symplectic integrators</li>
        </ul>
      </li>
      <li>Partial differential equations: steady/unsteady的区别就是是否含时
        <ol>
          <li>steady-state PDEs</li>
          <li>unsteady PDEs
            <ol>
              <li>Advection-diffusion-reaction problems
                <ol>
                  <li>diffusion problems</li>
                  <li>advection problems</li>
                </ol>
              </li>
              <li>Flow problems
                <ol>
                  <li>Navier-Stokes equations</li>
                  <li>hyperbolic equations</li>
                </ol>
              </li>
              <li>quantum problems</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>Other problems
        <ol>
          <li>Differential equations of fractional order
            <ul>
              <li>automatic differentiation not applicable to fractional order → <a href="https://doi.org/10.1515/fca-2019-0086">L1 scheme</a></li>
              <li><a href="https://doi.org/10.1137/18M1229845">numerical discretization for fractional operators</a></li>
              <li><a href="https://doi.org/10.1038/s43588-021-00158-0">separate network to represent each fractional order</a></li>
            </ul>
          </li>
          <li>Uncertainty Estimation: <a href="https://doi.org/10.1016/j.jcp.2020.109913">Bayesian</a></li>
        </ol>
      </li>
      <li>Solving a Differential Problem with PINN
        <ul>
          <li>1d non-linear Schrödinger equation</li>
          <li>dataset by simulation with MATLAB-based Chebfun open-source(?) software</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>PINNs: Data, Applications, and Software
    <ol>
      <li>Data</li>
      <li>Applications
        <ol>
          <li>Hemodynamics</li>
          <li>Flows Problems</li>
          <li>Optics and Electromagnetic Applications</li>
          <li>Molecular Dynamics and Materials-Related Applications</li>
          <li>Geoscience and Elastiostatic Problems</li>
          <li>Industrial Application</li>
        </ol>
      </li>
      <li>Software
        <ol>
          <li><code class="language-plaintext highlighter-rouge">DeepXDE</code>: initial library by one of the vanilla PINN authors</li>
          <li><code class="language-plaintext highlighter-rouge">NeuroDiffEq</code>: PyTorch based used at Harvard IACS</li>
          <li><code class="language-plaintext highlighter-rouge">Modulus</code>: previously known as Nvidia SimNet</li>
          <li><code class="language-plaintext highlighter-rouge">SciANN</code>: implementation of PINN as Keras wrapper</li>
          <li><code class="language-plaintext highlighter-rouge">PyDENs</code>: heat and wave equations</li>
          <li><code class="language-plaintext highlighter-rouge">NeuralPDE.jl</code>: part of SciML</li>
          <li><code class="language-plaintext highlighter-rouge">ADCME</code>: extending TensorFlow</li>
          <li><code class="language-plaintext highlighter-rouge">Nangs</code>: stopped updates, but faster than PyDENs</li>
          <li><code class="language-plaintext highlighter-rouge">TensorDiffEq</code>: TensorFlow for multi-worker distributed computing</li>
          <li><code class="language-plaintext highlighter-rouge">IDRLnet</code>: a python toolbox inspired by Nvidia SimNet</li>
          <li><code class="language-plaintext highlighter-rouge">Elvet</code>: coupled ODEs or PDEs, and variational problems about the minimization of a functional</li>
          <li>Other Packages</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>PINN Future Challenges and Directions
    <ol>
      <li>Overcoming Theoretical Difficulties in PINN</li>
      <li>Improving Implementation Aspects in PINN</li>
      <li>PINN in the SciML Framework</li>
      <li>PINN in the AI Framework</li>
    </ol>
  </li>
  <li>Conclusion</li>
</ol>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[本文是《Scientific Machine Learning Through Physics–Informed Neural Networks: Where we are and What’s Next》这篇综述的读书笔记。]]></summary></entry><entry><title type="html">.pdf | 《你的第一本哲学书》笔记（更新中）</title><link href="https://mountaye.github.io/blog/articles/your-first-philosophy-course-what-does-it-all-mean" rel="alternate" type="text/html" title=".pdf | 《你的第一本哲学书》笔记（更新中）" /><published>2023-03-03T00:00:00-06:00</published><updated>2023-03-03T00:00:00-06:00</updated><id>https://mountaye.github.io/blog/articles/your-first-philosophy-course-what-does-it-all-mean</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/your-first-philosophy-course-what-does-it-all-mean"><![CDATA[<p>托马斯·内格尔 (Thomas Nagel) 的《What Does It All Mean?——A Very Short Introduction to Philosophy》，中文版将标题译作“你的第一本哲学书”。</p>

<p>原作者在中译版前面写了如下一段话：</p>

<blockquote>
  <p>本书将传达在当代西方哲学中最为核心的东西——思想自由的理念。它会使读者感到，要评估每一种主张、每一条论证和每一套理论，并且尝试着判断它们是否可以被接受，这最终都依赖于每一个人的独立思考，而非听命于权威。</p>
</blockquote>

<hr class="slender" />

<p>该书依据讨论的问题共分为9章，每章涉及正反方的多个哲学流派：</p>

<ol>
  <li>外部世界是否存在
    <ol>
      <li>存在：常识、科学思维、验证论 (verificationism)</li>
      <li>不存在/不知道：唯我论 (Solipsism)、怀疑论 (skepticism)</li>
    </ol>
  </li>
  <li>关于他人心灵的知识
    <ol>
      <li>能了解：常识</li>
      <li>不能了解：怀疑论 (skepticism)</li>
    </ol>
  </li>
  <li>心灵与大脑之间的关系
    <ol>
      <li>心理活动就是脑的生理过程：常识、物理主义(physicalism)/唯物主义(materialism)</li>
      <li>心理活动不是/不止生理过程：二元论 (dualism)、两面论(dual aspect theory)</li>
    </ol>
  </li>
  <li>语言如何可能
    <ol>
      <li>词语和指代的对象之间存在特殊的联系。</li>
      <li>词语和指代的对象之间存在怎样的联系，这种联系如何存在？</li>
    </ol>
  </li>
  <li>我们是否有自由意志
    <ol>
      <li>有：非决定论 (non-determinism)、科学思维(?)</li>
      <li>没有：决定论 (determinism)</li>
    </ol>
  </li>
  <li>道德的基础：在何种程度上是普遍和客观的
    <ol>
      <li>存在普世道德：道德整体一致</li>
      <li>不存在普世道德：道德相对主义</li>
    </ol>
  </li>
  <li>何种不平等是不公正的</li>
  <li>死亡的本性</li>
  <li>生活的意义</li>
</ol>

<hr class="slender" />

<p>本科时候计算物理老师的教学水平不敢恭维，但是他说过一句我深感认同的话：“当你知道该用哪种数据结构装下你对问题的描述的时候，你就几乎已经解决了这个问题。”我决定用 YAML 格式总结全书内容，每一章的结构如下，：</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">辩题</span><span class="pi">:</span>
<span class="na">总结</span><span class="pi">:</span> <span class="c1"># 总结放在正反方论点前面，是因为后两者实在是太长了~ </span>
<span class="na">正方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【流派 (translation)】</span> <span class="c1"># 支持正方的第1种流派</span>
  <span class="na">主张</span><span class="pi">:</span> <span class="c1"># 该流派的各条观点</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="c1"># 第1条观点</span>
    <span class="na">论证</span><span class="pi">:</span> 
    <span class="na">反驳</span><span class="pi">:</span> <span class="c1"># 其他流派对这一观点的反驳</span>
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【流派 (translation)】</span> <span class="c1"># 第1条反驳来自的流派</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="c1"># 第1条反驳的内容</span>
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="c1"># 第2条反驳，其他字段同上</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="c1"># 第2条观点，其他字段同上</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【流派 (translation)】</span> <span class="c1"># 支持正方的第2种流派</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="c1"># 该流派的第1条观点</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="c1"># 同上</span>
    <span class="na">反驳</span><span class="pi">:</span> 
<span class="na">反方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【流派 (translation)】</span> <span class="c1"># 支持反方的第1种流派</span>
  <span class="na">主张</span><span class="pi">:</span> <span class="c1"># 同上</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> 
    <span class="na">论证</span><span class="pi">:</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> 
      <span class="na">内容</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="c1"># 同上</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="c1"># 同上</span>
</code></pre></div></div>

<hr class="slender" />

<p>以下是 YAML 格式的全书内容总结。</p>

<h3 id="1-外部世界是否存在-how-do-we-know-anything">1. 外部世界是否存在 (How Do We Know Anything?)</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">辩题</span><span class="pi">:</span> <span class="s">在你的心灵之外是否存在别的东西，你能否证明其存在或不存在。</span>
<span class="na">总结</span><span class="pi">:</span> <span class="s">这就给我们留下了如下三个问题：</span>
<span class="pi">-</span> <span class="s">1. 你心灵之内的东西是惟一存在的东西，或者说即使有一个你意识之外的世界，这个世界也和你所相信的世界大相径庭，这种可能性有意义吗？</span>
<span class="pi">-</span> <span class="s">2．如果这些可能性是存在的，你是否有办法向自己证明它们实际上并不是真的？</span>
<span class="pi">-</span> <span class="s">3．如果不能证明在你的心灵之外还有别的东西存在，你可以继续若无其事地相信外部世界的存在吗？</span> 
<span class="na">正方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【常识】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">外部世界客观存在。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">因为如果不是在你之外有东西可以发光或反光，将光照射到你眼睛里，并且使你产生了视觉经验，你就看不到建筑、人群或者星星这些东西了。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">你能说出的理由仍然是关于外在世界以及你与这个世界之间的联系，而它必须建立在你的感官证据之上。然而，你之所以能够用这些感官证据来说明视觉经验是如何产生的，只是因为你已经在心灵之内预设了外在世界的存在。如果你用自己的感觉印象去证明感觉印象的可靠性，你就是在循环论证，无法得出任何东西。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">一定得有一个外在世界。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">否则的话你就是在没有任何外在原因的情况下拥有了所有的体验，而这实在是令人难以置信。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【怀疑论 (skepticism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">第一，即使有外在原因，你也不能从你的经验内容中发现这些原因是什么样的，因为你从来没有直接观察过这些原因。第二，你凭什么认为，万事万物都得有一个原因呢？</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">客观世界是存在的</span>
    <span class="na">论据</span><span class="pi">:</span> <span class="s">实际上你并不能认真地让自己相信周围的东西可能并不真实存在。我们关于外部世界存在的信念是发自本能而坚定有力的：我们不可能经过哲学论证就丢掉这个信念。如果我们对于心灵之外的世界的信念是如此自然，也许我们就不需要为此寻找根据。我们可以就这么相信着，并且权当自己是对的。事实上，这也正是绝大多数人在找不到这种根据之后所做的：他们不能提出反对怀疑论的理由，也不愿意接受怀疑论。但是，这也就意味着，我们虽然可以坚持关于这个世界的大多数通常信念，却不得不面对两个事实：1）这些信念可能完全是错误的；2）我们无法排除这种错误的可能性。</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【科学思维】</span> 
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">我们相信外部世界存在，这就像科学家相信原子的存在是一样的道理</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">从世界最初看上去的样子，过渡到与这种样子有所不同的实在。我们尝试用理论去解释现象，这种理论被认为是描述了现象背后的某种“实在”，而这种“实在”我们是不能直接观察到的。通过这种方式，物理学和化学研究得出结论说：我们所看到的周围一切东西都是由看不到的微小原子构成的。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【怀疑论 (skepticism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">科学推理的过程同样会引起我们一直在思考的怀疑论难题：科学和知觉一样经不起推敲。即使科学观念从理论上很好地解释了我们的观察，可是我们又怎么知道在我们意识之外的世界对应于这些观念呢？如果不能建立起感觉经验和外部世界之间的可靠联系，我们也就没有理由去信赖建立在这种联系基础上的科学理论。</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【验证论 (verificationism)】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">极端怀疑论是没有意义的。有时候我们的观察是被歪曲的，但是这意味着它们能够被其他的观察所纠正。</span>
    <span class="na">论据</span><span class="pi">:</span> <span class="s">说存在着一个永远没有人能够发现的外在实在，这种说法是毫无意义的。具体论证如下：如果你做了一个梦，你就能够从中醒来，并且发现自己刚才睡着了；如果你看到了一幕幻象，其他人（或者你本人在稍后的时间里）就能够看出它不是真的。与实在不相符合的印象和现象必须能够与那些与实在相符合的印象和现象相互比照，否则现象和实在之间的区分也就没有意义了。</span>
    <span class="na">反驳</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【怀疑论 (skepticism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">如果有一个外在世界，那么，其中的东西是因为它们存在，所以才能被观察到，而不是相反。存在并不等同于可观察性。虽然当我们能够观察到经验和实在之间的差别时，就可以形成梦和幻象这样的观念，但是，似乎即使这种差别不能够被观察到，这类观念仍然可以形成。</span>
<span class="na">反方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【唯我论 (Solipsism)】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">只有你的心灵才是惟一存在的东西。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
      <span class="na">反方</span><span class="pi">:</span> <span class="s">【验证论 (verificationism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">除非有人能观察到物质世界是不存在的，否则就不能说实际上它是不存在的。而怀疑论者所认为的恰恰是除了他在心灵之内所做的观察之外，没有人能够观察到物质世界或者别的什么东西。因此，唯我论是没有意义的。它想要从我的印象整体中抽掉外部世界，但却失败了，因为一旦外部世界被抽掉，这些印象就不仅仅是印象，而成为了对实在的感知本身。</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【怀疑论 (skepticism)】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">你只能知道自己的感觉印象和经验，除此之外就一无所知。或许有一个外在世界，或许没有。如果有一个外在世界的话，它和你所看到的世界或许完全不同，或许大体类似，但是无论怎样，你都对此一无所知。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">你甚至根本不能确信自己过去的存在与经验。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">因为你所接触的一切都只不过是心灵中当下呈现的内容――包括记忆中的印象。要证明自己不可能是几分钟前才开始存在的，你只有依赖诸如“人是怎样产生的以及他们的记忆是怎么产生的”等等这样一些信念，可是这些信念本身就是从一些被你认为在过去确曾发生的另外一些事情上总结出来的。然而，如果从这些信念出发来证明你自己过去就是存在的，这还是一个循环论证。你这是假定了过去的实在性，再用它来证明过去的实在性。</span>
  <span class="pi">-</span> <span class="na">观点</span><span class="pi">:</span> <span class="s">【自我中心困境】你总是无法跳出自己心灵的牢笼。如果对验证论的反驳是正确的，那么认为这个世界一无所有而所有的东西都只是在你的心灵中存在，这种想法也就不是没有意义的，尽管无论是你还是其他任何人都不可能发现这一点是真是假。而且，如果它不是无意义的，而是你必须思考的一种可能性，那么似乎你就没有办法证明它是错误的，因为一切这样的尝试都只能是循环论证而已。</span>
</code></pre></div></div>

<h3 id="2-关于他人心灵的知识-other-minds">2. 关于他人心灵的知识 (Other Minds)</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">辩题</span><span class="pi">:</span> <span class="s">在多大程度上能知道他者是否有意识</span>
<span class="na">总结</span><span class="pi">:</span> <span class="s">因此问题就在于：除了你知道自己是有意识的这个事实之外，关于世界中其他有意识的生命的情况，你还能知道些什么呢？是否可能，有意识的生命比你设想的要少得多（除了你自己的意识之外再没有别的意识），或者要多得多（即使你认为是无意识的东西实际上也是有意识的）？</span>
<span class="na">正方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【常识】</span>
  <span class="na">主张</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">可以把两个人的味觉经验进行直接比较。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">因为你们都是人，并且你们都能把不同的冰淇淋的味道区别开来。都能说出草莓冰淇淋和香草冰淇淋的区别何在――所以说你们的味觉经验就应当是相同的。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【怀疑论 (skepticism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">有什么理由认为，其他人察觉到的联系和你所察觉到的相同呢？要是他所尝到的巧克力味和你所尝到的香草味一样，而他所尝到的香草味又和你所尝到的巧克力味一样，这不也完全说得通么？</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">味觉和色觉经验总是可以无一例外地联系到某些特定的作用在感官上的物理刺激，无论接受这些刺激的人是谁。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【怀疑论 (skepticism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">你做这样的假设并无证据，并且因为这种假设本身的特点，你也不可能有任何证据：你所能观察到的一切都只是你自身经验之内的联系而已。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">内在经验和特定的可观察到的反应之间有关联。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">的确有一些不确定的成分，外在刺激与内在经验之间的联系或许并不是在每个人身上都一模一样的。然而，这种彼此经验中的差异不可能太极端，否则我们就能够察觉到了。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【怀疑论 (skepticism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">你观察到了龇牙咧嘴的表现和你自身经验中称为“酸”的味道之间的联系，然而你怎么知道别人身上也有同样的联系呢？或许让你朋友龇牙咧嘴的，恰恰是你喝麦片粥时的味觉体验呢。</span>
<span class="na">反方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【怀疑论 (skepticism)】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">除了你自己的心灵之外，其他人的心灵或者经验的性质，都值得怀疑。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">你只能观察到人类以及其他动物的身体。你看到他们做的事情，听到他们讲话和发出其他声音，并且看到他们如何对自己的环境做出反应。你也能把其他生灵给剖开，看到他们的身体内部，或许还可以将他们的身体结构与你自己的作个对比。这些都不能使你直接接触到他们的体验、思想和感觉。如果你相信他人精神生活中发生的事情，这只能通过观察他们的生理构造和身体行为。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">无法知道你的朋友是有意识的，无法知道在你自己的心灵之外，还有任何别的心灵存在。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">1. 你认为在心灵、行为、身体结构和物质环境之间有一种关系，但是对于这种关系，你所直接观察到的惟一例证就是你自己。即使其他人和动物根本没有任何经验，没有任何一种内在精神生活，而只是比较精致的生物机器，你也根本看不出其中有什么区别。2. 我们相信其他人是有意识的，并且绝大多数人都相信哺乳动物和鸟类也是有意识的。然而，说到鱼、昆虫、毛虫或者水母有没有意识，人们的意见就不尽一致了。我们绝大多数人会认为（如果我们能想到这个问题的话）组成我们身体的单个细胞是没有意识的。可是，你怎么知道事情是这样的呢？</span>
</code></pre></div></div>

<h3 id="3-身心关系-the-mind-body-problem">3. 身心关系 (The Mind-Body Problem)</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">辩题</span><span class="pi">:</span> <span class="s">你的思想、感受、知觉、感情和愿望等等，是附加在你的大脑中所发生的生理过程之上的东西呢，还是本身就是这些生理过程呢？</span>
<span class="na">总结</span><span class="pi">:</span> <span class="s">看起来，在世界上有两种完全不同种类的东西：一是属于物质实在的东西，许多不同的人都能够从外部观察这些东西；二是另外一些属于心理实在的东西，我们每个人都从自身的内部体验到这些东西。这不仅仅是对人类才成立的，狗、猫、马和鸟看起来也是有意识的，鱼、蚂蚁和甲壳虫可能也一样。谁知道这个列举应当停止于何处呢？为什么把一大堆物质元素以某种方式放在一起，不仅会产生出一个自己运转的生物有机体，而且能产生出一个有意识的存在者？除非我们能解释这一点，否则就不能对这个世界形成一个充分而普遍的看法。如果意识自身能够等同于某种物理状态，那么就有可能找到一种统一的物理理论解释身心关系，甚至从而可以找到一种统一的物理理论来解释整个宇宙。然而，反对把意识仅仅视为一种物理状态的那些理由是如此的有力，以至于似乎不可能用一种物理理论来解释实在整体。</span>
<span class="na">正方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【常识】</span> 
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">对于任何发生在你的心灵或意识中的活动，你的脑中同时也要发生一些活动。</span>
    <span class="na">论据</span><span class="pi">:</span> <span class="s">人人都知道，意识活动依赖于肉体上的活动。你要是扎一下脚趾就会感到疼痛，要是闭上眼睛就看不到眼前的东西，要是咬一口“好时”，就会尝到巧克力的味道；要是有人在你脑袋上猛击一下，你就昏倒了。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【二元论(Dualism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">如果一个科学家在你吃巧克力的时候把你的头盖骨打开进行观察，他所能看到的不过是一堆灰色的神经细胞。如果他用工具去探测在这些细胞里都发生了什么，他会发现许多不同种类的生理作用。但是，他能发现巧克力的“味道”吗？似乎不能。由于你品尝巧克力的体验以一种特定的方式被嵌入到你的心灵中，所以它不可能被其他任何人观察到――即使打开你的头盖骨，观察你的大脑也是徒劳。你的体验以一种特殊的方式隐藏在你的心灵里，它不同于大脑隐藏在脑袋里的方式。</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【物理主义(Physicalism)】/【唯物主义(Materialism)】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">人只是由物质材料构成的，而人的心理状态只是他们大脑的生理状态。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">正如我们熟悉的其他一些事物的真实本质（我们原先不可能料想到）是由科学研究最终揭示出来的一样，我们最终也可以发现心灵体验实际上是脑部的生理作用。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">虽然主张品尝巧克力的体验只不过是你脑中复杂的生理事件，这听起来有点奇怪，但是，比起人们发现许许多多普通的东西具有出人意料的真实本质这一点来，它并不更加让人奇怪。科学家已经发现了光是什么，植物如何生长，肌肉如何运动，因此，发现心灵的生物学本性也不过是时间问题而已。比如说，人们发现钻石是由碳元素构成的，就和煤一样，只不过原子排列有些不同。又比如，众所周知水是由氢和氧构成的，但是这两种元素分开来看一点也不像水。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【二元论(Dualism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">其他的东西与心灵有所不同。譬如，当我们发现水的化学构成时，我们与之打交道的是某种明显存在于物质世界中的东西，某种我们看得见摸得着的东西。当我们分析出水是由氢和氧构成的时候，不过是把一个外在的物质实体分解成更小的物质成分而已。这种分析的关键在于，我们并不是以化学分析的方式来分解水给我们带来的外观、触感和味道。这些东西发生在我们的内在体验中，而不是发生在我们将其分解为原子的水中。而一种滋味的感觉是不可能由许许多多脑中的物理事件构成的，不管这些事件有多么复杂。一个物质的整体能被分解成较小的物质部分，但是一个心理状态不能。物质部分不能加总为心理整体。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">唯有能够被科学研究的物质世界才是存在的，这就是客观实在的世界。</span>
    <span class="na">反驳</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">这样一来,他们就得为感受、欲望、思想、经验――还有你和我――在物质世界上找到容身之所。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">你的心理状态的本质在于这些状态与引起它们的东西以及与它们所引起的东西之间的关联。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">比如说，当你绊伤了脚趾感到疼痛的时候，这种疼痛就是某种在你脑中所发生的事件。它不只是物理属性的总和，也并非某种神秘的、非物理的属性。毋宁说，使得疼痛之为疼痛的东西，乃是通常由伤害引起的一种脑的状态。这种状态通常使你喊叫跳跃并且躲避弄伤你的东西。它可以是脑的一种纯粹的生理状态。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">但是这些东西看起来似乎并不足以构成一种疼痛。疼痛也以某种特定的方式被感到，而这个“感到”看起来与一切有关它的因果联系都不同，也不同于疼痛的一切物理属性</span>
<span class="na">反方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【二元论(Dualism)】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">人是由两种极为不同的东西组成的：一个复杂的生理有机体，加上一个完全精神性的灵魂。存在着一个灵魂。它以一种特殊的方式附着在你的身体上，因此二者可以相互作用。</span>
    <span class="na">论据</span><span class="pi">:</span> <span class="s">别人能打开你的脑袋，观察里面的大脑，但是他们不能够打开你的心灵，观察里面的内容――至少不能像打开你的脑袋那样去打开你的心灵。</span>
    <span class="na">反驳</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">【物理主义(Physicalism)】/【唯物主义(Materialism)】</span>
      <span class="na">内容</span><span class="pi">:</span> <span class="s">既然世界上其他一切东西都是由物质材料构成的，只是同一些化学元素不同的组合而已，为什么我们就不是如此？精子和卵子在受精的时候结合起来，产生出一个单一的细胞，然后再经由一个复杂的生理过程长成了我们的身体。通过添加一些普通的材料，一个细胞逐渐演化成了一个带有胳膊、腿、眼睛、耳朵还有大脑的人体，使得我们能够移动、感觉、看到东西，最后还能说话和思考。有些人认为，这个复杂的生理过程本身就能够产生出有意识的生命。难道不是这样吗？无论如何，难道说单凭哲学论证就能否认这一点么？既然哲学不能告诉我们星星或者钻石是由什么构成的，那么，它又怎么能告诉我们人是由某种东西或者不是由某种东西构成的呢？</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【两面论(Dual Aspect Theory)】</span>
  <span class="na">主张</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">脑是意识的发生地，但是它的意识状态并非仅仅是物理状态。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">当你咬一口巧克力的时候，在你的脑中就产生了一个两方面的状态或者作用：一个物质方面，它包括许多不同的电化学反应；一个心理方面，也就是对巧克力的味觉体验。当这个作用发生的时候，科学家如果观察你的大脑，只会看到物质方面，但是你自己却可以从内部感受到心理方面：你会有尝到巧克力的感觉。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">你并不是一个身体加一个灵魂，而只是一个身体。你的身体或至少是你的脑，不仅仅是一个物理系统，它同时有物质和精神两个方面，它可以被拆解掉，但是它有一种内在的方面，是不可能通过拆解而显露出来的。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">你之所以在这个内在方面有尝到巧克力味的体验，是因为当你吃巧克力的时候，大脑就会出现某种状态，这种状态就其内在方面而言，就是吃巧克力的体验。</span>
</code></pre></div></div>

<h3 id="4-语言如何可能-the-meaning-of-words">4. 语言如何可能 (The Meaning of Words)</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">辩题</span><span class="pi">:</span> <span class="s">我们所说的声音、所写的符号，如何可能具有意义？</span>
<span class="na">总结</span><span class="pi">:</span> <span class="s">我们是有限的、渺小的造物，但是凭着声音或者纸上符号的帮助，意义却能够使我们把握整个世界以及其中的万事万物，甚至发明一些不存在而且或许永远也不会存在的东西。</span>
<span class="na">正方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">无</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">词语和它指代的事物之间的关系不是拟声或者象形的关系。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">词语不能只当作标签，在句子或陈述里才有意义。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">一些词能用另一些词来定义，但是定义不能充当一切词语意义的基础，最后我们总是要还原到直接具有意义的词。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">人在使用一个词语的时候，指的是这种东西在世界上过去、现在和未来所有的样本，超出了一个人所见过的所有这种东西，涵盖了一个极其广大而又特定的范围。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">无论一个词和它所指的对象之间的关系是什么，在其他语言中也具有这种关系。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">词和指代的对象的关系是间接的，词背后有某种别的东西：概念、观念或思想，这些东西以某种方式涵盖了宇宙中的所有对象。</span>
    <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">这个“中介”是什么东西？他是你心灵中的某种东西吗，还是心灵之外，而你以某种方式捕捉了它？</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">我们用同一个词指称同样的事物，但我们关于这个词和事物的经验都各不相同，如何做到这一点呢？一开始我们的问题是词语如何表示一类物体，现在问题变成了词语如何表示概念，并没有解决问题。</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">还产生了新的问题：这些概念是如何与一切现实的物体样本联系在一起的。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">【可能有人认为】，这一普遍因素就是当我们使用这个词的时候某种在我们心灵中所共同拥有的东西。</span>
    <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">这种东西是什么？可能当我说这个词的时候，我的脑海里会出现某种意象，但是其他人心里的图像也可能与我的完全不同，这不妨碍我们用这个词表示同样的意思。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">意义的神秘之处在于，看上去它似乎不在任何地方：不在词语中，不在心灵中，也不在词语、心灵和我们所谈论的事物之间盘旋的、独立的概念或观念中。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">虽然如此，我们仍时时处处使用着语言，它使得我们能够思考复杂的、跨越了广袤时空的思想。</span>
    <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">语言的普遍涵盖性说的太过头了，日常生活中，我们用语言表达的大多数陈述和思想要具体的多。“把盐递给我。”这里的语言只是一个“信号-反应”系统。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">是不是大部分语言都只是一个“信号-反应”系统呢？</span>
    <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">语言并不仅此而已，不只是用一两个词简单交流，而是对远远超出当下周围环境的描述或者虚构。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">利用词语在较大范围内的使用来帮助我们理解它在较小范围内的使用，似乎更为可能。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">“盐在桌子上。”这样的话，无论是在吃午饭的时候，还是作为一种对可能出现的想想场景的假设性陈述，都有着相同的意义。因此，处于日常的、实用的目的所说的话中一定有某种普遍的东西，这种东西应该同样能被用来解释那些出于其他完全不同的目的而说的话，从而使这些话的意义都相同。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">语言是一种社会现象，当我们还是小孩子的时候就开始学说话，落入一个业已存在的系统中。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">把我使用的词语放在一个更大的语境中，这对解释他们的普遍意义似乎有所帮助。</span>
    <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">一个词的意义包含了它所有可能的，或真或假的使用，现实的使用仅仅是所有可能的使用中极小的一部分而已。</span>
</code></pre></div></div>

<h3 id="5-我们是否有自由意志-free-will">5. 我们是否有自由意志 (Free Will)</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">辩题</span><span class="pi">:</span> <span class="s">当一个人说自己能够做一些与实际所做的不同的事的时候，这话是什么意思？如果一个人的确可以做与实际所做的不同的事情，我们和世界需要具有哪些特点？</span>
<span class="na">总结</span><span class="pi">:</span> 
<span class="na">正方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">非【决定论(Determinism)】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">人们在外在条件一模一样的情况下，并不需要发生任何不同的事情作为前提，就能够做某些他们实际上并没有做的事情。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">在你最终决定自己的选择是什么的那一刻之前，一切都不是无可挽回的。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">有人（也许还有一些高等动物）才具有这种“能够”或“本来可以”。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">自由行为是世界的一种基本特性，不能再加以分析</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">某件事情不需要原因而发生，和一个行为不需要原因而被做出，这是两个不同的问题。这种不同我们大家都知道，即使我们都不能对其加以解释。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">如果说你的行为并未被你的愿望、信念和人格及其他东西所事先决定，它看起来就是无缘无故自己发生的事情。这样一来，你在什么情况下，在什么意义上能够去“做”它呢？</span>
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">两种选择在事先皆有可能，除非是“我”决定选其中某个，否则我仍然不需要对这种选择负责，如果没有东西决定它，我又如何能够决定它呢？</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">科学</span>
  <span class="na">主张</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">决定论也许并不是正确的.</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">对于基本粒子而言，决定论是不适用的。(量子力学。)也许决定论对于人的行为也是不适用的，这就给自由意志和责任留下了余地。</span>
<span class="na">反方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【决定论(Determinism)】</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">某些事情是先前就被决定的。比如说，太阳明天将在一个特定的钟点升起</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">在绝对的意义上，我们永远不可能做与我们事实上所做的不同的事。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">在任何情况下，我们行动的各种条件决定了我们的行为，并且使它成为不可避免的。一个人的经验、欲望和知识、他的遗传因子、社会环境、各种选择的性质，以及其他我们尚不知晓的因素，这一切加在一起，共同使得一个在具体情境下的行为成为必然。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="err">*</span><span class="nv">*不主张</span><span class="err">**</span> <span class="s">我们能够知道宇宙中的一切法则，并且用这些法则来预言未来会发生什么。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">首先，我们不可能知道影响人类行为的一切复杂条件；其次，即使我们知道了若干条件，并且尝试着做出预言，但是这一预言本身就会导致条件的变化，它本身就可能改变被预言的结果。</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【决定论(Determinism)】分支1</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">不能责备干坏事的人和夸奖做好事的人。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">在当时的条件下，他们不可能做别的事情。这样一来我们就没有理由让他们为自己的行为负责了。</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【决定论(Determinism)】分支2</span>
  <span class="na">主张</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">即使人的行为是不可避免的，扬善斥恶的做法仍然是有意义的。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">就算一个人被事先决定了要做坏事，这也并不意味着他所做的就不是坏事了。进一步来说，如果我们不去责备或者甚至惩罚他，那就难保他下次不会再犯。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">如果我们认为他的行为是被事先决定的，而仍然要责罚他，这并不意味着我们认为他应该对他所做的负责，我们只是试图以此来改变他将来的行为。</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">【决定论(Determinism)】分支3</span>
  <span class="na">主张</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">只有我们的行为是被决定的，而非自由选择的，才谈得上责任。</span>
    <span class="na">论证</span><span class="pi">:</span> <span class="s">如果一个行为是你所做的，那么它就是被你身上的某些东西所引起的。这一解释看起来意味着你的行为最终仍然是被事先决定的。因果决定论本身并不对自由构成威胁，仅仅是某些特定种类的原因才与自由相悖。</span>
</code></pre></div></div>

<h3 id="6-道德的基础-right-and-wrong">6. 道德的基础 (Right and Wrong)</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">辩题</span><span class="pi">:</span> <span class="s">道德来自于何处/道德的动机是什么？</span>
  <span class="na">总结</span><span class="pi">:</span> <span class="s">道德论证想要诉诸于每个人心中追求公义的能力。这种能力被深深埋藏着，需要与其他自私或不自私的私人性动机相竞争。为道德辩护的困难在于人存在着太多种动机。</span>
  <span class="na">正方</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">对与错和是否违反规定不是一回事。</span>
    <span class="na">主张</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">否则，人们就不能像评价行为的对错一样来评价一条规定的对错了。</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">道德考虑的是一个行为对他人的影响</span>
    <span class="na">主张</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">并不一定直接影响他人的感受，因为他们可能永远也发现不了。</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">认为做某事是错误的，是因为这件事会影响其他人，其他人不喜欢你做这样的事，而且一旦发现还会加以反对。</span>
      <span class="na">反驳</span><span class="pi">:</span> 
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">“可是谁在乎他们呢，我就是想做某事，干嘛在乎他们高不高兴？”</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">找出这个人在乎的某种东西，然后把这种东西和道德联系起来</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">承上，宗教是道德的基础</span>
    <span class="na">主张</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">即使你能在世时坏事做尽，但是死后上帝会惩罚你</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">遵守上帝的诫命，并不是出于害怕惩罚，而是对上帝的爱</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">很多人不信上帝，却依然能够判断是非</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">即使上帝存在且禁止某些事，仍不能使这些事成为错误的。上帝不能通过禁止某些多年的习惯（比如穿袜子先穿左脚）就让这些习惯成为错误的。</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">害怕惩罚、追求奖赏、对上帝的爱，看起来并不是遵守道德的正确动机。不应该做某些事，是因为它们对受害者是坏事，而不是你害怕对自己不利的后果，或上帝不高兴。</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">承上，道德力量归结为行为者自身的利益</span>
    <span class="na">主张</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">你想要别人怎么对你，你就应该怎么对别人。</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">假如你做的好事不被人发现，或者做了坏事却能及时逃走，这种说法就不适用了。</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">对于他人直接的关心乃是道德的无可替代的基础。</span>
    <span class="na">主张</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">即使一个人自私心非常强烈，但他仍有某种理由去关心他人。</span>
      <span class="na">论证</span><span class="pi">:</span> <span class="s">“要是别人也这么对你，你会怎么想？”</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">“我当然很不高兴，但是幸运的是没人这么对我，而是我这么对待别人，我可不在乎别人怎么想。”</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">“我根本不会感到怨恨，我不认为他有什么理由去在乎我的感受。”</span>
  <span class="na">反方</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">道德考虑的不是一个行为对他人的影响</span>
    <span class="na">主张</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">道德论证的就是不做一件事的理由，如果某人根本不把其他人当回事，假如他能逃避惩罚的话，他有什么理由不去做这些事？如果没有理由解释他为什么不应该这么做，说这种行为错误的意义何在？</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">“我当然很不高兴，但是幸运的是没人这么对我，而是我这么对待别人，我可不在乎别人怎么想。”</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">这种感觉不只是不高兴而已，你会怨恨做这件事的人。如果你感到怨恨，你就承认了你认为这个人不应当伤害你。那就得考虑这个不应当的理由是什么。这个理由不是因为他伤害的是你，因为他没有理由只伤害你而不伤害别人。这个理由应当是普遍有效的，因此你自己也不能例外。</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">“我根本不会感到怨恨，我不认为他有什么理由去在乎我的感受。”</span>
      <span class="na">反驳</span><span class="pi">:</span> 
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">有多少人会问心无愧地这么说呢，绝大多数人都认为他们的切身利害，不仅对于他们自己是重要的，在某种意义上其他人也不该忽视。当我们被伤害的时候，不仅对我们来说是件坏事，这本身就是坏事。</span>
<span class="pi">-</span> <span class="na">辩题</span><span class="pi">:</span> <span class="s">我们应该做到多大程度的不偏不倚？</span> 
  <span class="na">总结</span><span class="pi">:</span> <span class="s">道德的动机并未告诉我们如何考虑他人的利益，孰是孰非的细节仍然众说纷纭。</span>
  <span class="na">正方</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">主张</span><span class="pi">:</span> <span class="s">人应该像关心自己一样关心其他人。</span>
    <span class="pi">-</span> <span class="na">反驳</span><span class="pi">:</span> 
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">你每次去看电影的时候都应当问自己：“如果我把买票的钱送给别人，或者救济贫民，这对于他们来说不是更大的幸福吗？”</span>
  <span class="pi">-</span> <span class="na">主张</span><span class="pi">:</span> <span class="s">他对和自己比较亲密的人或许会有某种特殊的情感，但是，如果他是完全不偏不倚的话，他就不能更为偏向他们。</span>
<span class="pi">-</span> <span class="na">辩题</span><span class="pi">:</span> <span class="s">对与错的标准对每个人来说都一样吗？</span>
  <span class="na">正方</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">道德一般被认为是普遍的。</span>
    <span class="na">主张</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">对错对每个人来说都是一样的，但并非每个人都有理由去扬善避恶。</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">这种说法承认了道德的普遍性，却牺牲了道德的力量。</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">人人都有理由做好事而不做坏事，但这些理由并不依赖于人的实际动机。</span>
      <span class="na">论证</span><span class="pi">:</span> <span class="s">毋宁说，这些理由是用来改变人的不良动机的。</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">没有说清楚这些不依赖于人人都有的实际动机的普遍理由是什么。</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">道德的标准是普遍的，但是道德动机依赖于他对一般人的关心程度。</span>
      <span class="na">论证</span><span class="pi">:</span> <span class="s">如果他有强烈的道德动机，也就会有强烈的道德理由和道德要求；如果他的道德动机非常薄弱，甚至根本没有，其道德要求也就</span>
  <span class="na">反方</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">不会有一个人人都有理由遵守的基本行为标准。</span>
    <span class="na">主张</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">如果不去做某事是因为他是错的，并且人做事总是处于一定的动机，而人们的动机是千变万化的，那么就很难有唯一的对错标准。</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">对错对每个人来说都是一样的，但并非每个人都有理由去扬善避恶。</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">人人都有理由做好事而不做坏事，但这些理由并不依赖于人的实际动机。</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">道德的标准是普遍的，但是道德动机依赖于他对一般人的关心程度。</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">道德相对性</span>
    <span class="na">主张</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">对于错的最基本标准，完完全全依赖于你所生活的社会接受的是什么样的道德标准。</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">你总是能够批评在自己的社会中被接受的标准，这就必须诉诸于一个更客观的标准，而这个标准在此处是和大多数人的看法相悖的。</span>
  <span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> <span class="s">让自己高兴</span>
    <span class="na">主张</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">人们无论做什么事情，其唯一动机只是这么做让他高兴，或不这么做让他不高兴。那么，要把对别人的关心作为道德的基础自然毫无希望。</span>
      <span class="na">论证</span><span class="pi">:</span> <span class="s">即便是损己利人的明显道德行为，也不过是想避免不做正确的事给他的内疚感，或者想体会做了好事的自豪感。如果他没有这种感觉，也就没有动机变得道德了。</span>
      <span class="na">反驳</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">反方</span><span class="pi">:</span> <span class="s">作者</span>
        <span class="na">内容</span><span class="pi">:</span> <span class="s">进行道德行为时的快乐和反之的不快，并不意味着这种感觉就是他们行为的动机。也有可能是另有动机产生了道德行为，而这些感觉同样是那些动机的结果。</span>
</code></pre></div></div>

<h3 id="7-何种不平等是不公正的-justice">7. 何种不平等是不公正的 (Justice)</h3>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">辩题</span><span class="pi">:</span> <span class="s">那些并不由受苦的人自己造成的不平等在何种程度上是件坏事呢？政府是否应当为此运用权力去减少这种不平等呢？</span>
<span class="na">总结</span><span class="pi">:</span> 
<span class="na">正方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> 
  <span class="na">主张</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">某些不平等是刻意强加的。种族歧视有意剥夺某些种族的人民工作，性别歧视把工作机会和特权都留给男人。这些不仅仅是运气问题，这种不平等是由于一些本不应当人民的基本权益的因素造成的。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">公平的做法是人人机会均等，有能力就能得到。如果政府努力促进这种机会的平等，是件好事。在刻意的歧视的情况下，造成不平等的原因是错误的，补救措施也就只是制止这种歧视而已。</span> 
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">反对非歧视下的不公，是因为我们反对仅仅由于社会经济通常运行机制的缘故，而让无辜的人一生下来就承受种种困境。补救措施要么干预这些原因本身，要么直接干预这些不平等的结果。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">对于社会地位差异造成的不公，如果政府要减少时代积累的、财产上不平等的发展趋势，可取的方案是间接干涉人们的经济生活，例如税收，要点是不让人们掌控全部的财富。国家税收提供健康、食品、住宅和教育方面的基本福利。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">对于能力造成的不平等，唯一可能的替代方案是中央集权的经济，由中央权力分配给人们工作，并且付给人们大致一样的薪金。</span>
    <span class="na">反驳</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">一些国家实施过这种经济体制，但是付出了高昂的代价。既牺牲了自由，又缺乏效率。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">要减少能力差异的不平等，同时保留自由竞争经济，只有改变不平等的结果。可以对高收入者课以重税，并对低收入者提供福利。</span>
    <span class="na">反驳</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">这些方式都只能减弱而不能完全摆脱不应有的不平等，并且任何一种税收体系都会对经济有其他影响，难以事先预测。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">从世界范围来说，问题还要复杂得多，因为缺乏可以征“世界税”并被监督有效使用的世界政府。如此很难说何种补救措施才是可行的。</span>
    <span class="na">反驳</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">不太可能有一个世界范围内的正义的政府，若有这样的政府，它可能在很多方面都是非常可怕的。</span>
<span class="na">反方</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">主义</span><span class="pi">:</span> 
  <span class="na">主张</span><span class="pi">:</span> 
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">如果没有刻意的种族或者性别歧视，在一般的情况下也会造成不平等的现象。对此我们很难指责什么。</span>
    <span class="na">反驳</span><span class="pi">:</span> 
    <span class="pi">-</span> <span class="na">内容</span><span class="pi">:</span> <span class="s">如果这些差别使得某些人的境况非常悲惨的话，这会令人非常不安。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">社会地位的差异，出生于富裕家庭的人会受到较好的教育，拥有较多的资源。即使在一个机会平等的社会里，对于自然天赋相同的人而言，如果某人生来就比别人占优势，最终也会比别人得到更多的收益。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">社会需要的自然天赋或才能上的差异，而自然天赋的不同造成的结果也会相当不同。</span>
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">再分配税是不合理的，除非人们做了错事，否则政府就不该干涉。</span>
<span class="pi">-</span> <span class="na">主张</span><span class="pi">:</span>  
  <span class="pi">-</span> <span class="na">论点</span><span class="pi">:</span> <span class="s">更应该反对社会经济造成的不平等，而非个人天赋或才能造成的不平等。</span>
</code></pre></div></div>

<h3 id="8-死亡的本性-death">8. 死亡的本性 (Death)</h3>

<h3 id="9-生活的意义-the-meaning-of-life">9. 生活的意义 (The Meaning of Life)</h3>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[这是编程随想 [电子书库/哲学/通俗读物] 中的一本，他重回赛博空间的可能性已经越来越小了，读书，写读书笔记，也是对他进行纪念的一种方式。]]></summary></entry><entry><title type="html">.ai | 神经网络中的卷积及其参数</title><link href="https://mountaye.github.io/blog/articles/parameters-in-convolution-in-neural-network-and-transposeconv" rel="alternate" type="text/html" title=".ai | 神经网络中的卷积及其参数" /><published>2022-12-29T00:00:00-06:00</published><updated>2022-12-29T00:00:00-06:00</updated><id>https://mountaye.github.io/blog/articles/parameters-in-convolution-in-neural-network-and-transposeconv</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/parameters-in-convolution-in-neural-network-and-transposeconv"><![CDATA[<p>在读 PyTorch 的文档和源码的时候，发现写文档的人也不怎么解释啥是卷积，卷积的各个参数是什么意思，只在文档里扔了个链接就完事了，链接那头是一个 GitHub 上的动图演示仓库，是一篇论文《A guide to convolution arithmetic for deep learning》（链接在文末）的附件。于是这篇文章，基本上就是论文的读书笔记了。</p>

<h2 id="数学的卷积连续-vs-离散">数学的卷积：连续 vs. 离散</h2>

<h3 id="定义">定义</h3>

<p>连续的情况，两个单变量函数 \(f(\cdot)\) 和 \(g(\cdot)\) 的卷积，定义为：</p>

\[\left(f*g\right)(x):=\int_{-\infty}^{\infty}f(\tau)g(x-\tau)d\tau\]

<p>离散的情况，两个向量（也就是一阶张量） \(\vec f\) 和 \(\vec g\) 的卷积，定义为：</p>

\[\left(\vec f * \vec g\right)_i := \sum_{j=-\infty}^{\infty} f_j g_{i-j}\]

<p>多变量函数/高阶张量的情况，只需要多加几重积分/求和号就可以类推了。</p>

<p>看这两个定义——</p>

<p>只看等号左边的话，可以把卷积看作是一种特殊的乘法，也就是一种<strong>运算。</strong>f 和 g 的地位是平等的，卷积甚至还满足交换律，你甚至可以把两者的顺序变一变；</p>

<p>但是看等号右边的话，卷积就应该被看作是一种<strong>变换</strong>。f 和 g 的地位不再平等，f 是被变换的函数/向量，g 是变换的核 (kernel)。函数的情况里，g 把定义在 \(\tau\) 空间里的函数 f 变换成了 x 空间里的另一个函数；向量的情况里，g 把一个 J (j 所有可能取值的数量) 维向量 f 变换成了一个 I (i 所有可能取值的数量) 维向量。</p>

<p>神经网络中的卷积，<strong>借用</strong>的主要是第二种<strong>理解</strong>。</p>

<h3 id="手算一个例子">手算一个例子</h3>

<p>例如 \(\vec f = (1,2,3,4)\), \(\vec g = (1,2,3)\)，而且约定下标从 0 开始的话——</p>

<p>  \((\vec f*\vec g)_0 = f_0g_0 = 1\)</p>

<p>  \((\vec f*\vec g)_1 = f_0g_1 + f_1g_0  = 4\)</p>

<p>  \((\vec f*\vec g)_2 = f_0g_2 + f_1g_1 + f_2g_0 = 10\)</p>

<p>  \((\vec f*\vec g)_3 = f_1g_2 + f_2g_1 + f_3g_0 = 16\)</p>

<p>  \((\vec f*\vec g)_4 = f_2g_2 + f_3g_1 = 17\)</p>

<p>  \((\vec f*\vec g)_5 = f_3g_2 = 12\)</p>

<p>不想手算？</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">signal</span>
<span class="n">signal</span><span class="p">.</span><span class="nf">convolve</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]),</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
</code></pre></div></div>

<h3 id="形象化表示">形象化表示</h3>

<p>上面的计算过程，可以看作是——</p>

<ol>
  <li>把 g 向量的<strong>顺序反过来；</strong></li>
  <li>把 g 的最右一个元素和 f 的最左元素对齐，</li>
  <li>上下两行都有数字的列相乘（也就是把没有数字的地方看作 0），然后把所有乘积相加，得到 f*g 的第一项；</li>
  <li>把 g 向右移动一格</li>
  <li>重复第3、4步</li>
  <li>直到 g 的最左项移动到 f 的最右一个元素。</li>
</ol>

<p>形如下列各表：</p>

<table>
  <thead>
    <tr>
      <th>f</th>
      <th> </th>
      <th> </th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
    <tr>
      <th>g</th>
      <th>3</th>
      <th>2</th>
      <th>1</th>
      <th> </th>
      <th> </th>
      <th> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>(f*g)(0) = 1</td>
      <td> </td>
      <td> </td>
      <td>1</td>
      <td> </td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<hr class="slender" />

<table>
  <thead>
    <tr>
      <th>f</th>
      <th> </th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
    <tr>
      <th>g</th>
      <th>3</th>
      <th>2</th>
      <th>1</th>
      <th> </th>
      <th> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>(f*g)(1) = 4</td>
      <td> </td>
      <td>2</td>
      <td>2</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<hr class="slender" />

<table>
  <thead>
    <tr>
      <th>f</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>g</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td> </td>
    </tr>
    <tr>
      <td>(f*g)(2) = 10</td>
      <td>3</td>
      <td>4</td>
      <td>3</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<hr class="slender" />

<table>
  <thead>
    <tr>
      <th>f</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
    </tr>
    <tr>
      <th>g</th>
      <th> </th>
      <th>3</th>
      <th>2</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>(f*g)(3) = 16</td>
      <td> </td>
      <td>6</td>
      <td>6</td>
      <td>4</td>
    </tr>
  </tbody>
</table>

<hr class="slender" />

<table>
  <thead>
    <tr>
      <th>f</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th> </th>
    </tr>
    <tr>
      <th>g</th>
      <th> </th>
      <th> </th>
      <th>3</th>
      <th>2</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>(f*g)(4) = 17</td>
      <td> </td>
      <td> </td>
      <td>9</td>
      <td>8</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<hr class="slender" />

<table>
  <thead>
    <tr>
      <th>f</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th> </th>
      <th> </th>
    </tr>
    <tr>
      <th>g</th>
      <th> </th>
      <th> </th>
      <th> </th>
      <th>3</th>
      <th>2</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>(f*g)(5) = 12</td>
      <td> </td>
      <td> </td>
      <td> </td>
      <td>12</td>
      <td> </td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="机器学习的卷积是卷积吗">机器学习的卷积，是卷积吗？</h2>

<p>看论文给出的图 Figure 1.1，在卷积核是灰色 3*3 矩阵的情况下，对蓝色 5*5 矩阵的卷积就是直接把核对齐到蓝色矩阵上，<strong>并没有把核的元素顺序颠倒过来</strong>。</p>

<p>这玩意能叫卷积吗？</p>

<p><img src="/blog/assets/photos/2022-12-29-convolution.png" alt="convolution" /></p>

<p>有人强行挽尊，说我们画图示的时候已经把核给颠倒过来了，想知道卷积核就把灰色小矩阵再颠倒回去——</p>

<p>但是，不颠倒就对齐相乘的运算也是有名字的，叫 cross correlation。核有没有颠倒，convolution 还是 cross correlation 一组合，可以带来升维打击般的混乱，堪比高中化学的“还原剂被氧化，氧化剂被还原”……所以，对于计算机专业的数学水平，不予置评～</p>

<p>（你这样纠缠有意思吗？.jpg）</p>

<h2 id="卷积torchnnconv-及其各个参数">卷积<code class="language-plaintext highlighter-rouge">torch.nn.Conv</code> 及其各个参数</h2>

<h3 id="in_channels--out_channels"><code class="language-plaintext highlighter-rouge">in_channels</code> &amp; <code class="language-plaintext highlighter-rouge">out_channels</code></h3>

<p>“卷积”的意义在于用一种比较省内存的方式，考虑输入张量中各个元素，和空间上相近的邻居元素之间的关系。所以只需要在真的存在空间关系的维度做卷积，其他维度可以留着不动。</p>

<p>比如一张彩色图片，是一个 (颜色<em>高度</em>宽度) 的 3 阶张量，我们只需要对高度和宽度两个维度做卷积，颜色就是不参与“卷积”的 channel。</p>

<p><code class="language-plaintext highlighter-rouge">in_channel</code> 就是被“卷积”的张量的 channel 数，<code class="language-plaintext highlighter-rouge">out_channel</code> 是“卷积”结果的 channel 数。比如我们想从一张 RGB 三色图片中分辨出前景和背景两种不同区域，<code class="language-plaintext highlighter-rouge">in_channel=3</code>, <code class="language-plaintext highlighter-rouge">out_channel=2</code>。</p>

<p>而 <code class="language-plaintext highlighter-rouge">in_channel</code> 如何能够与 <code class="language-plaintext highlighter-rouge">out_channel</code> 取值不同，原理见 Figure 1.3。我们使用 <code class="language-plaintext highlighter-rouge">out_channel</code> 个不含 channel 维度的“卷积”核，每一个核都与每一个 in channel 做卷积，得到图中的蓝、紫色小矩阵，然后直接把不同的 in channel 暴力求和，得到的结果分别作为卷积结果的 out channel。（这个暴力求和与我以前想得不一样，我以为是什么每一元素都做了一个<code class="language-plaintext highlighter-rouge">in_channel</code>*<code class="language-plaintext highlighter-rouge">out_channel</code> 的全联通层）</p>

<p><img src="/blog/assets/photos/2022-12-29-channels.png" alt="channels" /></p>

<p>PyTorch 的习惯，对于一个 N 阶“卷积”，参与卷积的是张量的最后 N 阶，<code class="language-plaintext highlighter-rouge">in_channel</code> 和 <code class="language-plaintext highlighter-rouge">out_channel</code> 也就是被卷张量和卷积结果的 <code class="language-plaintext highlighter-rouge">Tensor.shape[-(N+1)]</code></p>

<p>后面图示的例子都没有考虑 <code class="language-plaintext highlighter-rouge">in_channel</code> 和 <code class="language-plaintext highlighter-rouge">out_channel</code> 的数量，也就是都当作 1 了。</p>

<h3 id="kernel_size"><code class="language-plaintext highlighter-rouge">kernel_size</code></h3>

<p>就是灰色矩阵“卷积”核，每边有几个数字。如果不同方向的边长不一，该参数就需要用一个 tuple 来表示。Figure 1.1 的灰色卷积核，<code class="language-plaintext highlighter-rouge">kernel_size=(3,3)</code></p>

<p><img src="/blog/assets/photos/2022-12-29-kernel.png" alt="kernel" /></p>

<h3 id="padding--padding_mode"><code class="language-plaintext highlighter-rouge">padding</code> &amp; <code class="language-plaintext highlighter-rouge">padding_mode</code></h3>

<p>前面手算例子的时候很鸡贼地把 0 作为向量下标的起点。如果采用日常 1 开头的下标来算，第 1 项结果为零，整个卷积结果的长度会长很多，而且多出来的后面几项也都是零。</p>

<p>而且在这个过程中，我们实际上是把一个有限长度的向量，看作了一个以所有整数 \(\Z\) 为定义域的函数，除了那有限的几项之外，其余地方都定义函数值为 0。</p>

<p>用计算机计算的话显然没法如此奢侈地谈“无限多个”，例子中实际用到的，在 \(\vec f\) 左右两边各需要 2 个 0，也就是说 <code class="language-plaintext highlighter-rouge">padding=2</code>, <code class="language-plaintext highlighter-rouge">padding_mode='zeros'</code></p>

<p>Figure 1.2 表示的就是 <code class="language-plaintext highlighter-rouge">padding=(1,1)</code> 的情况（蓝色是被卷张量，白色是 padding，灰色是卷积核，绿色是卷积结果）：</p>

<p><img src="/blog/assets/photos/2022-12-29-padding.png" alt="padding" /></p>

<p>既然神经网络中的卷积并不是真正的卷积，所以他们索性不装了——</p>

<p>正常卷积的结果往往比被卷张量大一圈（具体大多少取决于  <code class="language-plaintext highlighter-rouge">kernel_size</code>, <code class="language-plaintext highlighter-rouge">padding</code>, <code class="language-plaintext highlighter-rouge">stride</code> 多个参数），但是图像处理的时候经常希望输出图片和输入图片一样大，此时可以用字符串 <code class="language-plaintext highlighter-rouge">“same”</code> 作为 <code class="language-plaintext highlighter-rouge">padding</code> 的参数，自动计算 padding 的大小。<code class="language-plaintext highlighter-rouge">“strict”</code> 则表示 <code class="language-plaintext highlighter-rouge">padding=0</code>, 这样输出图片尺寸会变小，但是没有 padding，也就没有往图片里掺杂研究者对图片边缘以外信息的臆测。</p>

<p>同时 <code class="language-plaintext highlighter-rouge">padding_mode</code> 参数表示往被卷张量四周填充的数字也不一定是 0。比如对于图片，0 往往表示纯黑，而绝大多数图片的视野之外，往往是和图片边缘像素值相差不大的值。所以 <code class="language-plaintext highlighter-rouge">padding_mode</code> 除了 <code class="language-plaintext highlighter-rouge">zeros</code> 之外，还接受以下取值：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">reflect</code>: 以图片边缘为镜面，把边缘附近的像素值对陈反射出去；</li>
  <li><code class="language-plaintext highlighter-rouge">replicate</code>: 只取边缘的像素值作为常数，直接向外延拓；</li>
  <li><code class="language-plaintext highlighter-rouge">circular</code>: 类似于物理中的周期性边界条件，取对边附近的像素值作为 padding 内容。</li>
</ul>

<h3 id="stride"><code class="language-plaintext highlighter-rouge">stride</code></h3>

<p>前面手算卷积的第4步，把卷积核向右移动了1格，如果每次移动超过1格，就需要这个参数指定移动步长。如果不同方向的步长不同，也是用 tuple 来表示。</p>

<p>Figure 1.4 表示的就是 <code class="language-plaintext highlighter-rouge">stride=(2,2)</code> 的情况（蓝色是被卷张量，蓝色中的深色块是卷积核，绿色是卷积结果）：</p>

<p><img src="/blog/assets/photos/2022-12-29-stride.png" alt="stride" /></p>

<h3 id="dilation"><code class="language-plaintext highlighter-rouge">dilation</code></h3>

<p>这个参数把“卷积”核撑开，也就相当于在“卷积”核的相邻元素之间加 0。Figure 1.5 表示的就是 <code class="language-plaintext highlighter-rouge">dilation=(1,1)</code> 的情况（蓝色是被卷张量，蓝色中的深色块是卷积核，绿色是卷积结果）：</p>

<p><img src="/blog/assets/photos/2022-12-29-dilation.png" alt="dilation" /></p>

<p>比如 <code class="language-plaintext highlighter-rouge">dilation=1</code> 时，(1,2,3) 的卷积核就相当于 (1,0,2,0,3)</p>

<p>比如 <code class="language-plaintext highlighter-rouge">dilation=2</code> 时，(1,2,3) 的卷积核就相当于 (1,0,0,2,0,0,3)</p>

<p>这样可以让卷积核在尺寸比较小的情况下，覆盖到更大面积的被卷张量。当然具体实现时，不可能直接补 0 这么浪费内存。</p>

<h3 id="groups"><code class="language-plaintext highlighter-rouge">groups</code></h3>

<p>该参数必须是 <code class="language-plaintext highlighter-rouge">in_channel</code> 和 <code class="language-plaintext highlighter-rouge">out_channel</code> 的公约数，当其不为 1 时，就相当于同时做 <code class="language-plaintext highlighter-rouge">groups</code> 个卷积，其中每个卷积的 <code class="language-plaintext highlighter-rouge">in_channel=in_channel/groups</code>, <code class="language-plaintext highlighter-rouge">out_channel=out_channel/groups</code></p>

<h3 id="bias"><code class="language-plaintext highlighter-rouge">bias</code></h3>

<p>该参数是一个布尔值，卷积类似于一种高维空间里的乘法，这个参数就决定是否要拟合 <code class="language-plaintext highlighter-rouge">y=kx+b</code> 中的 <code class="language-plaintext highlighter-rouge">b</code></p>

<h2 id="卷积的逆运算-transposeconv">“卷积”的“逆运算”： <code class="language-plaintext highlighter-rouge">TransposeConv</code></h2>

<p>卷积的结果比 padding 之后的被卷张量要小。尤其当“卷积”的 <code class="language-plaintext highlighter-rouge">stride</code> 约等于 <code class="language-plaintext highlighter-rouge">kernel_size</code> 时，卷积的就变成了某些池化 (pooling)（求最大值不是一种线性算子，所以最大值池化不能用卷积表示，但是平均值池化可以）。</p>

<p>那么在类似 U-net 这样的模型里，右半边的数据升维（下图中的绿箭头），就需要一种“卷积”的“逆运算”。有人把这种运算叫做 deconvolution，有人叫做 transposed convolution，还有人叫做 convolution with fractional strides。</p>

<p><img src="/blog/assets/photos/2022-12-29-unet.png" alt="Unet" /></p>

<p>PyTorch 取的是第二种名字。论文解释了为什么这么取名字，笔记以后有时间再补上把……</p>

<p>因为这个与运算本身就是作为“卷积”的逆运算出现的，所以 PyTorch 的文档里这么说：</p>

<blockquote>
  <p>This is set so that when a <code class="language-plaintext highlighter-rouge">Conv2d</code> and a <code class="language-plaintext highlighter-rouge">ConvTranspose2d</code> are initialized with same parameters, they are inverses of each other in regard to the input and output shapes.</p>

</blockquote>

<p>也就是说，把 <code class="language-plaintext highlighter-rouge">ConvTranspose</code> 的输入和输出反过来，然后按照 <code class="language-plaintext highlighter-rouge">Conv</code> 的规则确定各个参数，填入 <code class="language-plaintext highlighter-rouge">ConvTranspose</code> 的括号里就可以了，除了 <code class="language-plaintext highlighter-rouge">output_padding</code></p>

<h3 id="output_padding"><code class="language-plaintext highlighter-rouge">output_padding</code></h3>

<p><code class="language-plaintext highlighter-rouge">ConvTranspose</code> 的输出就是对应 <code class="language-plaintext highlighter-rouge">Conv</code> 的输入。看 Figure 2.7：</p>

<p><img src="/blog/assets/photos/2022-12-29-output-padding.png" alt="padding_output" /></p>

<p>当 \((input+2*padding)/stride\) 不能整除的时候，最右的几列最下的几行就被卷积核忽略掉了。那么在逆运算 <code class="language-plaintext highlighter-rouge">TransposeConv</code> 中，这就意味着同一个输入可能对应着 \(stride-1\) 种可能的输出。<code class="language-plaintext highlighter-rouge">output_padding</code>参数就可以消除这种歧义，调整 <code class="language-plaintext highlighter-rouge">TransposeConv</code> 输出张量的尺寸。</p>

<h2 id="参考链接">参考链接</h2>

<ul>
  <li>给卷积正名: <a href="https://www.kaggle.com/general/225375">https://www.kaggle.com/general/225375</a></li>
  <li>PyTorch Conv2d 源码: <a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#_ConvNd">https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#_ConvNd</a></li>
  <li>论文: <a href="https://arxiv.org/abs/1603.07285">https://arxiv.org/abs/1603.07285</a></li>
  <li>动图演示: <a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md</a></li>
  <li>U-net: <a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/</a></li>
  <li>PyTorch TransposeConv 文档: <a href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html">https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html</a></li>
</ul>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[在读 PyTorch 的文档和源码的时候，发现写文档的人也不怎么解释啥是卷积，卷积的各个参数是什么意思，只在文档里扔了个链接就完事了……]]></summary></entry><entry><title type="html">文革史笔记-2.2 | 清除“顶峰论”的反对者</title><link href="https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-2" rel="alternate" type="text/html" title="文革史笔记-2.2 | 清除“顶峰论”的反对者" /><published>2022-12-17T00:00:00-06:00</published><updated>2022-12-17T00:00:00-06:00</updated><id>https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-2</id><content type="html" xml:base="https://mountaye.github.io/blog/articles/great-cultural-revolution-ten-years-2-2"><![CDATA[<h2 id="格式说明">格式说明</h2>

<ul>
  <li><em>下划线</em> 包括的内容，是对应章节的内容梗概。</li>
  <li><code class="language-plaintext highlighter-rouge">&gt; blockquote</code> 引用的内容是对原文的摘抄。</li>
  <li>没有下划线的内容，是根据引文的个人引申和感想。<del>一般来说是引文在前，感想在后</del>。各段感想之间以分割线 <code class="language-plaintext highlighter-rouge">&lt;hr /&gt;</code> 区分。</li>
  <li>无序列表的内容，是对应章节的时间线整理。很多章节的时间线互相重叠，这在第二卷和第三卷中会更加常见，所以我另外维护了一份总的时间线，笔记全部完成后发布。</li>
</ul>

<h2 id="内容梗概">内容梗概</h2>

<p><em>林彪因为身体不好，难以胜任国防部长的实际职责，具体工作多由罗瑞卿负责。为了将权力抓在自己手里，罗织罪名批斗之，导致罗瑞清跳楼，摔成残疾。</em></p>

<p><em>为了交好江青，作为投名状，在军队系统举办“部队文艺工作座谈会”。</em></p>

<p><em>作为“部队文艺工作座谈会”内容的延申，中宣部长陆定一及其妻子成为斗争目标。</em></p>

<p>本章内容非常没劲，无非是红色贵族之间的勾心斗角。但是，如果不是这些无聊的勾心斗角，使得众多的红色贵族也成为了这场运动的受害者，这场运动还能短暂地获得“彻头彻尾的动乱”的定性，无数被构陷的普通百姓还能恢复名誉吗？唉……</p>

<hr class="slender" />

<h2 id="摘抄随想">摘抄随想</h2>

<p>简体影印版第197页缺失，根据“本土与世界”修订新版，补录如下：</p>

<blockquote>
  <p>……进市后，罗瑞卿没被安排在他每次去上</p>

  <p>海时住的锦江饭店，而是安排在他从来未住过的地方。罗瑞卿心中生疑，问了一句，得到的答复是锦江饭店住满了。按照惯例，罗瑞卿每到一处，秘书的第一件事就是把电话机架好，这次却受到婉转而坚决的阻挡。接着，通知罗瑞卿，有关领导人正在房间里等他谈话。他觉得蹊跷，有些紧张，又猜不透可能会发生什么事情。他没有发觉，这里警戒森严，不同于以往，便径直走向目的地。在房间里等待罗瑞卿的几位领导人是他熟悉又深为敬重的老战友，但谈话时却犹犹豫豫，经常中断话语，似乎有难以启齿之言。然而，为了服从上级部门的决定，他们最终还是说明了，正在开的会议是对罗瑞卿进行批判。罗瑞卿急于想知道会议情况，但自始至终被拒绝在会场门外。</p>

  <p>罗瑞卿不得而知，被拒之门外的会议是林彪策划的一次对罗瑞卿进行突击的紧急会议。这次会议从1965年12月8日开始，到15日结束，由林彪主持。</p>

  <p>事情源于1965年11月末。在杨尚昆被调离中央办公厅后，林彪立即向罗瑞卿发难了。林彪亲自给毛泽东写了一封信，说有重要情况需要报告，欲先派叶群送材料并作初步口头汇报。在得到毛泽东的应允后，叶群到杭州向毛泽东作了六七个小时的汇报，主要是利用海军的材料诬陷罗瑞卿。12月2日，毛泽东在一份报告上对罗瑞卿问题作了如下披语：“那些不相信突出政治，对于突出政治表示阳奉阴违，而袭击另外散布一套折中主义（即机会主义）的人们，大家应当有所警惕。”会议遵照毛泽东的批示，揭发、批判了罗瑞卿的所谓“反党篡军的罪行”。
这次会议是中共中央政治局常委扩大会议。连中央委会都不是的叶群不仅出席了会议，还在会上就罗瑞卿问题作了三次发言，总计约十小时，成了会上“最有分量”的“炮弹”。叶群这个被称为“浑身上下都是假”的女人，早就使罗瑞卿十分厌恶。六十年代初部队评级定勋时，由于叶群自四九年后不断调动工作，从军队到地方，又从地方到军队……每次调动，都伴随着职级的提升，因此对她来说，职级已经很不低了，罗瑞卿考虑到这些因素，按照规定将叶群评为上校，而没有满足叶群要定大校的愿望，使叶群记恨在心；1965年春，林彪</p>

  <p>关于“突出政治五项原则”发到部队前，罗瑞卿建议改掉文件中提到叶群名字的地方……</p>
</blockquote>

<hr class="slender" />

<h2 id="时间线">时间线</h2>

<ul>
  <li>1959年
    <ul>
      <li>林彪主持中央军委工作，任国防部长后， 由于身体的原因，军内许多事务实际上是由罗瑞卿具体来抓，刘少奇就曾公开表示过，罗瑞卿是国防部长的接班人。【2.2.对“顶峰论”的异议】</li>
    </ul>
  </li>
  <li>1960年
    <ul>
      <li>林彪拋出“顶峰论”和“最高最活”等极左口号时，罗瑞卿针锋相对地指出：“难道马列主义、毛泽东思想就不再发展了？把革命导师的理论说成‘顶峰’，这本身就违 背了毛泽东思想。” “‘最高最活’，难道还有次高次活？毛主席知道了也不会同意。”【2.2.对“顶峰论”的异议】</li>
    </ul>
  </li>
  <li>1961年
    <ul>
      <li>林彪提出“背警句”、“立竿见影”等口号。罗瑞卿明确表示同意罗荣桓元帅的观点。【2.2.对“顶峰论”的异议】</li>
    </ul>
  </li>
  <li>1960年代初
    <ul>
      <li>部队评级定勋时，由于叶群自四九年后不断调动工作，从军队到地方，又从地方到军队……每次调动，都伴随着职级的提升，因此对她来说，职级已经很不低了，罗瑞卿考虑到这些因素，按照规定将叶群评为上校，而没有满足叶群要定大校的愿望，使叶群记恨在心。【2.2.1965年底的上海“紧急会议”】</li>
    </ul>
  </li>
  <li>1965年初
    <ul>
      <li>抓住这一时代特征，林彪就在学习毛泽 东著作上，更用心地大作文章。他不断地宣传，“应该用毛泽东思想，用毛主席著作，去提高群众的觉悟，提高群众的思想。地方工作总要有一个武器么！现成的武器不用，是最笨的了！ ”“中国要兴旺，就要用毛泽东思想武装人民群众。毛主席的思想武装了群众，中国就兴旺起来了。”“毛主席的话， 水平最髙，威力最大，句句是真理，一句顶一万句。”林彪企图用这些讲话来赢得毛泽东对他的更大欢心。【2.2.部队文艺工作座谈会】</li>
    </ul>
  </li>
  <li>1965年春
    <ul>
      <li>林彪关于“突出政治五项原则”发到部队前，罗瑞卿建议改掉文件中提到叶群名字的地方。【2.2.1965年底的上海“紧急会议”】</li>
    </ul>
  </li>
  <li>1965年11月
    <ul>
      <li>《评新编历史剧<海瑞罢官>》发表前后，江青多次打电话给罗瑙卿，说她要召开一个 “部队文艺工作座谈会”，请罗瑞卿参加。罗瑞卿对江 青反感，对江青的要求置之不理。【2.2.嫉妒与怨恨的结合】</海瑞罢官></li>
      <li>江青还要求发给她军装，罗瑞卿又明确交待：军衣可以发一套，她没有军籍，领 章、帽徵不给她发。【2.2.嫉妒与怨恨的结合】</li>
      <li>月末，杨尚昆被调离中央办公厅后，林彪立即向罗瑞卿发难了。林彪亲自给毛泽东写了一封信，说有重要情况需要报告，欲先派叶群送材料并作初步口头汇报。在得到毛泽东的应允后，叶群到杭州向毛泽东作了六七个小时的汇报，主要是利用海军的材料诬陷罗瑞卿。【2.2.1965年底的上海“紧急会议”】</li>
    </ul>
  </li>
  <li>1965年12月2日
    <ul>
      <li>毛泽东在一份报告上对罗瑞卿问题作了如下披语：“那些不相信突出政治，对于突出政治表示阳奉阴违，而袭击另外散布一套折中主义（即机会主义）的人们，大家应当有所警惕。”【2.2.1965年底的上海“紧急会议”】</li>
    </ul>
  </li>
  <li>1965年秋冬之际
    <ul>
      <li>林彪叫秘书打电话授意海军副司令员李作鹏写一个《关于近年来海军两种思想斗争 的情况》，重点是罗瑞卿的表现。【2.2.1965年底的上海“紧急会议”】</li>
      <li>林彪的老婆叶群则亲自打电 活给李作鹏，说罗瑞卿“有野心”，“想当国防部长”，“正在组织新班子”，要李作鹏“从海军角度”写材料。【2.2.1965年底的上海“紧急会议”】</li>
      <li>林彪、叶群又指使空军司令员吴法宪利用前空军司令员刘亚楼等问题诬陷罗瑞卿。【2.2.1965年底的上海“紧急会议”】</li>
      <li>罗瑞卿作为总参谋长从北京去云南落实中央军委的军事部署。突然接到通知，要他 马上到上海开会，却没有透露会议内容。在上海机场前来接他的是上海市委的一位负责人和空军司令员吴法宪，以往那种见到上司满脸堆着殷勤献媚的笑容无影无踪了。【2.2.1965年底的上海“紧急会议”】</li>
    </ul>
  </li>
  <li>1965年12月8日-15日
    <ul>
      <li>中共中央政治局常委扩大会议。【2.2.1965年底的上海“紧急会议”】
        <ul>
          <li>罗瑞卿不得而知，被拒之门外的会议是林彪策划的一次对罗瑞卿进行突击的紧急会议。</li>
          <li>会议遵照毛泽东的批示，揭发、批判了罗瑞卿的所谓“反党篡军的罪行”。</li>
          <li>这次会议是连中央委会都不是的叶群不仅出席了会议，还在会上就罗瑞卿问题作了三次发言，总计约十小时，成了会上“最有分量”的“炮弹”。</li>
          <li>林彪在紧急会议上宣布了撤销罗瑞卿中共中央书记处书记、国务院副总理、公安部部长，国防部副部长、中国人民解放军参谋长、中央军委秘书长、国防委员会副主席等一切职务。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>1966年2月2日-20日
    <ul>
      <li>江靑勾结林彪召开了一次部队文艺工作座谈会。为了夺取她对文艺界的领导权，为了向全国抛出她制造的“文艺黑线专政论”。【2.2.部队文艺工作座谈会】</li>
      <li>林彪积极配合江青百开部队文艺工作座谈会。会前，他亲自向与会者宣布他与江青关系的密切。会后， 起草了《林彪同志委托江青同志召开的部队文艺工作座谈会纪要》。江青梦寐以求的领导中国文艺的愿望，从军队幵始打开了缺口，而林彪利用江青亲近毛泽东的目标也大大地进了一 步。【2.2.部队文艺工作座谈会】</li>
      <li>《林彪同志委托江青同志召开的部队文艺工作座谈会纪要》中提到，自建国以来，文艺界被一条与毛泽东思想相对立的反党反社会主义的黑线专了我们的政”。江青的“文艺黑线专政论”，就是针对陆定一等人提出的。【2.2.对陆定一和严慰冰的打击】</li>
    </ul>
  </li>
  <li>1966年3月
    <ul>
      <li>在北京连续召开了批判罗瑞卿的会议，并指定罗瑞卿在会上做检查。如果罗瑞卿不承认林彪所罗列的他的一系列罪行，检査便休想通过。因此，会议开得很特别，没有确定的日程，停停开开，开开停停。每次休会意味着罗瑞卿失去一次陈述真相的机会，而每次复会，却是对罗瑞卿狂暴的又一次升级。【2.2.把罗瑞卿逼上绝路】</li>
      <li>罗瑞卿女儿点点在《生命的歌》一文中所叙述的那样：“看见的 是，他所崇敬的德高望重者沉然地背过脸去，卖身求荣者的敢 噪淹没了仗义执言的呼声，心地善良的人被迫缄口不言或违心附合，反复无常的人则高举顺风旗，脸上堆满狞笑，血口喷 人。他好象被推进茫茫黑夜中，黎明没有盼头，他好象被推上悬崖绝壁，却只能往前走。他面前的一切使他心境徬徨，迷惑 无法解，他意识到有人在逼他，逼他离开这个世界。”【2.2.把罗瑞卿逼上绝路】</li>
    </ul>
  </li>
  <li>1966年3月18日深夜
    <ul>
      <li>罗瑞卿孤寂、郁闷，觉得再也忍受不到天明。当他觉得一切终将结束时，他给妻子郝治平，留下了一张字条：“治平：会议的事没有告诉你，为了守纪律 ……永别了，要叫孩子们永远听党的话，听毛主席的话！我们 的党永远是光荣的、正确的、伟大的，你要继续改造自已！永远革命。”便从他住房的楼顶纵身跳了下去。【2.2.把罗瑞卿逼上绝路】</li>
      <li>罗瑞卿没有失去生命，只是左腿骨折。当他躺在医院里，睁开眼猜看见正在流泪的妻子时，一再嘱咐她“要把孩子们养大，不要让他们斩草除根。总有一天， 党会把事情搞清楚的。”【2.2.把罗瑞卿逼上绝路】</li>
      <li>罗瑞卿失却了自由。他被送进了一个不知名的地方，陪伴他的是一张硬板床，一张小方 桌，一个难得见到阳光的小窗户，严密的看守，无昼无夜的自 责和思索，以及难以忍受的断肢的疼痛和不断发作的心绞痛。【2.2.把罗瑞卿逼上绝路】</li>
      <li>林彪则把罗瑞卿看作是“身残名裂”的敌人，以自杀这种形式来表示“叛党叛国”的“罪犯”。他幸灾乐祸，并要一步步把 罗瑞卿逼到绝路。【2.2.把罗瑞卿逼上绝路】</li>
    </ul>
  </li>
  <li>1966年3月底
    <ul>
      <li>毛泽东说：“一九六二年十中全会作出了进行阶级斗争的决议，为什么吴晗写了那么许多反动文章，中宣部都不要打招呼，而发表姚文元的文章却偏偏要跟中宣部打招呼呢？难道中央的决议不算数吗？”“扣压左派稿件、包庇反共知识分子的人是‘大学阀’。中宣部是阎王殷。要‘打倒阎王、解放小鬼！’”是对中宣部长陆定一更尖锐的批评。【2.2.对陆定一和严慰冰的打击】</li>
    </ul>
  </li>
  <li>1966年4月28日
    <ul>
      <li>为了加紧对陆定一的打击陷害，严慰冰被诱捕入狱。【2.2.对陆定一和严慰冰的打击对陆定一和严慰冰的打击】</li>
    </ul>
  </li>
  <li>1966年5月18日
    <ul>
      <li>林彪在会议上说：“有人可能搞鬼，他们现 在已经在搞鬼。野心家，大有人在，他们是资产阶级的代表，想推翻我们的无产阶级专政。不能让他们得逞。有一批王八蛋，他们要冒险，他们待机而动。他们想杀我们，我们就要 镇压他们，他们是假革命，他们是假马克思主义，他们是假毛泽东思想，他们是背叛分子，毛主席健在，他们就背叛，他们就阳奉阴违，他们是野心家，他们搞鬼，他们现在就想杀人，用种种手法杀人。陆定一就是一个，陆定一的老婆就是一个。”【2.2.对陆定一和严慰冰的打击】</li>
      <li>严慰冰曾多次隐蔽地掲露林彪、叶群的虚伪，并对叶群在延安时期生活作风问题提出斥责，还对叶群自称十六岁入党的问题提出质疑，这些造成了林彪、叶群对严慰冰的怨恨。【2.2.对陆定一和严慰冰的打击】</li>
    </ul>
  </li>
</ul>]]></content><author><name>MountAye</name></author><summary type="html"><![CDATA[本章内容非常没劲，无非是红色贵族之间的勾心斗角。但是，如果不是这些无聊的勾心斗角，使得众多的红色贵族也成为了这场运动的受害者，这场运动还能短暂地获得“彻头彻尾的动乱”的定性，无数被构陷的普通百姓还能恢复名誉吗？唉……]]></summary></entry></feed>